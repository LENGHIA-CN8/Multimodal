{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_WijfxppfYfk",
    "outputId": "59217166-a6fa-4270-d536-d0aec5224098"
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch-lightning\n",
    "# !pip install transformers\n",
    "# !pip install vncorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YEE6ZUhdK8DJ",
    "outputId": "6f3c47ea-f836-4cee-e288-3b0492153fa2"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  7 01:28:21 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 32%   53C    P2    47W / 250W |   5526MiB / 11019MiB |     25%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:86:00.0 Off |                  N/A |\n",
      "|  0%   29C    P8     4W / 250W |   3496MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    214205      C   ...da3/envs/AI_DA/bin/python     5523MiB |\n",
      "|    1   N/A  N/A    429695      C   python                           3493MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-r5rwk7EG8Et"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nghiatl/anaconda3/envs/AI_DA/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "SEED_VALUE = 0\n",
    "random.seed(SEED_VALUE)\n",
    "torch.manual_seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5JN5uIr4LBuS",
    "outputId": "5549bc0c-f90d-47dc-e4ea-2ace1f478985"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/Colab Notebooks/Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOPX9jdjgwaB",
    "outputId": "fce64c1f-5b21-40b5-e362-57f5b14037a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception-Copy1.ipynb\r\n",
      "Inception.ipynb\r\n",
      "local1_folder_temp.zip\r\n",
      "local1_folder.zip\r\n",
      "Multimodal.ipynb\r\n",
      "Multimodal_newmodel.ipynb\r\n",
      "Multimodal_newmodel-weight.ipynb\r\n",
      "my_checkpoint_incept_seed0_bt16_fc_1e-3_1_nofreeze.pth.tar\r\n",
      "my_checkpoint_incept_seed0_bt16_fc_1e-3_1.pth.tar\r\n",
      "my_checkpoint_incept_seed0_bt16_fc_1e-3.pth.tar\r\n",
      "my_checkpoint_incept_seed0_bt16_fc_only2048_1e-4_freeze.pth.tar\r\n",
      "my_checkpoint_multi_modal_mrTrong_freeze_continue_10epoch.pth.tar\r\n",
      "my_checkpoint_multi_modal_mrTrong_freeze_f1.pth.tar\r\n",
      "my_checkpoint_multi_modal_mrTrong_freeze_f1_weight.pth.tar\r\n",
      "my_checkpoint_multi_modal_mrTrong_freeze.pth.tar\r\n",
      "my_checkpoint_multi_modal_mrTrong_freeze_weight.pth.tar\r\n",
      "my_checkpoint_multivoting_freeze_20.pth.tar\r\n",
      "my_checkpoint_multivoting_freeze_new_20_af_unfreeze.pth.tar\r\n",
      "my_checkpoint_multivoting_freeze_new_20.pth.tar\r\n",
      "my_checkpoint_resnet34_seed0_bt16_fc_5e-4.pth.tar\r\n",
      "my_checkpoint_resnet_seed0_bt16_fc_1e-3.pth.tar\r\n",
      "OUTPUT\r\n",
      "PhoBERT_foody.ipynb\r\n",
      "Resnet.ipynb\r\n",
      "runs\r\n",
      "vncorenlp\r\n",
      "VotingMultimodal.ipynb\r\n",
      "VotingMultimodal_newmodel.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "data_zip_file = './local1_folder.zip'\n",
    "# data_zip_file2 = './local2_folder.zip'\n",
    "\n",
    "csv_file2 = './OUTPUT/Comment_22.csv'\n",
    "csv_file3 = './OUTPUT/Comment_23.csv'\n",
    "csv_file4 = './OUTPUT/Comment_24.csv'\n",
    "csv_file5 = './OUTPUT/Comment_25.csv'\n",
    "\n",
    "csv_file = './OUTPUT/Comment.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YinE6ts__dfB"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwSAFGjcLttP"
   },
   "source": [
    "## Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AuYQmzhSgxiW"
   },
   "outputs": [],
   "source": [
    "data_zip = zipfile.ZipFile(data_zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EJSSyN5UEqZ",
    "outputId": "3f225eae-f16d-4305-c2dc-2a83376642b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58766"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_zip.namelist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'local1_folder-1/foody-fukunohana-hanoi-japanese-retstaurant-970-637197316556573205.jpg' in data_zip.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "DdGQBwnJg_Bs",
    "outputId": "19086978-ed5b-4920-d305-7728a4eff1cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local1_folder-1/foody-fukunohana-hanoi-japanese-retstaurant-970-637197316556573205.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=800x734 at 0x7F2D7EE8F010>\n",
      "(734, 800, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2d89b42800>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_path = data_zip.namelist()[1]\n",
    "print(img_path)\n",
    "img = Image.open(data_zip.open(img_path))\n",
    "print(img)\n",
    "print(np.asarray(img).shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LD9uOa1eiRj7"
   },
   "outputs": [],
   "source": [
    "# ### Scale image to [0,1]\n",
    "# trans = T.ToTensor()\n",
    "# trans(img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMRLRh98LpkS"
   },
   "source": [
    "## CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Pg2j5eX7kJ2I",
    "outputId": "688189ef-369e-4559-b4f8-a2a2093f3c17"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Đặt dồi sụn của quán vì đọc comment thấy hấp d...</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dồi khá ngon, mua về còn nóng mở ra thơm phức,...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Đặt xuất mỳ trộn thập cẩm, khá đầy đủ và đầy đ...</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Không hiểu sao quán này được 7.9 luôn. Đặt bán...</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dồi sụn bé tẹo, giá quá cao so với các quán kh...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Rating\n",
       "0  Đặt dồi sụn của quán vì đọc comment thấy hấp d...     5.8\n",
       "1  Dồi khá ngon, mua về còn nóng mở ra thơm phức,...     9.0\n",
       "2  Đặt xuất mỳ trộn thập cẩm, khá đầy đủ và đầy đ...     9.4\n",
       "3  Không hiểu sao quán này được 7.9 luôn. Đặt bán...     4.6\n",
       "4  Dồi sụn bé tẹo, giá quá cao so với các quán kh...     1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df1 = pd.read_csv(csv_file)\n",
    "data_df2 = pd.read_csv(csv_file2)\n",
    "data_df3 = pd.read_csv(csv_file3)\n",
    "data_df4 = pd.read_csv(csv_file4)\n",
    "data_df5 = pd.read_csv(csv_file5)\n",
    "\n",
    "\n",
    "\n",
    "data_df1[['Comment', 'Rating']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZ4rpv-1tdNu",
    "outputId": "1cfdc147-fb29-4a68-e65c-17551869e713"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3093, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-oQbCbM4gkOH"
   },
   "outputs": [],
   "source": [
    "data_df = pd.concat([data_df1,data_df2,data_df3,data_df4, data_df5], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHC1UlnMtlcz",
    "outputId": "dfe5d7e3-91a6-44f9-a944-4a3e6366f520"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14174, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DFR0Di-d-KCX"
   },
   "outputs": [],
   "source": [
    "data_df = data_df.dropna()\n",
    "data_df = data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sVhY9Oj9iwsf",
    "outputId": "d02fc229-a419-44b9-a985-1e9f36cb6d07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RevId                   0\n",
       "UserId                  0\n",
       "ResId                   0\n",
       "Comment                 0\n",
       "image_urls              0\n",
       "Food_score_cmt          0\n",
       "Services_score_cmt      0\n",
       "Atmosphere_score_cmt    0\n",
       "Position_score_cmt      0\n",
       "Price_score_cmt         0\n",
       "Rating                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "id": "uTTgx8nBJaIf",
    "outputId": "4febeb01-8ff8-4dc5-cb3d-330416a3154c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RevId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ResId</th>\n",
       "      <th>Comment</th>\n",
       "      <th>image_urls</th>\n",
       "      <th>Food_score_cmt</th>\n",
       "      <th>Services_score_cmt</th>\n",
       "      <th>Atmosphere_score_cmt</th>\n",
       "      <th>Position_score_cmt</th>\n",
       "      <th>Price_score_cmt</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3648046</td>\n",
       "      <td>8920424</td>\n",
       "      <td>965165</td>\n",
       "      <td>Đặt dồi sụn của quán vì đọc comment thấy hấp d...</td>\n",
       "      <td>https://images.foody.vn/res/g97/965165/s800/fo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3695359</td>\n",
       "      <td>18558601</td>\n",
       "      <td>965165</td>\n",
       "      <td>Dồi khá ngon, mua về còn nóng mở ra thơm phức,...</td>\n",
       "      <td>https://images.foody.vn/res/g97/965165/s800/fo...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3695487</td>\n",
       "      <td>13885433</td>\n",
       "      <td>965165</td>\n",
       "      <td>Đặt xuất mỳ trộn thập cẩm, khá đầy đủ và đầy đ...</td>\n",
       "      <td>https://images.foody.vn/res/g97/965165/s800/fo...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4256913</td>\n",
       "      <td>11400976</td>\n",
       "      <td>965165</td>\n",
       "      <td>Không hiểu sao quán này được 7.9 luôn. Đặt bán...</td>\n",
       "      <td>https://images.foody.vn/res/g97/965165/s800/fo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4246644</td>\n",
       "      <td>525112</td>\n",
       "      <td>965165</td>\n",
       "      <td>Dồi sụn bé tẹo, giá quá cao so với các quán kh...</td>\n",
       "      <td>https://images.foody.vn/res/g97/965165/s800/fo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RevId    UserId   ResId  \\\n",
       "0  3648046   8920424  965165   \n",
       "1  3695359  18558601  965165   \n",
       "2  3695487  13885433  965165   \n",
       "3  4256913  11400976  965165   \n",
       "4  4246644    525112  965165   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  Đặt dồi sụn của quán vì đọc comment thấy hấp d...   \n",
       "1  Dồi khá ngon, mua về còn nóng mở ra thơm phức,...   \n",
       "2  Đặt xuất mỳ trộn thập cẩm, khá đầy đủ và đầy đ...   \n",
       "3  Không hiểu sao quán này được 7.9 luôn. Đặt bán...   \n",
       "4  Dồi sụn bé tẹo, giá quá cao so với các quán kh...   \n",
       "\n",
       "                                          image_urls  Food_score_cmt  \\\n",
       "0  https://images.foody.vn/res/g97/965165/s800/fo...             5.0   \n",
       "1  https://images.foody.vn/res/g97/965165/s800/fo...            10.0   \n",
       "2  https://images.foody.vn/res/g97/965165/s800/fo...            10.0   \n",
       "3  https://images.foody.vn/res/g97/965165/s800/fo...             1.0   \n",
       "4  https://images.foody.vn/res/g97/965165/s800/fo...             1.0   \n",
       "\n",
       "   Services_score_cmt  Atmosphere_score_cmt  Position_score_cmt  \\\n",
       "0                 9.0                   5.0                 5.0   \n",
       "1                10.0                   9.0                 8.0   \n",
       "2                10.0                   9.0                 8.0   \n",
       "3                 5.0                   5.0                 6.0   \n",
       "4                 1.0                   1.0                 1.0   \n",
       "\n",
       "   Price_score_cmt  score  \n",
       "0              5.0    5.8  \n",
       "1              8.0    9.0  \n",
       "2             10.0    9.4  \n",
       "3              6.0    4.6  \n",
       "4              1.0    1.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add more data\n",
    "data_df.rename(columns={\"Rating\":\"score\"}, inplace=True)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "m87U0yoinm9x",
    "outputId": "c15d55ad-880d-4e67-89d4-25fb2a849ce1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://images.foody.vn/res/g97/965165/s800/foody-doi-sun-pate-shop-online-389-637116772226077520.jpg,https://images.foody.vn/res/g97/965165/s800/foody-doi-sun-pate-shop-online-427-637116772199356351.jpg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['image_urls'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "pPmcItkiypTV",
    "outputId": "5f3bfcb3-8015-48e0-9b16-8231d5921b2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Giữa cái thời tiết HN sớm trưa mưa nắng thất t...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9677</th>\n",
       "      <td>Sáng nào mình cx phải ăn phở ở đây ms chịu đc ...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9701</th>\n",
       "      <td>Hàng xôi tấp nập người ghé ăn &amp; mua mang đi, n...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9705</th>\n",
       "      <td>Quán chè nhỏ nhỏ, đối diện bakery Tati. Cô chủ...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9713</th>\n",
       "      <td>❤ Vị trí : hàng này mới mở dạo gần đây. Nằm ng...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>* mùa dịch ăn gì ??🤔🤔\\nĐang mùa dịch thế này c...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4907</th>\n",
       "      <td>Suất đặc biệt cơm gà + sườn ship Now</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>Chè sầu chính hãng nè cả nhà 😻 viêm họng mà vẫ...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>Nhân ngày xe bus hỏng đúng quán ding tea, mình...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14161</th>\n",
       "      <td>Vô tình thấy quán ở ngay mặt đường, sạch sẽ nổ...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>860 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Comment  score\n",
       "8      Giữa cái thời tiết HN sớm trưa mưa nắng thất t...    8.0\n",
       "9677   Sáng nào mình cx phải ăn phở ở đây ms chịu đc ...    8.0\n",
       "9701   Hàng xôi tấp nập người ghé ăn & mua mang đi, n...    8.0\n",
       "9705   Quán chè nhỏ nhỏ, đối diện bakery Tati. Cô chủ...    8.0\n",
       "9713   ❤ Vị trí : hàng này mới mở dạo gần đây. Nằm ng...    8.0\n",
       "...                                                  ...    ...\n",
       "4892   * mùa dịch ăn gì ??🤔🤔\\nĐang mùa dịch thế này c...    8.0\n",
       "4907                Suất đặc biệt cơm gà + sườn ship Now    8.0\n",
       "4955   Chè sầu chính hãng nè cả nhà 😻 viêm họng mà vẫ...    8.0\n",
       "5034   Nhân ngày xe bus hỏng đúng quán ding tea, mình...    8.0\n",
       "14161  Vô tình thấy quán ở ngay mặt đường, sạch sẽ nổ...    8.0\n",
       "\n",
       "[860 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Calculate score\n",
    "# data_df['score'] = data_df.apply(lambda x: (x['Food_score_cmt']+x['Services_score_cmt']+x['Atmosphere_score_cmt']+x['Position_score_cmt']+x['Price_score_cmt'])/5, axis = 1)\n",
    "data_df[(data_df['score'] >= 8) & (data_df['score'] <= 8)][['Comment','score']].sort_values(by=['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "Vw82otAuoXKO",
    "outputId": "09ab683f-f722-440f-d9e2-74bf27527e34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Giữa cái thời tiết HN sớm trưa mưa nắng thất thường, tối phần phật gió như này thì việc ngồi nhâm nhâm nhi nhi em caramen hoa quả này là 1 điều thật tuyệt - thơm thơm ngậy ngậy của caramen, vị thanh mát của các loại hoa quả: dưa hấu, xoài, thanh long, mít....được kết hợp lại với nhau rất thú vị, cốc còn rất là đầy đặn nữa chứ. Cơ mà anh chị chủ quán làm ngon quá đi, cứ bị nghiện ý, mỗi ngày sẽ nếm 1 vị: sữa chua thạch lá nếp nè, sc hoa quả, chè khoai dẻo nè.....chu choa v.v.....vân vân và mây mây...'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Comment'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2vytA2UJB4e5"
   },
   "outputs": [],
   "source": [
    "## label data\n",
    "def label_comment(x):\n",
    "  if x['score'] >= 8:\n",
    "    return 1\n",
    "  elif (x['score'] >= 6) & (x['score'] < 8):\n",
    "    return 2\n",
    "  else:\n",
    "    return 0\n",
    "data_df['label'] = data_df.apply(label_comment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "Oym9ogwW97m1",
    "outputId": "9b2b8026-7d6b-4e5c-c569-90af870cd086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6953\n",
      "2    4194\n",
      "0    3023\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAALRElEQVR4nO3dX4yl9V3H8c/XXaDyJwsU0pCFdCAhGBJMIZta0qYxNSKwpt70AtIo0RoS/yQlmpglTUy8W71o1KSxJRb1otJqW5VADWJLYjSGdpZC+efKtq6BDXStpksjFwr+vDjPwGFdnIGcc/Y7zOuVTOY5zzn85jvLs+995jlnZmqMEQD6+qHTPQAA/z+hBmhOqAGaE2qA5oQaoLndy1j0oosuGmtra8tYGuBt6dChQ98bY1x8qvuWEuq1tbWsr68vY2mAt6Wq+tc3us+lD4DmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaE6oAZpbyi8OePzYiawduH8ZS/M2cvTg/tM9AmwLzqgBmhNqgOaEGqA5oQZoTqgBmhNqgOaEGqA5oQZoTqgBmhNqgOaEGqA5oQZoTqgBmhNqgOa2FOqqurGqDlfVkao6sOyhAHjNpqGuql1JPpXkpiRXJ7m1qq5e9mAAzGzljPq9SY6MMb4zxvivJJ9P8jPLHQuADVsJ9d4kz87dfm7aB8AKLOzJxKq6varWq2r9lZdOLGpZgB1vK6E+luSyuduXTvteZ4xx1xhj3xhj366z9yxqPoAdbyuh/kaSK6vq8qo6M8ktSe5d7lgAbNj0t5CPMV6uql9N8kCSXUnuHmM8ufTJAEiyhVAnyRjjK0m+suRZADgF35kI0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0NyWfnrem3XN3j1ZP7h/GUsD7DjOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoLndy1j08WMnsnbg/mUsDe0dPbj/dI/A24wzaoDmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaE6oAZoTaoDmhBqguU1DXVWXVdVDVfVUVT1ZVR9fxWAAzGzl51G/nOTXxxiPVNV5SQ5V1YNjjKeWPBsA2cIZ9Rjj+THGI9P2D5I8nWTvsgcDYOZNXaOuqrUk1yZ5+BT33V5V61W1/spLJxY0HgBbDnVVnZvkS0nuGGO8ePL9Y4y7xhj7xhj7dp29Z5EzAuxoWwp1VZ2RWaQ/N8b48nJHAmDeVl71UUk+m+TpMcYnlz8SAPO2ckb9/iQ/m+RDVfXo9HbzkucCYLLpy/PGGH+fpFYwCwCn4DsTAZoTaoDmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaG4rvzPxTbtm756sH9y/jKUBdhxn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0NzuZSz6+LETWTtw/zKWBmjp6MH9S1vbGTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0Nymoa6qu6vqeFU9sYqBAHi9rZxR/3GSG5c8BwBvYNNQjzH+Lsl/rGAWAE7BNWqA5hYW6qq6varWq2r9lZdOLGpZgB1vYaEeY9w1xtg3xti36+w9i1oWYMdz6QOgua28PO+eJP+Y5Kqqeq6qPrb8sQDYsHuzB4wxbl3FIACcmksfAM0JNUBzQg3QnFADNCfUAM0JNUBzQg3QnFADNCfUAM0JNUBzQg3QnFADNCfUAM1t+tPz3opr9u7J+sH9y1gaYMdxRg3QnFADNCfUAM0JNUBzQg3QnFADNCfUAM0JNUBzQg3QnFADNCfUAM0JNUBzQg3QnFADNCfUAM0JNUBzQg3QXI0xFr9o1Q+SHF74wst1UZLvne4h3gJzr5a5V2snzf3uMcbFp7pjKb+KK8nhMca+Ja29FFW1vt1mTsy9auZeLXPPuPQB0JxQAzS3rFDftaR1l2k7zpyYe9XMvVrmzpKeTARgcVz6AGhOqAGaW2ioq+rGqjpcVUeq6sAi136L89xdVcer6om5fRdW1YNV9cz0/oJpf1XV70+zf6uqrpv7b26bHv9MVd225Jkvq6qHquqpqnqyqj6+TeZ+R1V9vaoem+b+rWn/5VX18DTfF6rqzGn/WdPtI9P9a3Nr3TntP1xVP7XMuec+5q6q+mZV3bdd5q6qo1X1eFU9WlXr077Wx8n08c6vqi9W1T9V1dNVdX33uavqqunPeePtxaq6Y2VzjzEW8pZkV5JvJ7kiyZlJHkty9aLWf4szfTDJdUmemNv3O0kOTNsHkvz2tH1zkr9OUknel+Thaf+FSb4zvb9g2r5giTNfkuS6afu8JP+c5OptMHclOXfaPiPJw9M8f5bklmn/p5P80rT9y0k+PW3fkuQL0/bV07FzVpLLp2Nq1wqOlV9L8qdJ7ptut587ydEkF520r/VxMn3MP0nyi9P2mUnO3w5zz82/K8kLSd69qrkXOfz1SR6Yu31nkjtX8Qe3yVxreX2oDye5ZNq+JLNvzkmSzyS59eTHJbk1yWfm9r/ucSuY/6+S/OR2mjvJ2UkeSfJjmX131u6Tj5EkDyS5ftrePT2uTj5u5h+3xHkvTfLVJB9Kct80x3aY+2j+b6hbHydJ9iT5l0wvZNguc5806w1J/mGVcy/y0sfeJM/O3X5u2tfNu8YYz0/bLyR517T9RvOfts9r+rL62szOTtvPPV0+eDTJ8SQPZnZW+f0xxsunmOHV+ab7TyR55+mYO8nvJvmNJP8z3X5ntsfcI8nfVNWhqrp92tf9OLk8yb8l+aPpUtMfVtU522DuebckuWfaXsncO/rJxDH7J63l6xOr6twkX0pyxxjjxfn7us49xnhljPGezM5Q35vkR07vRJurqp9OcnyMceh0z/IWfGCMcV2Sm5L8SlV9cP7OpsfJ7swuR/7BGOPaJP+Z2SWDVzWdO0kyPVfx4SR/fvJ9y5x7kaE+luSyuduXTvu6+W5VXZIk0/vj0/43mn/ln1dVnZFZpD83xvjydpl7wxjj+0keyuySwflVtfEzZeZneHW+6f49Sf49q5/7/Uk+XFVHk3w+s8sfv7cN5s4Y49j0/niSv8jsH8fux8lzSZ4bYzw83f5iZuHuPveGm5I8Msb47nR7JXMvMtTfSHLl9Gz5mZl9eXDvAtdflHuTbDzTeltm14A39v/c9Gzt+5KcmL6keSDJDVV1wfSM7g3TvqWoqkry2SRPjzE+uY3mvriqzp+2fziz6+pPZxbsj7zB3Bufz0eSfG06I7k3yS3TqysuT3Jlkq8va+4xxp1jjEvHGGuZHbNfG2N8tPvcVXVOVZ23sZ3Z/98n0vw4GWO8kOTZqrpq2vUTSZ7qPvecW/PaZY+N+ZY/94Ivst+c2asUvp3kE6u4sL/JPPckeT7Jf2f2L/nHMrue+NUkzyT52yQXTo+tJJ+aZn88yb65dX4hyZHp7eeXPPMHMvvy6VtJHp3ebt4Gc/9okm9Ocz+R5Den/VdkFqwjmX25eNa0/x3T7SPT/VfMrfWJ6fM5nOSmFR4vP57XXvXReu5pvsemtyc3/r51P06mj/eeJOvTsfKXmb36YTvMfU5mXz3tmdu3krl9CzlAczv6yUSA7UCoAZoTaoDmhBqgOaEGaE6oAZoTaoDm/hfbB3VVTumTMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data_df['label'].value_counts())\n",
    "data_df['label'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "J8CW9ISc6o4G",
    "outputId": "daa2c6d8-639e-42c9-e76f-ef92125c48ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Đặt dồi sụn của quán vì đọc comment thấy hấp d...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dồi khá ngon, mua về còn nóng mở ra thơm phức,...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Đặt xuất mỳ trộn thập cẩm, khá đầy đủ và đầy đ...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Không hiểu sao quán này được 7.9 luôn. Đặt bán...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dồi sụn bé tẹo, giá quá cao so với các quán kh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  label  score\n",
       "0  Đặt dồi sụn của quán vì đọc comment thấy hấp d...      0    5.8\n",
       "1  Dồi khá ngon, mua về còn nóng mở ra thơm phức,...      1    9.0\n",
       "2  Đặt xuất mỳ trộn thập cẩm, khá đầy đủ và đầy đ...      1    9.4\n",
       "3  Không hiểu sao quán này được 7.9 luôn. Đặt bán...      0    4.6\n",
       "4  Dồi sụn bé tẹo, giá quá cao so với các quán kh...      0    1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[['Comment','label', 'score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "5BGOclJx6q07",
    "outputId": "48837a3b-9c51-4c4e-9a7f-87d4ab42d742"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RevId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ResId</th>\n",
       "      <th>Comment</th>\n",
       "      <th>image_urls</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3648046</td>\n",
       "      <td>8920424</td>\n",
       "      <td>965165</td>\n",
       "      <td>Đặt dồi sụn của quán vì đọc comment thấy hấp d...</td>\n",
       "      <td>https://images.foody.vn/res/g97/965165/s800/fo...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3695359</td>\n",
       "      <td>18558601</td>\n",
       "      <td>965165</td>\n",
       "      <td>Dồi khá ngon, mua về còn nóng mở ra thơm phức,...</td>\n",
       "      <td>https://images.foody.vn/res/g97/965165/s800/fo...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3695487</td>\n",
       "      <td>13885433</td>\n",
       "      <td>965165</td>\n",
       "      <td>Đặt xuất mỳ trộn thập cẩm, khá đầy đủ và đầy đ...</td>\n",
       "      <td>https://images.foody.vn/res/g97/965165/s800/fo...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4256913</td>\n",
       "      <td>11400976</td>\n",
       "      <td>965165</td>\n",
       "      <td>Không hiểu sao quán này được 7.9 luôn. Đặt bán...</td>\n",
       "      <td>https://images.foody.vn/res/g97/965165/s800/fo...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4246644</td>\n",
       "      <td>525112</td>\n",
       "      <td>965165</td>\n",
       "      <td>Dồi sụn bé tẹo, giá quá cao so với các quán kh...</td>\n",
       "      <td>https://images.foody.vn/res/g97/965165/s800/fo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RevId    UserId   ResId  \\\n",
       "0  3648046   8920424  965165   \n",
       "1  3695359  18558601  965165   \n",
       "2  3695487  13885433  965165   \n",
       "3  4256913  11400976  965165   \n",
       "4  4246644    525112  965165   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  Đặt dồi sụn của quán vì đọc comment thấy hấp d...   \n",
       "1  Dồi khá ngon, mua về còn nóng mở ra thơm phức,...   \n",
       "2  Đặt xuất mỳ trộn thập cẩm, khá đầy đủ và đầy đ...   \n",
       "3  Không hiểu sao quán này được 7.9 luôn. Đặt bán...   \n",
       "4  Dồi sụn bé tẹo, giá quá cao so với các quán kh...   \n",
       "\n",
       "                                          image_urls  score  label  \n",
       "0  https://images.foody.vn/res/g97/965165/s800/fo...    5.8      0  \n",
       "1  https://images.foody.vn/res/g97/965165/s800/fo...    9.0      1  \n",
       "2  https://images.foody.vn/res/g97/965165/s800/fo...    9.4      1  \n",
       "3  https://images.foody.vn/res/g97/965165/s800/fo...    4.6      0  \n",
       "4  https://images.foody.vn/res/g97/965165/s800/fo...    1.0      0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df.drop(['Food_score_cmt','Services_score_cmt','Atmosphere_score_cmt','Position_score_cmt','Price_score_cmt'],axis=1)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_imgpath(df):\n",
    "    img_p = []\n",
    "    for path in df['image_urls'].split(\",\"):\n",
    "        img_path = 'local1_folder-1/' + path.split('/')[-1]\n",
    "        if img_path in data_zip.namelist():\n",
    "            img_p.append(img_path)\n",
    "    if len(img_p) > 0:\n",
    "        return ','.join(img_p)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['image_urls'] = data_df.apply(preprocess_imgpath, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RevId         0\n",
       "UserId        0\n",
       "ResId         0\n",
       "Comment       0\n",
       "image_urls    0\n",
       "score         0\n",
       "label         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df.dropna()\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "KPh6mSQK-pDj",
    "outputId": "115478a6-9a8e-4d84-e18c-5c8dddafbc0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6952\n",
      "2    4194\n",
      "0    3023\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAALRElEQVR4nO3dX4yl9V3H8c/XXaDyJwsU0pCFdCAhGBJMIZta0qYxNSKwpt70AtIo0RoS/yQlmpglTUy8W71o1KSxJRb1otJqW5VADWJLYjSGdpZC+efKtq6BDXStpksjFwr+vDjPwGFdnIGcc/Y7zOuVTOY5zzn85jvLs+995jlnZmqMEQD6+qHTPQAA/z+hBmhOqAGaE2qA5oQaoLndy1j0oosuGmtra8tYGuBt6dChQ98bY1x8qvuWEuq1tbWsr68vY2mAt6Wq+tc3us+lD4DmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaE6oAZpbyi8OePzYiawduH8ZS/M2cvTg/tM9AmwLzqgBmhNqgOaEGqA5oQZoTqgBmhNqgOaEGqA5oQZoTqgBmhNqgOaEGqA5oQZoTqgBmhNqgOa2FOqqurGqDlfVkao6sOyhAHjNpqGuql1JPpXkpiRXJ7m1qq5e9mAAzGzljPq9SY6MMb4zxvivJJ9P8jPLHQuADVsJ9d4kz87dfm7aB8AKLOzJxKq6varWq2r9lZdOLGpZgB1vK6E+luSyuduXTvteZ4xx1xhj3xhj366z9yxqPoAdbyuh/kaSK6vq8qo6M8ktSe5d7lgAbNj0t5CPMV6uql9N8kCSXUnuHmM8ufTJAEiyhVAnyRjjK0m+suRZADgF35kI0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0NyWfnrem3XN3j1ZP7h/GUsD7DjOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoDmhBmhOqAGaE2qA5oQaoLndy1j08WMnsnbg/mUsDe0dPbj/dI/A24wzaoDmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaE6oAZoTaoDmhBqguU1DXVWXVdVDVfVUVT1ZVR9fxWAAzGzl51G/nOTXxxiPVNV5SQ5V1YNjjKeWPBsA2cIZ9Rjj+THGI9P2D5I8nWTvsgcDYOZNXaOuqrUk1yZ5+BT33V5V61W1/spLJxY0HgBbDnVVnZvkS0nuGGO8ePL9Y4y7xhj7xhj7dp29Z5EzAuxoWwp1VZ2RWaQ/N8b48nJHAmDeVl71UUk+m+TpMcYnlz8SAPO2ckb9/iQ/m+RDVfXo9HbzkucCYLLpy/PGGH+fpFYwCwCn4DsTAZoTaoDmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaE6oAZoTaoDmhBqgOaEGaG4rvzPxTbtm756sH9y/jKUBdhxn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0NzuZSz6+LETWTtw/zKWBmjp6MH9S1vbGTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0JxQAzQn1ADNCTVAc0IN0Nymoa6qu6vqeFU9sYqBAHi9rZxR/3GSG5c8BwBvYNNQjzH+Lsl/rGAWAE7BNWqA5hYW6qq6varWq2r9lZdOLGpZgB1vYaEeY9w1xtg3xti36+w9i1oWYMdz6QOgua28PO+eJP+Y5Kqqeq6qPrb8sQDYsHuzB4wxbl3FIACcmksfAM0JNUBzQg3QnFADNCfUAM0JNUBzQg3QnFADNCfUAM0JNUBzQg3QnFADNCfUAM1t+tPz3opr9u7J+sH9y1gaYMdxRg3QnFADNCfUAM0JNUBzQg3QnFADNCfUAM0JNUBzQg3QnFADNCfUAM0JNUBzQg3QnFADNCfUAM0JNUBzQg3QXI0xFr9o1Q+SHF74wst1UZLvne4h3gJzr5a5V2snzf3uMcbFp7pjKb+KK8nhMca+Ja29FFW1vt1mTsy9auZeLXPPuPQB0JxQAzS3rFDftaR1l2k7zpyYe9XMvVrmzpKeTARgcVz6AGhOqAGaW2ioq+rGqjpcVUeq6sAi136L89xdVcer6om5fRdW1YNV9cz0/oJpf1XV70+zf6uqrpv7b26bHv9MVd225Jkvq6qHquqpqnqyqj6+TeZ+R1V9vaoem+b+rWn/5VX18DTfF6rqzGn/WdPtI9P9a3Nr3TntP1xVP7XMuec+5q6q+mZV3bdd5q6qo1X1eFU9WlXr077Wx8n08c6vqi9W1T9V1dNVdX33uavqqunPeePtxaq6Y2VzjzEW8pZkV5JvJ7kiyZlJHkty9aLWf4szfTDJdUmemNv3O0kOTNsHkvz2tH1zkr9OUknel+Thaf+FSb4zvb9g2r5giTNfkuS6afu8JP+c5OptMHclOXfaPiPJw9M8f5bklmn/p5P80rT9y0k+PW3fkuQL0/bV07FzVpLLp2Nq1wqOlV9L8qdJ7ptut587ydEkF520r/VxMn3MP0nyi9P2mUnO3w5zz82/K8kLSd69qrkXOfz1SR6Yu31nkjtX8Qe3yVxreX2oDye5ZNq+JLNvzkmSzyS59eTHJbk1yWfm9r/ucSuY/6+S/OR2mjvJ2UkeSfJjmX131u6Tj5EkDyS5ftrePT2uTj5u5h+3xHkvTfLVJB9Kct80x3aY+2j+b6hbHydJ9iT5l0wvZNguc5806w1J/mGVcy/y0sfeJM/O3X5u2tfNu8YYz0/bLyR517T9RvOfts9r+rL62szOTtvPPV0+eDTJ8SQPZnZW+f0xxsunmOHV+ab7TyR55+mYO8nvJvmNJP8z3X5ntsfcI8nfVNWhqrp92tf9OLk8yb8l+aPpUtMfVtU522DuebckuWfaXsncO/rJxDH7J63l6xOr6twkX0pyxxjjxfn7us49xnhljPGezM5Q35vkR07vRJurqp9OcnyMceh0z/IWfGCMcV2Sm5L8SlV9cP7OpsfJ7swuR/7BGOPaJP+Z2SWDVzWdO0kyPVfx4SR/fvJ9y5x7kaE+luSyuduXTvu6+W5VXZIk0/vj0/43mn/ln1dVnZFZpD83xvjydpl7wxjj+0keyuySwflVtfEzZeZneHW+6f49Sf49q5/7/Uk+XFVHk3w+s8sfv7cN5s4Y49j0/niSv8jsH8fux8lzSZ4bYzw83f5iZuHuPveGm5I8Msb47nR7JXMvMtTfSHLl9Gz5mZl9eXDvAtdflHuTbDzTeltm14A39v/c9Gzt+5KcmL6keSDJDVV1wfSM7g3TvqWoqkry2SRPjzE+uY3mvriqzp+2fziz6+pPZxbsj7zB3Bufz0eSfG06I7k3yS3TqysuT3Jlkq8va+4xxp1jjEvHGGuZHbNfG2N8tPvcVXVOVZ23sZ3Z/98n0vw4GWO8kOTZqrpq2vUTSZ7qPvecW/PaZY+N+ZY/94Ivst+c2asUvp3kE6u4sL/JPPckeT7Jf2f2L/nHMrue+NUkzyT52yQXTo+tJJ+aZn88yb65dX4hyZHp7eeXPPMHMvvy6VtJHp3ebt4Gc/9okm9Ocz+R5Den/VdkFqwjmX25eNa0/x3T7SPT/VfMrfWJ6fM5nOSmFR4vP57XXvXReu5pvsemtyc3/r51P06mj/eeJOvTsfKXmb36YTvMfU5mXz3tmdu3krl9CzlAczv6yUSA7UCoAZoTaoDmhBqgOaEGaE6oAZoTaoDm/hfbB3VVTumTMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data_df['label'].value_counts())\n",
    "data_df['label'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "SgiD5uAdJXEm"
   },
   "outputs": [],
   "source": [
    "def loaddicchar():\n",
    "    dic = {}\n",
    "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|đ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
    "        '|')\n",
    "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|đ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "        '|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    " \n",
    " \n",
    "dicchar = loaddicchar()\n",
    " \n",
    "# Đưa toàn bộ dữ liệu qua hàm này để chuẩn hóa lại\n",
    "def convert_unicode(txt):\n",
    "    return re.sub(\n",
    "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|đ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "        lambda x: dicchar[x.group()], txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "28hSajIdAgb1"
   },
   "outputs": [],
   "source": [
    "from vncorenlp import VnCoreNLP\n",
    "rdrsegmenter = VnCoreNLP(\"./vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m') \n",
    "\n",
    "uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
    "punc_re = '[^\\w'+uniChars+']'\n",
    "def preprocess_text(sen):\n",
    "  ##Unicode reform\n",
    "  assert isinstance(sen, str), 'Not String'\n",
    "  sen = convert_unicode(sen)\n",
    "  ##Remove punctuation\n",
    "  sen = re.sub(punc_re,' ', sen)\n",
    "  ##Remove multiple space\n",
    "  sen = re.sub('\\s+',' ', sen)\n",
    "  ##Lower\n",
    "  sen = sen.lower()\n",
    "  ##Segment\n",
    "  seg = rdrsegmenter.tokenize(sen)\n",
    "  if len(seg) == 0:\n",
    "    sen = ' '\n",
    "  else: \n",
    "    sen = ' '.join(seg[0])\n",
    "  return sen\n",
    "# vec_pre = np.vectorize(preprocess_text)\n",
    "# print(vec_pre((data_df.iloc[3,3])))\n",
    "data_df['preprocess_comment'] = data_df.apply(lambda x: preprocess_text(x['Comment']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "7AGP68b2jlTj",
    "outputId": "96c14495-ae54-4d80-c1ac-a09c9d731547"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RevId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ResId</th>\n",
       "      <th>Comment</th>\n",
       "      <th>image_urls</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocess_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3648046</td>\n",
       "      <td>8920424</td>\n",
       "      <td>965165</td>\n",
       "      <td>Đặt dồi sụn của quán vì đọc comment thấy hấp d...</td>\n",
       "      <td>local1_folder-1/foody-doi-sun-pate-shop-online...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>đặt dồi sụn của quán vì đọc comment thấy hấp_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3695359</td>\n",
       "      <td>18558601</td>\n",
       "      <td>965165</td>\n",
       "      <td>Dồi khá ngon, mua về còn nóng mở ra thơm phức,...</td>\n",
       "      <td>local1_folder-1/foody-doi-sun-pate-shop-online...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>dồi khá ngon mua về còn nóng mở ra thơm_phức s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3695487</td>\n",
       "      <td>13885433</td>\n",
       "      <td>965165</td>\n",
       "      <td>Đặt xuất mỳ trộn thập cẩm, khá đầy đủ và đầy đ...</td>\n",
       "      <td>local1_folder-1/foody-doi-sun-pate-shop-online...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "      <td>đặt xuất mỳ trộn thập_cẩm khá đầy_đủ và đầy_đặ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4256913</td>\n",
       "      <td>11400976</td>\n",
       "      <td>965165</td>\n",
       "      <td>Không hiểu sao quán này được 7.9 luôn. Đặt bán...</td>\n",
       "      <td>local1_folder-1/foody-doi-sun-pate-shop-online...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "      <td>không hiểu sao quán này được 7 9 luôn đặt bánh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4246644</td>\n",
       "      <td>525112</td>\n",
       "      <td>965165</td>\n",
       "      <td>Dồi sụn bé tẹo, giá quá cao so với các quán kh...</td>\n",
       "      <td>local1_folder-1/foody-doi-sun-pate-shop-online...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dồi sụn bé tẹo giá quá cao so với các quán khá...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RevId    UserId   ResId  \\\n",
       "0  3648046   8920424  965165   \n",
       "1  3695359  18558601  965165   \n",
       "2  3695487  13885433  965165   \n",
       "3  4256913  11400976  965165   \n",
       "4  4246644    525112  965165   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  Đặt dồi sụn của quán vì đọc comment thấy hấp d...   \n",
       "1  Dồi khá ngon, mua về còn nóng mở ra thơm phức,...   \n",
       "2  Đặt xuất mỳ trộn thập cẩm, khá đầy đủ và đầy đ...   \n",
       "3  Không hiểu sao quán này được 7.9 luôn. Đặt bán...   \n",
       "4  Dồi sụn bé tẹo, giá quá cao so với các quán kh...   \n",
       "\n",
       "                                          image_urls  score  label  \\\n",
       "0  local1_folder-1/foody-doi-sun-pate-shop-online...    5.8      0   \n",
       "1  local1_folder-1/foody-doi-sun-pate-shop-online...    9.0      1   \n",
       "2  local1_folder-1/foody-doi-sun-pate-shop-online...    9.4      1   \n",
       "3  local1_folder-1/foody-doi-sun-pate-shop-online...    4.6      0   \n",
       "4  local1_folder-1/foody-doi-sun-pate-shop-online...    1.0      0   \n",
       "\n",
       "                                  preprocess_comment  \n",
       "0  đặt dồi sụn của quán vì đọc comment thấy hấp_d...  \n",
       "1  dồi khá ngon mua về còn nóng mở ra thơm_phức s...  \n",
       "2  đặt xuất mỳ trộn thập_cẩm khá đầy_đủ và đầy_đặ...  \n",
       "3  không hiểu sao quán này được 7 9 luôn đặt bánh...  \n",
       "4  dồi sụn bé tẹo giá quá cao so với các quán khá...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0MjDRAeZbrpe",
    "outputId": "62b6abe7-41b0-450a-eb83-5d25e03f8128"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df['preprocess_comment']==\" \"].shape\n",
    "# data_df.drop(data_df[data_df['preprocess_comment']==\" \"].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5t7qGKcjc8HS",
    "outputId": "3efb1572-d8bc-494d-cc79-911c341351ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4187    chưa bao_giờ phải đăng_nhập để bình_luận về đồ...\n",
       "4188    ko biết các mẹ đặt ntn nhưng hnay em có gọi su...\n",
       "4189    hôm_nay mình có vc ko đi ra ngoài ăn đc nên mì...\n",
       "4190    món iberico cắt từ đùi heo tại bàn đặc_sản của...\n",
       "Name: preprocess_comment, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df.reset_index()\n",
    "data_df['preprocess_comment'][4187:4191]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9pXfk9tBk_1",
    "outputId": "15337a24-3102-4db5-e239-38466aa2a289"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195      1\n",
       "558      1\n",
       "714      1\n",
       "1102     1\n",
       "1168     1\n",
       "1452     1\n",
       "1556     1\n",
       "1629     1\n",
       "2200     1\n",
       "2503     1\n",
       "2535     1\n",
       "2642     1\n",
       "2687     1\n",
       "3158     1\n",
       "3163     1\n",
       "3216     1\n",
       "3314     1\n",
       "3510     1\n",
       "3964     1\n",
       "3989     1\n",
       "4021     1\n",
       "4179     1\n",
       "4420     1\n",
       "4903     1\n",
       "5103     1\n",
       "6020     1\n",
       "6128     1\n",
       "6423     1\n",
       "6727     1\n",
       "7239     1\n",
       "7641     1\n",
       "7791     1\n",
       "8273     1\n",
       "8872     1\n",
       "9089     1\n",
       "9432     1\n",
       "10199    1\n",
       "10499    1\n",
       "10559    1\n",
       "10825    1\n",
       "11079    1\n",
       "12357    1\n",
       "12619    1\n",
       "13333    1\n",
       "13540    1\n",
       "13930    1\n",
       "Name: preprocess_comment, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = data_df['preprocess_comment'].str.split()\n",
    "a = a.apply(lambda x: len(x))\n",
    "a[a==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ghhFsnQZRIOx",
    "outputId": "738871be-e8bd-4daa-a25f-a6441d005ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         56\n",
       "1         43\n",
       "2         38\n",
       "3         34\n",
       "4         74\n",
       "        ... \n",
       "14164    107\n",
       "14165    185\n",
       "14166     17\n",
       "14167    319\n",
       "14168    133\n",
       "Name: preprocess_comment, Length: 14169, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uXAGoz9iQ2-0",
    "outputId": "b2d25fd1-ce31-4f08-eb56-6be297d2f662"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ổn'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Comment'][195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "v0cC4OTiRXqG",
    "outputId": "37953fe6-4a70-4659-d9b6-19775faa850e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(i.split()) for i in data_df['preprocess_comment']]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9S-CZXOtobN"
   },
   "source": [
    "# Load BPE, Vocab of PhoBERT and DataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131,
     "referenced_widgets": [
      "2f8400d957d4428b86f73a07c12a69ff",
      "b375fdd33a8f4fad9f7dcc33f24f3f7b",
      "562df45b9b7e42799e8323f7db1eaf18",
      "624a86d43249405388f1286063cebae4",
      "c9918922671546a88e3b2ee509394df3",
      "1bb3780855494b029edc7dc564fcc51e",
      "046f564c5ccc4b9f9c866a6a57b900bf",
      "49da75829cbd4350a64bfcdc04576ac1",
      "4bea41d4adb249d5afc2cbd40dc3210d",
      "08e56fb9c8c74262aa75994d2766136d",
      "ca0da54234e9446db60b5331fa076d81",
      "1250687b6c4e48e0a4b79de74f294235",
      "0cfbf06467a04d4e9f97d8fbbb9328b7",
      "16736771e702494cb52be951b3df47bc",
      "df155493042740d9b96ee0343b9f03d4",
      "70da72f327b64a8a8d2574848ddaa5c0",
      "345e16e44bad4ccf83b61099383e8b71",
      "69e00ff1b849487f9e10000b486a766c",
      "98128e9bcb0b4cf4a949d51f299b3bde",
      "302b8bb010ec40908960c26742dd4df3",
      "3f3889c16b134b408de36adb46505c40",
      "db463b1c3ae44d6980bec291e144523c",
      "2889253c1e7d4df1b02db1773a304e26",
      "876c019d15f04031af2f5735ed37a038",
      "800ec21aa4674fce95f33685c2033b11",
      "6b4ab9aa406a4071b5e888b0cd25335c",
      "82995c53c15f4166a2641b2560faa49d",
      "1e21006c0b9740ecb6f427f6a49bf409",
      "733c53bc95c0490982e6473ad1d55418",
      "3d8af058291c4c7393bb04f2f1ec2622",
      "e4cb55de261c4416b945fdb72232c12d",
      "ad4a2e90f75d49f289b127d43acca1df",
      "d63ef1d399ab42698b667b2938d7e398"
     ]
    },
    "id": "6fqLCkKLZKoO",
    "outputId": "3f9ba7ba-a6e1-48e5-b3e3-cebab77d7c3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "UEUtZY6lbnhU"
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "  input_ids = []\n",
    "  attention_masks = []\n",
    "  imgs = []\n",
    "  img_len = []\n",
    "  labels = []\n",
    "  for bt in batch:\n",
    "    input_ids.append(bt[0]['input_ids'][0])\n",
    "    attention_masks.append(bt[0]['attention_mask'][0])\n",
    "    imgs.extend(bt[1])\n",
    "    img_len.append(len(bt[1]))\n",
    "    labels.append(bt[2])\n",
    "\n",
    "  bert_tokens = torch.stack(input_ids)\n",
    "  attention_masks = torch.stack(attention_masks)\n",
    "  imgs_torch = torch.stack(imgs)\n",
    "  labels = torch.LongTensor(labels)\n",
    "\n",
    "  return  { 'input_ids': bert_tokens , 'attention_mask':attention_masks } , imgs_torch, img_len, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "NKgPUlOLlUx9"
   },
   "outputs": [],
   "source": [
    "trans = T.ToTensor()\n",
    "RANDOM_SEED = 0\n",
    "MAX_LEN = 150\n",
    "\n",
    "\n",
    "class SentimentData(Dataset):\n",
    "  def __init__(self, data, transform = None):\n",
    "    self.df = data.reset_index(drop=True)\n",
    "    self.transform = transform\n",
    "  def __len__(self):\n",
    "    # print('Size',len(self.df))\n",
    "    return len(self.df)  \n",
    "  def __getitem__(self,idx):\n",
    "    text = self.df[\"preprocess_comment\"][idx]\n",
    "    text = tokenizer(text, padding='max_length', truncation=True, max_length = MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "    img_list = []\n",
    "    for path in self.df['image_urls'][idx].split(\",\"):\n",
    "#       img_path = '/' + path.split('/')[-1]\n",
    "      img = Image.open(data_zip.open(path))\n",
    "      if self.transform is not None:\n",
    "        img = self.transform(img)\n",
    "      img_list.append(img)\n",
    "\n",
    "    # print(text.shape)\n",
    "    # text = ' '.join(text[0])\n",
    "    label = self.df[\"label\"][idx]\n",
    "\n",
    "    return (text, img_list, label)\n",
    "\n",
    "class SentimentDataModule(pl.LightningDataModule):\n",
    "    \n",
    "  def __init__(self, data, batch_size: int = 8, test_size = 0.2):\n",
    "      super().__init__()\n",
    "      self.test_size = test_size\n",
    "      self.data = data\n",
    "      self.batch_size = batch_size\n",
    "      self.train_data = ''\n",
    "      self.val_data = ''\n",
    "      self.test_data = ''\n",
    "\n",
    "  def prepare_data(self):\n",
    "      self.train_data, self.val_data = train_test_split(self.data, test_size = self.test_size, random_state=RANDOM_SEED, stratify = self.data['label'])\n",
    "      self.test_data, self.val_data = train_test_split(self.val_data,test_size = 0.5, random_state=RANDOM_SEED, stratify = self.val_data['label'])\n",
    "      print(self.data['label'].value_counts())\n",
    "      print(self.train_data['label'].value_counts())\n",
    "      print(self.val_data['label'].value_counts())\n",
    "      print(self.test_data['label'].value_counts())\n",
    "\n",
    "  def setup(self, stage = None):\n",
    "      train_transform = T.Compose([\n",
    "       T.Resize([299, 299]), T.RandomHorizontalFlip(), T.RandomRotation(10),\n",
    "        T.ToTensor(),\n",
    "      ])\n",
    "      val_transform = T.Compose([\n",
    "        T.Resize([299, 299]), T.ToTensor(),\n",
    "        # T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #             std=[0.229, 0.224, 0.225])\n",
    "      ])\n",
    "      test_transform = T.Compose([\n",
    "        T.Resize([299, 299]), T.ToTensor(),\n",
    "        # T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #             std=[0.229, 0.224, 0.225])\n",
    "      ])\n",
    "      self.train = SentimentData(self.train_data, train_transform)\n",
    "      self.val = SentimentData(self.val_data, val_transform)\n",
    "      self.test = SentimentData(self.test_data, test_transform)\n",
    "\n",
    "\n",
    "  def train_dataloader(self):\n",
    "      return DataLoader(self.train, batch_size=self.batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "  def val_dataloader(self):\n",
    "      return DataLoader(self.val, batch_size=self.batch_size, collate_fn=collate_batch)\n",
    "\n",
    "  def test_dataloader(self):\n",
    "      return DataLoader(self.test, batch_size=self.batch_size, collate_fn=collate_batch)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbSBBPTGf8d4",
    "outputId": "797072df-fabd-4599-a19d-7c3ad9236ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6952\n",
      "2    4194\n",
      "0    3023\n",
      "Name: label, dtype: int64\n",
      "1    5562\n",
      "2    3355\n",
      "0    2418\n",
      "Name: label, dtype: int64\n",
      "1    695\n",
      "2    419\n",
      "0    303\n",
      "Name: label, dtype: int64\n",
      "1    695\n",
      "2    420\n",
      "0    302\n",
      "Name: label, dtype: int64\n",
      "0\n",
      "torch.Size([8, 150])\n",
      "torch.Size([12, 3, 299, 299])\n",
      "12\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Do some Test with data\n",
    "if __name__ == \"__main__\":\n",
    "  dm = SentimentDataModule(data_df)\n",
    "  dm.prepare_data()\n",
    "  dm.setup()\n",
    "  for step, bat in enumerate(dm.train_dataloader()):\n",
    "    if step > 0: break\n",
    "    print(step)\n",
    "    print(bat[0]['input_ids'].shape)\n",
    "    print(bat[1].shape)\n",
    "    print(sum(bat[2]))\n",
    "    print(len(bat[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qiJlzVNbZ7f7",
    "outputId": "5243a986-b1f1-449c-bb6c-2cdd1a314eb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation device: cuda:1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Computation device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FknwjXWwJfkL"
   },
   "source": [
    "# PhoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "u9BWfj8BGmN5"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaModel, RobertaConfig, AdamW, AutoModel\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "pretrained_config_path = \"/content/drive/MyDrive/NLP/PhoBERT_base_transformers/config.json\"\n",
    "pretrained_model_path = \"/content/drive/MyDrive/NLP/PhoBERT_base_transformers/model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert_Lstm(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Bert_Lstm, self).__init__()\n",
    "    self.config = RobertaConfig.from_pretrained(\n",
    "    'vinai/phobert-base', from_tf=False, output_hidden_states=False)\n",
    "\n",
    "    self.PhoBERT = RobertaModel.from_pretrained(\n",
    "    'vinai/phobert-base',\n",
    "    config=self.config )\n",
    "\n",
    "    # self.lstm = nn.LSTM(input_size=768, hidden_size=128, num_layers= 1, batch_first=True)\n",
    "    self.dense = nn.Linear(768, 768)\n",
    "    self.dense1 = nn.Linear(768, 128)\n",
    "    self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "  \n",
    "  def forward(self, texts):\n",
    "    bert_out = self.PhoBERT(texts['input_ids'],token_type_ids=None, attention_mask = texts['attention_mask'])\n",
    "    bert_out = bert_out['last_hidden_state'][:,0,:]\n",
    "    x = self.dropout(bert_out)\n",
    "    x = self.dense(x)\n",
    "    x = torch.tanh(x)\n",
    "    x = self.dropout(x)\n",
    "    feature_extract = self.dense1(x)\n",
    "\n",
    "    # out, _ = self.lstm(bert_out)\n",
    "    # feature_extract = out[:,-1,:].contiguous()\n",
    "\n",
    "    return feature_extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "f0oZbzl0rb1F"
   },
   "outputs": [],
   "source": [
    "# # This time, the output's 2nd dimension is 3, indicating that there were 3 outputs given by the LSTM. \n",
    "# # This corresponds to the length of our input sequence. \n",
    "# # For the use cases where we'll need an output at every time step (many-to-many), such as Text Generation, the output of each time step can be extracted directly from the 2nd dimension and fed into a fully connected layer. \n",
    "# # For text classification tasks (many-to-one), such as Sentiment Analysis, the last output can be taken to be fed into a classifier.\n",
    "\n",
    "# pho_test = Bert_Lstm()\n",
    "# pho_test\n",
    "# # oooo = pho_test('iiii')\n",
    "# for name, child in pho_test.named_children():\n",
    "#   print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzr3M8PIIo6m"
   },
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "O-70eEW4KtHd"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Inception,self).__init__()\n",
    "    self.incept = inception_v3(pretrained = True,progress = True,aux_logits= False,transform_input = False)\n",
    "    self.incept_sequen = nn.Sequential(*list(self.incept.children())[:-3])\n",
    "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "    self.drop = nn.Dropout(p=0.4)\n",
    "#     self.flat = nn.Linear(2048, 128)\n",
    "    self.ffn = nn.Sequential(\n",
    "                nn.Linear(2048, 512),\n",
    "                nn.ReLU(),\n",
    "    #             nn.Dropout(0.1),\n",
    "                nn.Linear(512, 128),\n",
    "    #             nn.ReLU(),\n",
    "    #             nn.Dropout(0.2),\n",
    "                # nn.Linear(128, 3),\n",
    "            )\n",
    "\n",
    "  def process(self, feature, len_img_list):\n",
    "    max_fea = torch.zeros(len(len_img_list), 2048, feature.shape[-1], feature.shape[-1]).to(device)\n",
    "    start = 0\n",
    "    for idx, num in enumerate(len_img_list):\n",
    "      max_fea[idx] = feature[start:start+num].max(0)[0]\n",
    "      start += num\n",
    "\n",
    "    return max_fea\n",
    "  \n",
    "\n",
    "  def forward(self, image, len_img_list):\n",
    "    feature = self.incept_sequen(image)\n",
    "    feature = self.process(feature, len_img_list)\n",
    "    feature = self.avgpool(feature)\n",
    "    feature = self.drop(feature)\n",
    "\n",
    "    img_fea = feature.reshape(-1, 2048)\n",
    "    out = self.ffn(img_fea)\n",
    "\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inc = inception_v3(pretrained = True,progress = True,aux_logits= False,transform_input = False)\n",
    "# inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incept_sequen = nn.Sequential(*list(inc.children())[:-3])\n",
    "# incept_sequen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "owCLI2adVEoV"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras import models\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# basemodel = InceptionV3(weights='imagenet', include_top=False, input_tensor=layers.Input(shape=(299, 299, 3)))\n",
    "# x = basemodel.output\n",
    "# # t = layers.AveragePooling2D(pool_size=(8, 8), name='AVG_Pooling')(x)\n",
    "# model_cnn = Model(basemodel.input, x)\n",
    "\n",
    "# basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "U0E4iJyHdDUN"
   },
   "outputs": [],
   "source": [
    "# ou = model_cnn(np.random.rand(1,299,299,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "r7_2g1eNhBWe"
   },
   "outputs": [],
   "source": [
    "# ou.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEsEq9RHfbCV"
   },
   "source": [
    "# Multimodal (no pytorch-lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "hmIwJsEOlt8h"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/mrtrongmodel-06/04')\n",
    "\n",
    "class LRScheduler():\n",
    "    def __init__(\n",
    "        self, optimizer, patience=1, min_lr=1e-6, factor=0.1\n",
    "    ):\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.factor = factor\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
    "                self.optimizer,\n",
    "                mode='max',\n",
    "                patience=self.patience,\n",
    "                factor=self.factor,\n",
    "                min_lr=self.min_lr,\n",
    "                verbose=True\n",
    "            )\n",
    "    def __call__(self, val_loss):\n",
    "        self.lr_scheduler.step(val_loss)\n",
    "\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            # reset counter if validation loss improves\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print('INFO: Early stopping')\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "mGO97xYhcuNV"
   },
   "outputs": [],
   "source": [
    "class Concatmodal(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Concatmodal,self).__init__()\n",
    "    # self.loss_module = nn.CrossEntropyLoss()\n",
    "    self.BERT = Bert_Lstm()\n",
    "    self.incept = Inception()\n",
    "    self.dense = nn.Linear(256,256)\n",
    "    self.cl = nn.Linear(256,3)\n",
    "    # self.bpe_path = \"/content/drive/MyDrive/NLP/PhoBERT_base_transformers/bpe.codes\"\n",
    "    # self.vocab_path = \"/content/drive/MyDrive/NLP/PhoBERT_base_transformers/dict.txt\"\n",
    "  \n",
    "  def forward(self, image, inputs, len_img_list, labels=None):\n",
    "    for key in inputs:\n",
    "        inputs[key] = inputs[key].to(device)\n",
    "    image = image.to(device)\n",
    "\n",
    "    fea1 = self.BERT(inputs)\n",
    "    fea2 = self.incept(image, len_img_list)\n",
    "    cat = torch.cat((fea1, fea2), 1)\n",
    "    out = self.cl(cat)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "BWqjbaCdq6nz"
   },
   "outputs": [],
   "source": [
    "def fit(model, dm, criterion, optimizer, epoch):\n",
    "  running_loss = 0.0\n",
    "  train_running_loss = 0.0\n",
    "  # running_correct = 0\n",
    "  reporting_step = 100\n",
    "\n",
    "  counter = 0\n",
    "  # total = 0\n",
    "  soft_m = nn.Softmax(dim=-1)\n",
    "\n",
    "  model.train()\n",
    "  train_preds = np.array([])\n",
    "  train_labels = np.array([])\n",
    "\n",
    "  for i, (texts, images, len_img_list, labels) in enumerate(dm.train_dataloader()):\n",
    "      counter += 1\n",
    "      labels = labels.to(device)\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(images, texts, len_img_list)\n",
    "      loss = criterion(outputs, labels)\n",
    "      output_scores = soft_m(outputs)\n",
    "      predictions = torch.argmax(output_scores, dim=-1)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.item()\n",
    "      train_running_loss += loss.item()\n",
    "      # _, preds = torch.max(outputs.data, 1)\n",
    "      predictions = torch.argmax(output_scores, dim=-1)\n",
    "\n",
    "      predictions = predictions.cpu().numpy()\n",
    "      labels = labels.cpu().numpy()\n",
    "      # _, preds = torch.max(outputs.data, 1)\n",
    "      train_preds = np.concatenate((train_preds, predictions), axis=0)\n",
    "      train_labels = np.concatenate((train_labels, labels), axis=0)\n",
    "\n",
    "      if i % reporting_step == reporting_step-1:\n",
    "            print(f\"Epoch {epoch} Step {i} ave_loss {running_loss/reporting_step:0.4f}\")\n",
    "            running_loss = 0.0\n",
    "            \n",
    "  train_loss = train_running_loss / counter\n",
    "  reports = classification_report(train_labels, train_preds, output_dict=True)\n",
    "  print(confusion_matrix(train_labels, train_preds))\n",
    "  train_f1 = classification_report(train_labels, train_preds, output_dict=True)['macro avg']['f1-score']\n",
    "  train_ac = accuracy_score(train_labels, train_preds)\n",
    "\n",
    "    \n",
    "#   writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "#   writer.add_scalar(\"macro-f1/train\", reports['macro avg']['f1-score'], epoch)\n",
    "#   writer.add_scalar(\"Acc/train\", train_ac, epoch)\n",
    "\n",
    "\n",
    "  return train_loss, train_ac, train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Fu5J5PqcvamM"
   },
   "outputs": [],
   "source": [
    "def validation(model, dm, criterion):\n",
    "  model.eval()\n",
    "  val_running_loss = 0.0\n",
    "  val_preds = np.array([])\n",
    "  val_labels = np.array([])\n",
    "\n",
    "  soft_m = nn.Softmax(dim=-1)\n",
    "\n",
    "  counter = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for i, (texts, images, len_img_list, labels) in enumerate(dm.val_dataloader()):\n",
    "        counter += 1\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images, texts, len_img_list)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        output_scores = soft_m(outputs)\n",
    "        predictions = torch.argmax(output_scores, dim=-1)\n",
    "\n",
    "        val_running_loss += loss.item()\n",
    "        \n",
    "        predictions = predictions.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        val_preds = np.concatenate((val_preds, predictions), axis=0)\n",
    "        val_labels = np.concatenate((val_labels, labels), axis=0)\n",
    "    \n",
    "\n",
    "  val_loss = val_running_loss / counter\n",
    "  print(classification_report(val_labels, val_preds))\n",
    "  print(confusion_matrix(val_labels, val_preds))\n",
    "  val_ac = accuracy_score(val_labels, val_preds)\n",
    "  val_f1 = classification_report(val_labels, val_preds, output_dict=True)['macro avg']['f1-score']\n",
    "\n",
    "#   writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "#   writer.add_scalar(\"Acc/val\", val_ac, epoch)\n",
    "#   writer.add_scalar(\"macro-f1/val\", val_f1, epoch)\n",
    "  \n",
    "  return val_loss, val_ac, val_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "eC6cw0Ywqgb_"
   },
   "outputs": [],
   "source": [
    "\n",
    "def testing(model, dm):\n",
    "  model.eval()\n",
    "  test_running_loss = 0.0\n",
    "  counter = 0\n",
    "  test_preds = torch.tensor([], device=device)\n",
    "  test_labels = torch.tensor([], device = device)\n",
    "\n",
    "  soft_m = nn.Softmax(dim=-1)\n",
    "\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for i, (texts, images, inputs, labels) in enumerate(dm.test_dataloader()):\n",
    "        counter += 1\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images, texts, inputs)\n",
    "\n",
    "        output_scores = soft_m(outputs)\n",
    "        predictions = torch.argmax(output_scores, dim=-1)\n",
    "\n",
    "        test_preds = torch.cat((test_preds, predictions), dim=0)\n",
    "        test_labels = torch.cat((test_labels, labels), dim=0)\n",
    "\n",
    "        # loss = criterion(outputs, labels)\n",
    "        # test_running_loss += loss.item()\n",
    "    \n",
    "  test_preds = test_preds.cpu().numpy()\n",
    "  test_labels = test_labels.cpu().numpy()\n",
    "       \n",
    "  print('test', classification_report(test_labels, test_preds))\n",
    "  print('test_ac', accuracy_score(test_labels, test_preds))\n",
    "  print('Confusion', confusion_matrix(test_labels, test_preds))\n",
    "  print('Macro_f1', classification_report(test_labels, test_preds, output_dict=True)['macro avg']['f1-score'])\n",
    "  \n",
    "  # test_loss = test_running_loss / counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "vbONbjzw0zLY"
   },
   "outputs": [],
   "source": [
    "# (t, i ,l) = next(iter(dm.train_dataloader()))\n",
    "# mo = Concatmodal()\n",
    "# ou = mo(i, t)\n",
    "# print(ou)\n",
    "# sf = nn.Softmax(dim=-1)\n",
    "# ou = sf(ou)\n",
    "# print(ou)\n",
    "# ou = torch.argmax(ou, dim=-1)\n",
    "# print(ou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "_J90rwZ6OPkF"
   },
   "outputs": [],
   "source": [
    "# testing(mo, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "QGsSjernAIOG"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename='my_checkpoint_multi_modal_mrTrong_unfreeze_weight.pth.tar'):\n",
    "    print('Saving....'+ filename)\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint1(state, filename='my_checkpoint_multi_modal_mrTrong_unfreeze_f1_weight.pth.tar'):\n",
    "    print('Saving....'+ filename)\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-I_Y6mlANvK",
    "outputId": "958dec5d-6e4f-48ec-de58-5a582d4481b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception-Copy1.ipynb\r\n",
      "Inception.ipynb\r\n",
      "\u001b[0m\u001b[01;31mlocal1_folder_temp.zip\u001b[0m\r\n",
      "\u001b[01;31mlocal1_folder.zip\u001b[0m\r\n",
      "Multimodal.ipynb\r\n",
      "Multimodal_newmodel.ipynb\r\n",
      "Multimodal_newmodel-weight.ipynb\r\n",
      "\u001b[01;31mmy_checkpoint_incept_seed0_bt16_fc_1e-3_1_nofreeze.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_incept_seed0_bt16_fc_1e-3_1.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_incept_seed0_bt16_fc_1e-3.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_incept_seed0_bt16_fc_only2048_1e-4_freeze.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_multi_modal_mrTrong_freeze_continue_10epoch.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_multi_modal_mrTrong_freeze_f1.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_multi_modal_mrTrong_freeze_f1_weight.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_multi_modal_mrTrong_freeze.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_multi_modal_mrTrong_freeze_weight.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_multivoting_freeze_20.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_multivoting_freeze_new_20_af_unfreeze.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_multivoting_freeze_new_20.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_resnet34_seed0_bt16_fc_5e-4.pth.tar\u001b[0m\r\n",
      "\u001b[01;31mmy_checkpoint_resnet_seed0_bt16_fc_1e-3.pth.tar\u001b[0m\r\n",
      "\u001b[01;34mOUTPUT\u001b[0m/\r\n",
      "PhoBERT_foody.ipynb\r\n",
      "Resnet.ipynb\r\n",
      "\u001b[01;34mruns\u001b[0m/\r\n",
      "\u001b[01;34mvncorenlp\u001b[0m/\r\n",
      "VotingMultimodal.ipynb\r\n",
      "VotingMultimodal_newmodel.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "tUOcHfHQzPvb"
   },
   "outputs": [],
   "source": [
    "# model = Concatmodal()\n",
    "# total_params = sum(p.numel() for p in model.parameters())\n",
    "# print(f\"{total_params:,} total parameters.\")\n",
    "# total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# print(f\"{total_trainable_params:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "bakUYVqazYM6"
   },
   "outputs": [],
   "source": [
    "def freeze(model):  \n",
    "  for param in model.BERT.PhoBERT.parameters():\n",
    "    param.requires_grad = False\n",
    "  for param in model.incept.incept.parameters():\n",
    "    param.requires_grad = False\n",
    "  return model\n",
    "\n",
    "def unfreeze(model):  \n",
    "  for param in model.BERT.PhoBERT.parameters():\n",
    "    param.requires_grad = True\n",
    "  for param in model.incept.incept.parameters():\n",
    "    param.requires_grad = True\n",
    "    # print(param)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "83GHcVAuzodA"
   },
   "outputs": [],
   "source": [
    "# total_params = sum(p.numel() for p in model.parameters())\n",
    "# print(f\"{total_params:,} total parameters.\")\n",
    "# total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# print(f\"{total_trainable_params:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# del model\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights=compute_class_weight(class_weight='balanced', classes=np.unique(dm.train_data['label']), y=dm.train_data['label'])\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Concatmodal(\n",
       "  (BERT): Bert_Lstm(\n",
       "    (PhoBERT): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dense1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (incept): Inception(\n",
       "    (incept): Inception3(\n",
       "      (Conv2d_1a_3x3): BasicConv2d(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (Conv2d_2a_3x3): BasicConv2d(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (Conv2d_2b_3x3): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (Conv2d_3b_1x1): BasicConv2d(\n",
       "        (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (Conv2d_4a_3x3): BasicConv2d(\n",
       "        (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (Mixed_5b): InceptionA(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch5x5_1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch5x5_2): BasicConv2d(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (Mixed_5c): InceptionA(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch5x5_1): BasicConv2d(\n",
       "          (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch5x5_2): BasicConv2d(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (Mixed_5d): InceptionA(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch5x5_1): BasicConv2d(\n",
       "          (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch5x5_2): BasicConv2d(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (Mixed_6a): InceptionB(\n",
       "        (branch3x3): BasicConv2d(\n",
       "          (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (Mixed_6b): InceptionC(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_3): BasicConv2d(\n",
       "          (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_4): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_5): BasicConv2d(\n",
       "          (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (Mixed_6c): InceptionC(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_2): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_3): BasicConv2d(\n",
       "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_4): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_5): BasicConv2d(\n",
       "          (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (Mixed_6d): InceptionC(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_2): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_3): BasicConv2d(\n",
       "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_4): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_5): BasicConv2d(\n",
       "          (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (Mixed_6e): InceptionC(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_3): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_4): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_5): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (AuxLogits): None\n",
       "      (Mixed_7a): InceptionD(\n",
       "        (branch3x3_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7x3_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7x3_2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7x3_3): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7x3_4): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (Mixed_7b): InceptionE(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_1): BasicConv2d(\n",
       "          (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_2a): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_2b): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3a): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3b): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (Mixed_7c): InceptionE(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_1): BasicConv2d(\n",
       "          (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_2a): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_2b): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3a): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3b): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    )\n",
       "    (incept_sequen): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): BasicConv2d(\n",
       "        (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicConv2d(\n",
       "        (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): InceptionA(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch5x5_1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch5x5_2): BasicConv2d(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): InceptionA(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch5x5_1): BasicConv2d(\n",
       "          (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch5x5_2): BasicConv2d(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): InceptionA(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch5x5_1): BasicConv2d(\n",
       "          (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch5x5_2): BasicConv2d(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): InceptionB(\n",
       "        (branch3x3): BasicConv2d(\n",
       "          (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): InceptionC(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_3): BasicConv2d(\n",
       "          (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_4): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_5): BasicConv2d(\n",
       "          (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): InceptionC(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_2): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_3): BasicConv2d(\n",
       "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_4): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_5): BasicConv2d(\n",
       "          (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): InceptionC(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_2): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_3): BasicConv2d(\n",
       "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_4): BasicConv2d(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_5): BasicConv2d(\n",
       "          (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): InceptionC(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7_3): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_3): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_4): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7dbl_5): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): InceptionD(\n",
       "        (branch3x3_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7x3_1): BasicConv2d(\n",
       "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7x3_2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7x3_3): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch7x7x3_4): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): InceptionE(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_1): BasicConv2d(\n",
       "          (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_2a): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_2b): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3a): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3b): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): InceptionE(\n",
       "        (branch1x1): BasicConv2d(\n",
       "          (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_1): BasicConv2d(\n",
       "          (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_2a): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3_2b): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_1): BasicConv2d(\n",
       "          (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_2): BasicConv2d(\n",
       "          (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3a): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch3x3dbl_3b): BasicConv2d(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch_pool): BasicConv2d(\n",
       "          (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (drop): Dropout(p=0.4, inplace=False)\n",
       "    (ffn): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (cl): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Concatmodal()\n",
    "model = freeze(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "7mSKvEYdVLGV",
    "outputId": "304f54d4-de09-4cfb-81a8-453bf339bcdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160,703,179 total parameters.\n",
      "1,870,339 training parameters.\n",
      "Epoch 0 of 20\n",
      "Epoch 0 Step 99 ave_loss 0.9383\n",
      "Epoch 0 Step 199 ave_loss 0.8249\n",
      "Epoch 0 Step 299 ave_loss 0.7759\n",
      "Epoch 0 Step 399 ave_loss 0.8018\n",
      "Epoch 0 Step 499 ave_loss 0.7590\n",
      "Epoch 0 Step 599 ave_loss 0.7828\n",
      "Epoch 0 Step 699 ave_loss 0.7869\n",
      "[[1804  269  345]\n",
      " [ 614 3399 1549]\n",
      " [ 521  986 1848]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.89      0.69       303\n",
      "         1.0       0.82      0.61      0.70       695\n",
      "         2.0       0.56      0.56      0.56       419\n",
      "\n",
      "    accuracy                           0.65      1417\n",
      "   macro avg       0.65      0.69      0.65      1417\n",
      "weighted avg       0.69      0.65      0.65      1417\n",
      "\n",
      "[[271  15  17]\n",
      " [107 422 166]\n",
      " [110  76 233]]\n",
      "Train Loss: 0.8080\n",
      "Train acc: 0.6221\n",
      "Val Loss: 0.6953\n",
      "Val Acc: 0.6535\n",
      "Better ver saved\n",
      "Saving....my_checkpoint_multi_modal_mrTrong_freeze_weight.pth.tar\n",
      "Better f1 ver saved\n",
      "Saving....my_checkpoint_multi_modal_mrTrong_freeze_f1_weight.pth.tar\n",
      "Epoch 1 of 20\n",
      "Epoch 1 Step 99 ave_loss 0.7507\n",
      "Epoch 1 Step 199 ave_loss 0.7495\n",
      "Epoch 1 Step 299 ave_loss 0.7960\n",
      "Epoch 1 Step 399 ave_loss 0.7468\n",
      "Epoch 1 Step 499 ave_loss 0.7518\n",
      "Epoch 1 Step 599 ave_loss 0.7870\n",
      "Epoch 1 Step 699 ave_loss 0.7638\n",
      "[[1891  216  311]\n",
      " [ 515 3632 1415]\n",
      " [ 465  952 1938]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.85      0.75       303\n",
      "         1.0       0.86      0.51      0.64       695\n",
      "         2.0       0.52      0.77      0.62       419\n",
      "\n",
      "    accuracy                           0.66      1417\n",
      "   macro avg       0.68      0.71      0.67      1417\n",
      "weighted avg       0.72      0.66      0.66      1417\n",
      "\n",
      "[[257  11  35]\n",
      " [ 73 355 267]\n",
      " [ 49  47 323]]\n",
      "Train Loss: 0.7640\n",
      "Train acc: 0.6582\n",
      "Val Loss: 0.6839\n",
      "Val Acc: 0.6598\n",
      "Better ver saved\n",
      "Saving....my_checkpoint_multi_modal_mrTrong_freeze_weight.pth.tar\n",
      "Better f1 ver saved\n",
      "Saving....my_checkpoint_multi_modal_mrTrong_freeze_f1_weight.pth.tar\n",
      "Epoch 2 of 20\n",
      "Epoch 2 Step 99 ave_loss 0.7194\n",
      "Epoch 2 Step 199 ave_loss 0.7714\n",
      "Epoch 2 Step 299 ave_loss 0.7417\n",
      "Epoch 2 Step 399 ave_loss 0.7706\n",
      "Epoch 2 Step 499 ave_loss 0.7534\n",
      "Epoch 2 Step 599 ave_loss 0.7707\n",
      "Epoch 2 Step 699 ave_loss 0.7576\n",
      "[[1863  227  328]\n",
      " [ 462 3666 1434]\n",
      " [ 445  904 2006]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.86      0.76       303\n",
      "         1.0       0.80      0.74      0.77       695\n",
      "         2.0       0.60      0.55      0.58       419\n",
      "\n",
      "    accuracy                           0.71      1417\n",
      "   macro avg       0.69      0.72      0.70      1417\n",
      "weighted avg       0.71      0.71      0.71      1417\n",
      "\n",
      "[[262  18  23]\n",
      " [ 53 513 129]\n",
      " [ 73 114 232]]\n",
      "Train Loss: 0.7553\n",
      "Train acc: 0.6648\n",
      "Val Loss: 0.6452\n",
      "Val Acc: 0.7107\n",
      "Better ver saved\n",
      "Saving....my_checkpoint_multi_modal_mrTrong_freeze_weight.pth.tar\n",
      "Better f1 ver saved\n",
      "Saving....my_checkpoint_multi_modal_mrTrong_freeze_f1_weight.pth.tar\n",
      "Epoch 3 of 20\n",
      "Epoch 3 Step 99 ave_loss 0.7325\n",
      "Epoch 3 Step 199 ave_loss 0.7564\n",
      "Epoch 3 Step 299 ave_loss 0.7086\n",
      "Epoch 3 Step 399 ave_loss 0.7399\n",
      "Epoch 3 Step 499 ave_loss 0.7201\n",
      "Epoch 3 Step 599 ave_loss 0.7326\n",
      "Epoch 3 Step 699 ave_loss 0.7532\n",
      "[[1896  224  298]\n",
      " [ 433 3723 1406]\n",
      " [ 428  902 2025]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.83      0.79       303\n",
      "         1.0       0.83      0.62      0.71       695\n",
      "         2.0       0.54      0.74      0.63       419\n",
      "\n",
      "    accuracy                           0.70      1417\n",
      "   macro avg       0.71      0.73      0.71      1417\n",
      "weighted avg       0.73      0.70      0.70      1417\n",
      "\n",
      "[[250  16  37]\n",
      " [ 40 430 225]\n",
      " [ 37  70 312]]\n",
      "Train Loss: 0.7332\n",
      "Train acc: 0.6744\n",
      "Val Loss: 0.6374\n",
      "Val Acc: 0.7001\n",
      "Better ver saved\n",
      "Saving....my_checkpoint_multi_modal_mrTrong_freeze_weight.pth.tar\n",
      "Better f1 ver saved\n",
      "Saving....my_checkpoint_multi_modal_mrTrong_freeze_f1_weight.pth.tar\n",
      "Epoch 4 of 20\n",
      "Epoch 4 Step 99 ave_loss 0.7207\n",
      "Epoch 4 Step 199 ave_loss 0.7557\n",
      "Epoch 4 Step 299 ave_loss 0.7028\n",
      "Epoch 4 Step 399 ave_loss 0.7531\n",
      "Epoch 4 Step 499 ave_loss 0.7271\n",
      "Epoch 4 Step 599 ave_loss 0.7423\n",
      "Epoch 4 Step 699 ave_loss 0.7535\n",
      "[[1834  247  337]\n",
      " [ 424 3746 1392]\n",
      " [ 436  900 2019]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.78      0.80       303\n",
      "         1.0       0.75      0.85      0.80       695\n",
      "         2.0       0.68      0.56      0.61       419\n",
      "\n",
      "    accuracy                           0.75      1417\n",
      "   macro avg       0.75      0.73      0.74      1417\n",
      "weighted avg       0.75      0.75      0.74      1417\n",
      "\n",
      "[[237  34  32]\n",
      " [ 27 592  76]\n",
      " [ 25 161 233]]\n",
      "INFO: Early stopping counter 1 of 5\n",
      "Train Loss: 0.7391\n",
      "Train acc: 0.6704\n",
      "Val Loss: 0.6757\n",
      "Val Acc: 0.7495\n",
      "Better f1 ver saved\n",
      "Saving....my_checkpoint_multi_modal_mrTrong_freeze_f1_weight.pth.tar\n",
      "Epoch 5 of 20\n",
      "Epoch 5 Step 99 ave_loss 0.7113\n",
      "Epoch 5 Step 199 ave_loss 0.7212\n",
      "Epoch 5 Step 299 ave_loss 0.7392\n",
      "Epoch 5 Step 399 ave_loss 0.7572\n",
      "Epoch 5 Step 499 ave_loss 0.7142\n",
      "Epoch 5 Step 599 ave_loss 0.7319\n",
      "Epoch 5 Step 699 ave_loss 0.7392\n",
      "[[1849  242  327]\n",
      " [ 407 3740 1415]\n",
      " [ 413  932 2010]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.77      0.79       303\n",
      "         1.0       0.78      0.78      0.78       695\n",
      "         2.0       0.61      0.64      0.63       419\n",
      "\n",
      "    accuracy                           0.74      1417\n",
      "   macro avg       0.74      0.73      0.73      1417\n",
      "weighted avg       0.74      0.74      0.74      1417\n",
      "\n",
      "[[233  31  39]\n",
      " [ 24 540 131]\n",
      " [ 29 121 269]]\n",
      "INFO: Early stopping counter 2 of 5\n",
      "Train Loss: 0.7321\n",
      "Train acc: 0.6704\n",
      "Val Loss: 0.6442\n",
      "Val Acc: 0.7354\n",
      "Epoch 6 of 20\n",
      "Epoch 6 Step 99 ave_loss 0.7353\n",
      "Epoch 6 Step 199 ave_loss 0.7479\n",
      "Epoch 6 Step 299 ave_loss 0.6983\n",
      "Epoch 6 Step 399 ave_loss 0.7449\n",
      "Epoch 6 Step 499 ave_loss 0.6861\n",
      "Epoch 6 Step 599 ave_loss 0.7101\n",
      "Epoch 6 Step 699 ave_loss 0.7303\n",
      "[[1873  228  317]\n",
      " [ 384 3774 1404]\n",
      " [ 407  916 2032]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.80      0.79       303\n",
      "         1.0       0.76      0.83      0.79       695\n",
      "         2.0       0.67      0.57      0.61       419\n",
      "\n",
      "    accuracy                           0.74      1417\n",
      "   macro avg       0.74      0.73      0.73      1417\n",
      "weighted avg       0.74      0.74      0.74      1417\n",
      "\n",
      "[[241  31  31]\n",
      " [ 34 576  85]\n",
      " [ 34 148 237]]\n",
      "INFO: Early stopping counter 3 of 5\n",
      "Train Loss: 0.7232\n",
      "Train acc: 0.6775\n",
      "Val Loss: 0.6375\n",
      "Val Acc: 0.7438\n",
      "Epoch 7 of 20\n",
      "Epoch 7 Step 99 ave_loss 0.6972\n",
      "Epoch 7 Step 199 ave_loss 0.6976\n",
      "Epoch 7 Step 299 ave_loss 0.7286\n",
      "Epoch 7 Step 399 ave_loss 0.7395\n",
      "Epoch 7 Step 499 ave_loss 0.7015\n",
      "Epoch 7 Step 599 ave_loss 0.6707\n",
      "Epoch 7 Step 699 ave_loss 0.7336\n",
      "[[1877  233  308]\n",
      " [ 388 3825 1349]\n",
      " [ 388  919 2048]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.90      0.70       303\n",
      "         1.0       0.81      0.70      0.75       695\n",
      "         2.0       0.61      0.50      0.55       419\n",
      "\n",
      "    accuracy                           0.68      1417\n",
      "   macro avg       0.66      0.70      0.67      1417\n",
      "weighted avg       0.70      0.68      0.68      1417\n",
      "\n",
      "[[272  16  15]\n",
      " [ 90 484 121]\n",
      " [113  96 210]]\n",
      "INFO: Early stopping counter 4 of 5\n",
      "Train Loss: 0.7093\n",
      "Train acc: 0.6837\n",
      "Val Loss: 0.6786\n",
      "Val Acc: 0.6817\n",
      "Epoch 8 of 20\n",
      "Epoch 8 Step 99 ave_loss 0.7078\n",
      "Epoch 8 Step 199 ave_loss 0.7049\n",
      "Epoch 8 Step 299 ave_loss 0.7357\n",
      "Epoch 8 Step 399 ave_loss 0.7438\n",
      "Epoch 8 Step 499 ave_loss 0.6908\n",
      "Epoch 8 Step 599 ave_loss 0.7260\n",
      "Epoch 8 Step 699 ave_loss 0.7045\n",
      "[[1881  215  322]\n",
      " [ 407 3795 1360]\n",
      " [ 398  947 2010]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.81      0.80       303\n",
      "         1.0       0.89      0.46      0.61       695\n",
      "         2.0       0.48      0.86      0.62       419\n",
      "\n",
      "    accuracy                           0.65      1417\n",
      "   macro avg       0.72      0.71      0.67      1417\n",
      "weighted avg       0.75      0.65      0.65      1417\n",
      "\n",
      "[[245   9  49]\n",
      " [ 39 320 336]\n",
      " [ 29  29 361]]\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "test               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.78      0.79       302\n",
      "         1.0       0.84      0.46      0.60       695\n",
      "         2.0       0.46      0.80      0.58       420\n",
      "\n",
      "    accuracy                           0.63      1417\n",
      "   macro avg       0.70      0.68      0.66      1417\n",
      "weighted avg       0.72      0.63      0.63      1417\n",
      "\n",
      "test_ac 0.6316160903316866\n",
      "Confusion [[237  14  51]\n",
      " [ 25 321 349]\n",
      " [ 38  45 337]]\n",
      "Macro_f1 0.6557085906863801\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "train_loss_list=[]\n",
    "epoch_list=[]\n",
    "val_loss_list=[]\n",
    "val_f1_list=[]\n",
    "train_f1_list=[]\n",
    "\n",
    "#define model\n",
    "# model = Concatmodal()\n",
    "# model = freeze(model)\n",
    "# model.to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")\n",
    "# define hyper\n",
    "# grouped_params = [\n",
    "#     {\"params\": [p for n, p in roberta_params], \"lr\": 1e-5},\n",
    "#     # {\"params\": [p for n, p in classifier_params], \"lr\": 3e-3}\n",
    "# ]\n",
    "optimizer = torch.optim.Adam([\n",
    "        {'params': model.incept.ffn.parameters()},  \n",
    "        {'params': model.dense.parameters()},       \n",
    "        {'params': model.cl.parameters()},   \n",
    "        {'params': model.BERT.dense.parameters()},\n",
    "        {'params': model.BERT.dense1.parameters()},\n",
    "        {'params': model.BERT.PhoBERT.parameters(), 'lr': 2e-5},\n",
    "        {'params': model.incept.incept.parameters(), 'lr': 1e-4}\n",
    "    ], lr=1e-3)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "#training\n",
    "# def training(model, optimizer):\n",
    "# define hyper\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "epochs = 20\n",
    "# lr_scheduler = LRScheduler(optimizer)\n",
    "early_stopping = EarlyStopping()\n",
    "min_loss = np.Inf\n",
    "max_f1 = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  print(f\"Epoch {epoch} of {epochs}\")\n",
    "  train_epoch_loss, train_epoch_ac, train_f1 = fit(\n",
    "        model, dm, criterion, optimizer, epoch\n",
    "    )\n",
    "  writer.flush()\n",
    "\n",
    "  val_epoch_loss, val_epoch_ac, val_f1 = validation(\n",
    "        model, dm, criterion\n",
    "    )\n",
    "  writer.flush()\n",
    "\n",
    "#   lr_scheduler(val_epoch_ac)\n",
    "\n",
    "  early_stopping(val_epoch_loss)\n",
    "  if early_stopping.early_stop:\n",
    "      break\n",
    "  print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "  print(f\"Train acc: {train_epoch_ac:.4f}\")\n",
    "  print(f'Val Loss: {val_epoch_loss:.4f}')\n",
    "  print(f'Val Acc: {val_epoch_ac:.4f}')\n",
    "\n",
    "  train_loss_list.append(train_epoch_loss)\n",
    "  train_f1_list.append(train_f1)\n",
    "  val_loss_list.append(val_epoch_loss)\n",
    "  val_f1_list.append(val_f1)\n",
    "  epoch_list.append(epoch)\n",
    "\n",
    "  if (min_loss >= val_epoch_loss):\n",
    "      checkpoint ={'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch, 'loss':val_epoch_loss, 'f1': val_f1}\n",
    "      print('Better ver saved')\n",
    "      min_loss = val_epoch_loss\n",
    "      save_checkpoint(checkpoint)\n",
    "        \n",
    "  if (max_f1 <= val_f1):\n",
    "      checkpoint ={'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch, 'loss':val_epoch_loss, 'f1': val_f1}\n",
    "      print('Better f1 ver saved')\n",
    "      max_f1 = val_f1    \n",
    "      save_checkpoint1(checkpoint)\n",
    "\n",
    "testing(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avdea5H8fkHR"
   },
   "outputs": [],
   "source": [
    "# training(model, optimizer)\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8577eb1924770d3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8577eb1924770d3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NZWVPRfjiSU8",
    "outputId": "f79cb692-35f3-42c9-8832-f8e211302236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160,703,179 total parameters.\n",
      "136,868,611 training parameters.\n",
      "Epoch 0 of 20\n",
      "Epoch 0 Step 99 ave_loss 0.7337\n",
      "Epoch 0 Step 199 ave_loss 0.7366\n",
      "Epoch 0 Step 299 ave_loss 0.6768\n",
      "Epoch 0 Step 399 ave_loss 0.6947\n",
      "Epoch 0 Step 499 ave_loss 0.6818\n",
      "Epoch 0 Step 599 ave_loss 0.6906\n",
      "Epoch 0 Step 699 ave_loss 0.7158\n",
      "Epoch 0 Step 799 ave_loss 0.6511\n",
      "Epoch 0 Step 899 ave_loss 1.0804\n",
      "Epoch 0 Step 999 ave_loss 1.0409\n",
      "Epoch 0 Step 1099 ave_loss 1.0197\n",
      "Epoch 0 Step 1199 ave_loss 1.0179\n",
      "Epoch 0 Step 1299 ave_loss 1.0151\n",
      "Epoch 0 Step 1399 ave_loss 1.0278\n",
      "[[1600  439  379]\n",
      " [ 773 3466 1323]\n",
      " [ 528 1134 1693]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.63      0.49       303\n",
      "         1.0       0.58      0.61      0.59       695\n",
      "         2.0       0.52      0.27      0.35       419\n",
      "\n",
      "    accuracy                           0.51      1417\n",
      "   macro avg       0.50      0.50      0.48      1417\n",
      "weighted avg       0.52      0.51      0.50      1417\n",
      "\n",
      "[[190  92  21]\n",
      " [193 421  81]\n",
      " [ 95 212 112]]\n",
      "Train Loss: 0.8439\n",
      "Train acc: 0.5963\n",
      "Val Loss: 0.9959\n",
      "Val Acc: 0.5102\n",
      "Better ver saved\n",
      "Saving....my_checkpoint_multi_modal_mrTrong_unfreeze_weight.pth.tar\n",
      "Better f1 ver saved\n",
      "Saving....my_checkpoint_multi_modal_mrTrong_unfreeze_f1_weight.pth.tar\n",
      "Epoch 1 of 20\n",
      "Epoch 1 Step 99 ave_loss 0.9902\n",
      "Epoch 1 Step 199 ave_loss 1.0353\n",
      "Epoch 1 Step 299 ave_loss 1.0396\n",
      "Epoch 1 Step 399 ave_loss 1.0367\n",
      "Epoch 1 Step 499 ave_loss 1.0158\n",
      "Epoch 1 Step 599 ave_loss 1.0166\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     27\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m   train_epoch_loss, train_epoch_ac, train_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#   writer.flush()\u001b[39;00m\n\u001b[1;32m     33\u001b[0m   val_epoch_loss, val_epoch_ac, val_f1 \u001b[38;5;241m=\u001b[39m validation(\n\u001b[1;32m     34\u001b[0m         model, dm, criterion\n\u001b[1;32m     35\u001b[0m     )\n",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, dm, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m train_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m     13\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (texts, images, len_img_list, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dm\u001b[38;5;241m.\u001b[39mtrain_dataloader()):\n\u001b[1;32m     16\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_DA/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_DA/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_DA/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_DA/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36mSentimentData.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m   img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(data_zip\u001b[38;5;241m.\u001b[39mopen(path))\n\u001b[1;32m     21\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m   img_list\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# print(text.shape)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# text = ' '.join(text[0])\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_DA/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_DA/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_DA/lib/python3.10/site-packages/torchvision/transforms/transforms.py:349\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_DA/lib/python3.10/site-packages/torchvision/transforms/functional.py:436\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    434\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    435\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39msize, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, max_size\u001b[38;5;241m=\u001b[39mmax_size, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_DA/lib/python3.10/site-packages/torchvision/transforms/functional_pil.py:265\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_size should only be passed if size specifies the length of the smaller edge, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi.e. size should be an int or a sequence of length 1 in torchscript mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    264\u001b[0m     )\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_DA/lib/python3.10/site-packages/PIL/Image.py:1980\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1972\u001b[0m             \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   1973\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1974\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   1975\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   1976\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   1977\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   1978\u001b[0m         )\n\u001b[0;32m-> 1980\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "train_loss_list=[]\n",
    "epoch_list=[]\n",
    "val_loss_list=[]\n",
    "val_f1_list=[]\n",
    "train_f1_list=[]\n",
    "\n",
    "#define model\n",
    "# model = Concatmodal()\n",
    "# model = freeze(model)\n",
    "# model.to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "epochs = 20\n",
    "lr_scheduler = LRScheduler(optimizer)\n",
    "early_stopping = EarlyStopping()\n",
    "min_loss = np.Inf\n",
    "max_f1 = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  print(f\"Epoch {epoch} of {epochs}\")\n",
    "  train_epoch_loss, train_epoch_ac, train_f1 = fit(\n",
    "        model, dm, criterion, optimizer, epoch\n",
    "    )\n",
    "#   writer.flush()\n",
    "\n",
    "  val_epoch_loss, val_epoch_ac, val_f1 = validation(\n",
    "        model, dm, criterion\n",
    "    )\n",
    "#   writer.flush()\n",
    "\n",
    "  lr_scheduler(val_f1)\n",
    "\n",
    "  early_stopping(val_epoch_loss)\n",
    "  if early_stopping.early_stop:\n",
    "      break\n",
    "  print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "  print(f\"Train acc: {train_epoch_ac:.4f}\")\n",
    "  print(f'Val Loss: {val_epoch_loss:.4f}')\n",
    "  print(f'Val Acc: {val_epoch_ac:.4f}')\n",
    "\n",
    "  train_loss_list.append(train_epoch_loss)\n",
    "  train_f1_list.append(train_f1)\n",
    "  val_loss_list.append(val_epoch_loss)\n",
    "  val_f1_list.append(val_f1)\n",
    "  epoch_list.append(epoch)\n",
    "\n",
    "  if (min_loss >= val_epoch_loss):\n",
    "      checkpoint ={'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch, 'loss':val_epoch_loss, 'f1': val_f1}\n",
    "      print('Better ver saved')\n",
    "      min_loss = val_epoch_loss\n",
    "      save_checkpoint(checkpoint)\n",
    "        \n",
    "  if (max_f1 <= val_f1):\n",
    "      checkpoint ={'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch, 'loss':val_epoch_loss, 'f1': val_f1}\n",
    "      print('Better f1 ver saved')\n",
    "      max_f1 = val_f1    \n",
    "      save_checkpoint1(checkpoint)\n",
    "\n",
    "testing(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del model \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  7 01:27:30 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "|  0%   55C    P2    86W / 250W |   5526MiB / 11019MiB |     23%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:86:00.0 Off |                  N/A |\n",
      "|  0%   28C    P8     4W / 250W |  11015MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    214205      C   ...da3/envs/AI_DA/bin/python     5523MiB |\n",
      "|    1   N/A  N/A    306612      C   ...da3/envs/AI_DA/bin/python     7519MiB |\n",
      "|    1   N/A  N/A    429695      C   python                           3493MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZ1CVGaDdnXX",
    "outputId": "2be27769-a799-40e1-9bf7-a3524561c637"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "PATH = \"my_checkpoint_multi_modal_mrTrong_freeze_f1_weight.pth.tar\"\n",
    "checkpoint = torch.load(PATH, map_location=device)\n",
    "model = Concatmodal()\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.to(device)\n",
    "print(checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160,703,179 total parameters.\n",
      "160,703,179 training parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(model):  \n",
    "#   for param in model.BERT.PhoBERT.parameters():\n",
    "#     param.requires_grad = False\n",
    "  for param in model.incept.incept.parameters():\n",
    "    param.requires_grad = False\n",
    "    # print(param)\n",
    "  return model\n",
    "\n",
    "model = freeze(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "oegFhN6sJeRV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 2\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 3\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 4\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 5\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 2e-05\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 6\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "        {'params': model.incept.ffn.parameters()},  \n",
    "        {'params': model.dense.parameters()},       \n",
    "        {'params': model.cl.parameters()},   \n",
    "        {'params': model.BERT.dense.parameters()},\n",
    "        {'params': model.BERT.dense1.parameters()},\n",
    "        {'params': model.BERT.PhoBERT.parameters(), 'lr': 2e-5},\n",
    "        {'params': model.incept.incept.parameters(), 'lr': 1e-4}\n",
    "    ], lr=1e-4)\n",
    "optimizer\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.77      0.81       302\n",
      "         1.0       0.75      0.83      0.79       695\n",
      "         2.0       0.63      0.55      0.59       420\n",
      "\n",
      "    accuracy                           0.74      1417\n",
      "   macro avg       0.74      0.72      0.73      1417\n",
      "weighted avg       0.73      0.74      0.73      1417\n",
      "\n",
      "test_ac 0.7374735356386732\n",
      "Confusion [[233  31  38]\n",
      " [ 14 580 101]\n",
      " [ 29 159 232]]\n",
      "Macro_f1 0.7282121629630188\n"
     ]
    }
   ],
   "source": [
    "testing(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {0: {'step': 3545,\n",
       "   'exp_avg': tensor([[ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "             5.6052e-45,  5.6052e-45],\n",
       "           [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "             5.6052e-45,  5.6052e-45],\n",
       "           [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "            -5.6052e-45, -5.6052e-45],\n",
       "           ...,\n",
       "           [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "             5.6052e-45,  5.6052e-45],\n",
       "           [ 9.4547e-04,  5.5210e-04,  6.4259e-05,  ...,  2.6656e-03,\n",
       "             5.8739e-04,  4.3998e-04],\n",
       "           [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "             5.6052e-45,  5.6052e-45]], device='cuda:1'),\n",
       "   'exp_avg_sq': tensor([[3.4968e-11, 1.2886e-10, 2.1474e-10,  ..., 3.1856e-10, 1.6988e-10,\n",
       "            2.3086e-10],\n",
       "           [5.5433e-09, 1.0802e-08, 9.4702e-09,  ..., 4.2254e-09, 1.2383e-08,\n",
       "            1.0670e-08],\n",
       "           [4.6705e-12, 3.8471e-11, 7.2376e-11,  ..., 8.2616e-11, 9.4266e-11,\n",
       "            1.0619e-10],\n",
       "           ...,\n",
       "           [3.9030e-09, 4.2667e-09, 5.4947e-09,  ..., 6.5227e-09, 1.2597e-08,\n",
       "            5.6720e-09],\n",
       "           [2.3610e-05, 2.0548e-05, 2.0197e-05,  ..., 2.4700e-05, 2.3118e-05,\n",
       "            2.4901e-05],\n",
       "           [5.0260e-09, 1.8090e-08, 1.6524e-08,  ..., 1.2903e-08, 1.7034e-08,\n",
       "            8.1685e-09]], device='cuda:1')},\n",
       "  1: {'step': 3545,\n",
       "   'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  5.6052e-45, -2.5644e-43,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  4.3215e-12,  5.6052e-45,  5.6052e-45,\n",
       "           -4.5033e-29,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  6.6684e-19,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  2.6780e-08,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  1.8777e-43,  5.6052e-45,\n",
       "            3.4942e-37,  9.4006e-15,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            1.1950e-33,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  9.9876e-28,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            1.4150e-21,  5.6052e-45,  7.2431e-26,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            4.2216e-08,  5.6052e-45, -1.2349e-03,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -3.4239e-20,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  6.9562e-13,  5.6052e-45,\n",
       "            5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45, -5.5715e-27,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  7.4553e-33,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  1.4433e-43,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  2.9779e-27,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "           -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "           -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  1.1722e-11,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            9.3219e-14,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45, -8.7801e-19,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "           -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  1.9449e-04,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            8.3154e-31,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45, -1.5531e-17,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "           -1.2090e-40,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  7.0208e-15,\n",
       "            7.6875e-29,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  6.1615e-25,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "           -2.2665e-04,  5.6052e-45], device='cuda:1'),\n",
       "   'exp_avg_sq': tensor([3.6576e-10, 7.9691e-09, 1.0663e-10, 3.7479e-09, 1.3833e-11, 4.1608e-10,\n",
       "           7.9920e-13, 7.9881e-10, 9.0175e-11, 2.5875e-11, 1.3764e-10, 7.7788e-10,\n",
       "           2.2181e-09, 5.6992e-09, 3.6975e-10, 3.8419e-10, 3.5841e-11, 7.6050e-10,\n",
       "           6.8407e-11, 1.4168e-09, 7.4533e-11, 1.5309e-11, 8.0388e-10, 5.0528e-11,\n",
       "           1.8963e-11, 7.4412e-09, 3.8475e-10, 4.7857e-11, 3.8919e-10, 9.8469e-11,\n",
       "           1.6968e-10, 2.0833e-09, 4.4240e-10, 4.8826e-10, 2.6311e-10, 1.0001e-09,\n",
       "           2.5876e-11, 4.0541e-11, 2.0988e-08, 2.9701e-09, 8.2467e-11, 1.9547e-10,\n",
       "           1.0612e-09, 3.3582e-10, 1.2227e-08, 8.1347e-12, 3.6104e-10, 8.6148e-09,\n",
       "           4.9181e-10, 1.3914e-09, 2.9564e-08, 9.1113e-11, 1.1120e-08, 2.7739e-08,\n",
       "           1.6287e-10, 1.7775e-08, 1.3788e-09, 5.5891e-12, 1.8970e-10, 2.9390e-11,\n",
       "           1.4879e-12, 1.6327e-10, 1.3366e-11, 1.0072e-09, 2.0387e-08, 8.6671e-11,\n",
       "           2.7533e-08, 1.2553e-10, 5.8927e-10, 5.8082e-08, 6.6333e-11, 3.6037e-09,\n",
       "           7.6028e-08, 1.1768e-09, 8.7230e-10, 1.1670e-10, 6.2484e-10, 2.5116e-10,\n",
       "           1.4591e-09, 3.9981e-13, 2.5291e-10, 5.3256e-09, 2.2470e-08, 2.5567e-10,\n",
       "           1.6326e-10, 7.8044e-10, 1.5553e-09, 1.6823e-09, 2.1047e-09, 3.5631e-11,\n",
       "           1.4821e-11, 2.5063e-09, 4.8678e-10, 1.8845e-09, 2.7181e-09, 4.9562e-09,\n",
       "           7.4370e-10, 7.2470e-11, 3.9832e-11, 4.2178e-10, 1.3228e-09, 4.1803e-09,\n",
       "           2.6419e-10, 1.3721e-09, 2.5527e-10, 9.0658e-09, 1.7627e-09, 3.3555e-10,\n",
       "           2.5753e-10, 1.1822e-10, 7.9389e-11, 3.2597e-09, 4.1750e-09, 3.5744e-09,\n",
       "           9.1042e-11, 7.4053e-10, 2.7066e-09, 2.6007e-11, 6.9154e-13, 3.2749e-10,\n",
       "           1.1061e-09, 1.2810e-10, 9.1003e-11, 1.1323e-09, 2.9242e-11, 1.7910e-08,\n",
       "           4.9252e-09, 3.5137e-11, 1.5906e-12, 1.4441e-08, 2.7063e-11, 9.2692e-11,\n",
       "           1.0528e-08, 9.1424e-10, 7.2449e-10, 1.9719e-09, 2.9659e-09, 3.4125e-09,\n",
       "           2.0749e-12, 7.0987e-11, 5.5419e-11, 2.3816e-13, 1.5843e-10, 2.0730e-10,\n",
       "           6.4407e-10, 9.4287e-13, 1.1433e-11, 1.8443e-09, 1.2714e-09, 1.5703e-10,\n",
       "           1.2442e-09, 2.3047e-11, 1.0312e-12, 4.1543e-11, 2.0546e-09, 5.1827e-08,\n",
       "           1.6708e-07, 1.0165e-08, 7.6145e-11, 4.1955e-10, 3.1699e-10, 2.4760e-10,\n",
       "           4.2897e-10, 8.3832e-10, 3.9421e-09, 1.0696e-10, 2.9188e-09, 4.8316e-10,\n",
       "           2.1418e-10, 1.3035e-10, 5.5146e-09, 8.2415e-10, 7.0308e-05, 9.2809e-10,\n",
       "           5.5237e-11, 1.2755e-09, 8.4733e-11, 4.1916e-13, 2.3231e-11, 5.6903e-09,\n",
       "           5.1322e-11, 3.6997e-09, 1.5971e-10, 2.5265e-10, 2.1794e-10, 2.4416e-09,\n",
       "           1.0653e-09, 2.1394e-09, 6.7335e-12, 1.0320e-08, 7.4012e-11, 4.7411e-10,\n",
       "           1.2065e-09, 3.8994e-11, 7.6692e-08, 7.7939e-09, 2.9144e-12, 4.1288e-10,\n",
       "           5.8031e-08, 6.7364e-10, 1.5341e-10, 3.0080e-10, 1.0641e-09, 9.8798e-11,\n",
       "           1.3716e-10, 9.9401e-10, 2.5263e-09, 4.2654e-10, 1.6805e-08, 2.9310e-09,\n",
       "           7.2817e-10, 3.5981e-09, 9.0468e-10, 4.1841e-10, 3.7736e-09, 5.8215e-10,\n",
       "           9.5578e-09, 8.8391e-10, 2.2021e-09, 3.0277e-09, 2.7497e-08, 2.0250e-11,\n",
       "           2.6486e-09, 6.9569e-10, 1.8482e-09, 2.4888e-09, 2.9526e-11, 5.8048e-11,\n",
       "           5.3988e-09, 9.1121e-09, 8.8248e-11, 5.9193e-10, 1.2221e-11, 1.8618e-10,\n",
       "           1.2512e-09, 1.1988e-11, 3.5014e-10, 1.4874e-09, 2.3461e-08, 1.3777e-08,\n",
       "           8.0788e-10, 4.1602e-11, 2.8946e-10, 1.3951e-12, 5.6549e-12, 2.2524e-09,\n",
       "           1.9600e-10, 1.7596e-10, 3.3298e-09, 7.9291e-09, 7.3549e-10, 9.0596e-09,\n",
       "           5.2883e-11, 1.8804e-08, 2.2812e-10, 2.6750e-10, 4.5915e-10, 4.6446e-09,\n",
       "           3.1005e-11, 1.0994e-09, 2.8272e-11, 1.2892e-09, 6.8291e-09, 1.1368e-10,\n",
       "           4.3415e-09, 2.9570e-11, 6.5082e-10, 4.0790e-11, 6.3845e-08, 8.1592e-10,\n",
       "           4.0755e-08, 3.9675e-09, 3.0639e-08, 2.4423e-13, 9.5362e-11, 5.3699e-10,\n",
       "           4.0708e-11, 8.3604e-10, 2.5109e-11, 2.0503e-09, 6.0697e-09, 6.0029e-12,\n",
       "           2.0456e-10, 5.7123e-12, 1.7937e-10, 3.5708e-09, 3.7573e-12, 9.2917e-10,\n",
       "           5.0349e-09, 1.1745e-09, 2.4183e-11, 1.5360e-09, 2.1222e-09, 2.1513e-10,\n",
       "           2.5559e-11, 2.6148e-10, 6.7083e-11, 9.6680e-11, 5.0705e-10, 2.1488e-09,\n",
       "           1.6386e-09, 1.6834e-08, 8.5823e-10, 2.7535e-10, 3.1964e-10, 1.9546e-10,\n",
       "           4.8800e-12, 5.2364e-09, 3.9160e-10, 1.5745e-10, 7.6426e-11, 7.1386e-10,\n",
       "           1.4809e-10, 4.2096e-09, 2.0662e-09, 1.9439e-11, 4.6735e-10, 3.1446e-10,\n",
       "           1.1558e-11, 1.9132e-09, 6.3288e-10, 2.4654e-12, 3.3362e-11, 4.9388e-11,\n",
       "           1.7231e-09, 7.4460e-09, 8.8063e-09, 7.6215e-10, 4.4894e-09, 2.3067e-10,\n",
       "           4.7644e-10, 3.5246e-09, 4.6787e-11, 2.8104e-13, 2.0339e-10, 3.9737e-12,\n",
       "           5.5522e-10, 5.1465e-11, 3.2363e-09, 3.0387e-11, 3.4352e-11, 7.8732e-10,\n",
       "           7.8643e-12, 2.0424e-11, 2.7309e-09, 2.5520e-09, 1.8812e-12, 1.4807e-10,\n",
       "           6.4349e-10, 1.3183e-11, 2.7328e-10, 3.2918e-11, 2.7114e-10, 4.6318e-10,\n",
       "           1.4120e-09, 7.2795e-10, 2.2341e-09, 4.4838e-11, 5.5655e-10, 2.3936e-08,\n",
       "           1.7858e-11, 2.4538e-08, 2.9398e-10, 2.2137e-09, 1.7933e-13, 1.9252e-11,\n",
       "           4.8255e-11, 1.2404e-09, 7.4949e-10, 7.5934e-12, 1.2826e-08, 4.2162e-09,\n",
       "           3.3090e-10, 1.3740e-09, 3.0833e-09, 1.6711e-11, 9.9118e-12, 2.5838e-10,\n",
       "           2.6956e-10, 4.5494e-08, 5.0296e-10, 1.2284e-08, 5.0406e-08, 1.3242e-10,\n",
       "           7.2570e-10, 5.9657e-10, 2.2677e-10, 4.6425e-10, 5.5399e-09, 7.5711e-11,\n",
       "           2.0694e-11, 2.2026e-08, 2.3592e-11, 7.5619e-10, 2.2671e-10, 3.9236e-12,\n",
       "           3.4342e-11, 9.5917e-10, 1.5418e-10, 3.7131e-11, 8.4627e-09, 8.0329e-12,\n",
       "           6.3836e-12, 7.3581e-12, 4.6003e-07, 2.7543e-08, 1.0235e-09, 5.3876e-09,\n",
       "           4.7548e-10, 3.4482e-12, 4.1631e-09, 1.2746e-10, 8.5436e-10, 3.7248e-10,\n",
       "           2.5804e-10, 7.1849e-10, 7.6936e-09, 4.2492e-10, 2.3677e-11, 1.9778e-10,\n",
       "           1.0526e-10, 8.7149e-10, 9.4701e-09, 1.3955e-10, 7.2833e-10, 3.9215e-09,\n",
       "           6.7549e-09, 2.8086e-10, 1.5055e-08, 1.8369e-11, 9.8600e-12, 1.7647e-08,\n",
       "           7.3445e-11, 1.8764e-10, 5.4028e-09, 1.1892e-10, 1.7960e-11, 1.1397e-09,\n",
       "           4.6791e-12, 8.6217e-10, 9.3785e-11, 1.9354e-11, 1.0924e-09, 4.9676e-12,\n",
       "           8.1124e-11, 1.1282e-09, 5.1346e-09, 2.4567e-09, 5.3794e-12, 4.9996e-10,\n",
       "           1.6257e-09, 2.9497e-12, 4.0500e-10, 1.5084e-12, 3.2132e-09, 7.9926e-10,\n",
       "           2.0029e-11, 1.8065e-11, 2.9775e-10, 1.4878e-08, 1.4496e-08, 1.2076e-09,\n",
       "           2.1398e-12, 1.8730e-10, 6.8422e-11, 5.4451e-10, 1.6591e-11, 9.3963e-09,\n",
       "           8.4544e-12, 7.5665e-10, 1.6249e-09, 2.7958e-09, 9.5936e-11, 8.3416e-11,\n",
       "           2.0273e-13, 1.0143e-09, 4.1749e-11, 4.7140e-11, 6.7025e-09, 1.7812e-09,\n",
       "           6.3122e-09, 1.4359e-09, 4.5045e-09, 3.8528e-10, 3.3558e-10, 1.2494e-10,\n",
       "           2.4200e-09, 8.9895e-09, 3.4165e-09, 8.7407e-10, 2.8816e-09, 3.2764e-11,\n",
       "           5.3353e-12, 3.0779e-10, 1.1946e-08, 8.8087e-10, 2.4958e-10, 2.8472e-12,\n",
       "           3.4335e-11, 2.4277e-10, 2.7936e-10, 1.8534e-10, 6.0824e-09, 1.5589e-10,\n",
       "           2.2459e-09, 5.1700e-12, 1.3675e-11, 1.2419e-10, 5.3689e-11, 6.2611e-09,\n",
       "           2.8112e-05, 2.4104e-08], device='cuda:1')},\n",
       "  2: {'step': 3545,\n",
       "   'exp_avg': tensor([[-5.6052e-45,  5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
       "            -6.0395e-03,  5.6052e-45],\n",
       "           [-5.6052e-45,  5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
       "            -1.1243e-02, -5.6052e-45],\n",
       "           [-5.6052e-45,  5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
       "            -9.0222e-04, -5.6052e-45],\n",
       "           ...,\n",
       "           [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "             2.4080e-03,  5.6052e-45],\n",
       "           [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "            -4.3378e-03,  5.6052e-45],\n",
       "           [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
       "             2.2655e-03, -5.6052e-45]], device='cuda:1'),\n",
       "   'exp_avg_sq': tensor([[4.6845e-09, 1.1157e-07, 2.4619e-09,  ..., 7.2742e-08, 6.4079e-04,\n",
       "            1.0662e-07],\n",
       "           [3.6564e-09, 4.1700e-07, 3.3328e-09,  ..., 4.6834e-08, 3.2659e-03,\n",
       "            3.1416e-07],\n",
       "           [6.5947e-10, 1.1265e-07, 7.4670e-10,  ..., 1.2979e-08, 1.4336e-04,\n",
       "            1.1851e-07],\n",
       "           ...,\n",
       "           [5.3820e-10, 8.4744e-08, 1.7266e-10,  ..., 2.6295e-08, 1.8295e-04,\n",
       "            1.7150e-07],\n",
       "           [6.1221e-10, 2.4879e-08, 5.6856e-10,  ..., 8.3031e-09, 4.1261e-04,\n",
       "            6.5936e-08],\n",
       "           [1.3230e-09, 4.2678e-08, 6.1293e-10,  ..., 3.0102e-08, 3.0165e-05,\n",
       "            6.3456e-08]], device='cuda:1')},\n",
       "  3: {'step': 3545,\n",
       "   'exp_avg': tensor([-1.2744e-04, -9.9841e-04, -1.8568e-05, -1.1307e-03,  5.6173e-05,\n",
       "            1.4059e-05,  3.7509e-04, -1.9265e-04, -1.5607e-04,  1.5326e-04,\n",
       "           -1.0890e-05,  1.5064e-04, -1.9320e-03,  5.2221e-05, -2.7707e-05,\n",
       "            6.2503e-05,  2.0670e-04,  4.0388e-04,  1.4269e-04,  1.4002e-04,\n",
       "            8.7207e-05, -5.0392e-05, -7.2825e-05, -7.0156e-06, -2.9013e-04,\n",
       "           -8.7596e-05,  9.2669e-05,  8.0927e-05, -4.2883e-05, -1.0506e-04,\n",
       "            1.7564e-05,  8.2074e-05,  3.3533e-05,  1.0888e-04,  1.7139e-04,\n",
       "            6.2442e-05,  1.9141e-04, -7.8262e-05,  4.8637e-05,  1.2328e-04,\n",
       "            1.3452e-04,  9.3244e-06,  5.6315e-05,  7.4057e-05,  8.4150e-05,\n",
       "           -1.8847e-04, -7.1498e-04, -1.7174e-04,  2.0607e-04, -9.5829e-05,\n",
       "            1.3490e-04, -2.6044e-05, -6.0569e-04, -1.1568e-04,  1.4178e-05,\n",
       "            3.1761e-04,  1.6298e-05, -6.1996e-04, -2.2360e-03, -8.7586e-05,\n",
       "           -1.4010e-04, -1.3003e-04, -9.0914e-05, -2.3966e-04,  1.9777e-04,\n",
       "           -5.8272e-06,  6.1168e-06,  1.4075e-05,  1.8504e-04,  1.8214e-04,\n",
       "            9.5573e-05,  1.8776e-04, -1.9177e-03, -1.4008e-03,  4.2726e-05,\n",
       "            3.2592e-04,  3.7035e-06, -1.1432e-03, -1.3123e-04,  3.4165e-05,\n",
       "            2.9640e-04, -6.2360e-05,  2.4429e-04,  8.1535e-04, -6.2479e-04,\n",
       "            6.6552e-04,  8.1942e-05,  3.9465e-05,  5.8297e-05,  2.5649e-05,\n",
       "            8.0351e-04,  8.3656e-05, -3.0994e-04, -1.4267e-04,  1.1713e-04,\n",
       "           -1.4372e-04,  3.4890e-05,  2.2071e-04,  3.6995e-06, -1.6935e-04,\n",
       "           -1.3645e-04,  6.7163e-05, -3.1535e-05,  3.0004e-06, -1.8229e-04,\n",
       "           -3.5833e-04, -5.9228e-05, -3.6391e-05,  1.0876e-03,  6.6195e-05,\n",
       "           -1.7810e-04,  3.4913e-04, -4.9367e-05, -7.0840e-04,  3.5645e-05,\n",
       "           -6.3461e-05, -1.4563e-05, -1.9081e-04,  2.0453e-04,  1.9164e-04,\n",
       "           -7.7296e-05,  3.4344e-04, -8.7557e-05,  9.6586e-05,  2.4471e-04,\n",
       "            4.2850e-05, -1.3712e-04,  1.3220e-04], device='cuda:1'),\n",
       "   'exp_avg_sq': tensor([9.9409e-06, 5.4328e-05, 2.7248e-06, 6.6391e-05, 8.1287e-06, 2.7987e-06,\n",
       "           1.3917e-05, 3.7377e-05, 1.5813e-06, 1.6817e-06, 5.4064e-06, 1.7102e-06,\n",
       "           1.4066e-04, 1.9029e-06, 2.0006e-06, 2.5982e-06, 7.7871e-07, 1.6882e-05,\n",
       "           1.4610e-06, 4.0343e-06, 8.7579e-06, 1.1367e-06, 5.9343e-07, 2.9650e-06,\n",
       "           1.2808e-05, 6.9185e-06, 5.8700e-07, 2.2422e-06, 2.7097e-06, 2.6912e-06,\n",
       "           3.6382e-06, 2.9648e-06, 6.0176e-07, 1.8729e-06, 5.8200e-06, 1.6954e-06,\n",
       "           5.9724e-06, 2.5228e-06, 1.5458e-06, 5.9988e-07, 5.3901e-07, 4.7166e-07,\n",
       "           5.7086e-07, 3.1263e-06, 2.0762e-06, 1.5940e-05, 2.9155e-05, 8.2639e-06,\n",
       "           6.7828e-06, 2.9042e-06, 6.1879e-07, 5.6322e-06, 3.3152e-05, 9.5782e-07,\n",
       "           5.3175e-06, 1.1237e-05, 1.0922e-06, 3.6341e-05, 2.3798e-04, 7.2029e-07,\n",
       "           2.2186e-05, 3.0320e-06, 8.5095e-07, 7.9434e-06, 7.3274e-07, 7.3199e-07,\n",
       "           1.4606e-06, 7.6300e-06, 8.8023e-07, 8.1674e-06, 2.5951e-06, 1.0153e-06,\n",
       "           1.7708e-04, 1.0193e-04, 4.6591e-06, 1.3108e-05, 6.8446e-07, 6.8725e-05,\n",
       "           5.0889e-06, 3.7233e-06, 7.6586e-06, 2.7860e-07, 1.6344e-05, 3.6532e-05,\n",
       "           3.0182e-05, 3.9437e-05, 2.4097e-06, 5.9845e-06, 2.3337e-06, 9.5715e-07,\n",
       "           4.4587e-05, 4.3221e-06, 1.0695e-05, 1.5144e-06, 6.9539e-07, 3.6077e-06,\n",
       "           1.9430e-06, 1.1329e-05, 5.0170e-07, 6.1711e-07, 8.4258e-06, 1.2833e-06,\n",
       "           1.0208e-06, 9.4834e-07, 1.2033e-06, 1.3928e-05, 2.3850e-06, 2.8400e-06,\n",
       "           6.3414e-05, 6.9510e-07, 7.4660e-07, 3.0848e-05, 4.0576e-06, 3.4570e-05,\n",
       "           1.2833e-06, 3.7235e-06, 3.9128e-06, 6.7719e-06, 7.3769e-07, 1.7896e-06,\n",
       "           1.6681e-06, 1.6571e-05, 5.2396e-06, 7.3698e-07, 1.2723e-05, 2.8441e-06,\n",
       "           6.4746e-06, 6.2749e-07], device='cuda:1')},\n",
       "  6: {'step': 3545,\n",
       "   'exp_avg': tensor([[-3.1835e-02,  2.1088e-02, -2.1362e-01,  9.8131e-03,  2.1589e-02,\n",
       "             3.2857e-01, -1.4933e-02, -6.3468e-02, -2.8677e-02,  3.3261e-02,\n",
       "            -2.5630e-02,  2.8360e-02, -8.1524e-03,  2.5744e-02, -8.7329e-03,\n",
       "             2.4987e-02,  5.1254e-03,  2.0353e-02,  3.7087e-02,  2.9515e-02,\n",
       "             1.8734e-02, -8.6270e-04, -8.1888e-03,  8.7631e-03, -3.0612e-02,\n",
       "            -6.4545e-03, -1.8102e-02, -6.1089e-03,  3.1354e-02, -1.5521e-02,\n",
       "             2.8520e-02,  2.9816e-01, -1.5779e-02,  9.9456e-03, -2.3020e-02,\n",
       "            -2.8830e-02,  1.0932e-02, -3.2808e-02,  1.6211e-02, -6.6137e-03,\n",
       "             2.2914e-02, -3.4594e-02,  3.7635e-02,  2.5470e-02, -9.4417e-04,\n",
       "             2.0596e-02, -1.3856e-02, -3.1879e-02, -2.5357e-02,  7.4978e-03,\n",
       "             2.4885e-02,  8.9057e-04,  3.9530e-02, -1.9518e-02, -1.6744e-02,\n",
       "             2.9734e-02,  4.3347e-03,  2.1281e-02,  7.4418e-03, -1.4916e-02,\n",
       "            -7.8990e-03, -2.7833e-02, -3.5606e-03,  1.0922e-02,  2.5509e-03,\n",
       "             1.7899e-02, -1.8316e-02, -1.2094e-02, -2.5431e-02,  9.4562e-03,\n",
       "             1.9027e-01,  9.6887e-03,  2.7042e-02, -1.2218e-01, -2.7811e-02,\n",
       "            -6.5795e-04, -1.3020e-02, -1.9626e-02,  2.2432e-02,  1.1533e-02,\n",
       "            -7.3616e-03, -3.6576e-02, -8.9502e-03, -1.7333e-03, -1.3396e-03,\n",
       "            -4.0033e-04, -1.3852e-02, -4.2937e-03,  5.2378e-04,  2.1560e-04,\n",
       "             6.2983e-03, -1.2027e-02,  9.6387e-04,  3.9482e-02,  1.5554e-02,\n",
       "             3.6294e-03, -5.8820e-03, -3.8247e-02,  1.8551e-02, -1.3247e-02,\n",
       "            -5.0468e-01, -2.1369e-03,  3.2191e-02, -1.8536e-02, -7.3905e-01,\n",
       "             1.7275e-02,  7.2036e-03,  3.8527e-01,  2.0384e-02, -4.5200e-04,\n",
       "             2.9857e-02,  8.2451e-03,  9.0605e-03, -1.8299e-02,  2.2366e-02,\n",
       "             7.2886e-03, -8.3062e-03, -2.8524e-01, -2.7786e-02, -8.1047e-03,\n",
       "            -2.8881e-02, -1.5372e-02,  6.3335e-03, -4.3304e-01, -2.8451e-02,\n",
       "             1.0843e-02, -3.9989e-02,  2.4300e-03, -9.5521e-05,  1.5151e-03,\n",
       "            -5.7130e-05,  1.1839e-02, -1.3229e-03,  1.7109e-04, -9.5815e-04,\n",
       "             3.4437e-03,  1.3996e-03, -1.7589e-03,  1.5336e-03, -1.8416e-03,\n",
       "             1.7784e-02, -5.0656e-04,  2.1491e-05, -1.4176e-03, -1.4160e-03,\n",
       "            -6.5565e-05, -7.9083e-04, -2.2834e-04,  1.0577e-03,  2.9602e-04,\n",
       "             1.1533e-03,  1.4624e-03,  5.4498e-04, -5.8409e-04, -9.8937e-04,\n",
       "            -1.3613e-03,  5.6951e-04,  8.9890e-04, -1.6521e-04, -1.2756e-03,\n",
       "            -7.6376e-04, -7.2660e-04, -1.9845e-04, -7.2186e-04, -8.2582e-04,\n",
       "             4.1255e-04,  3.7643e-04, -9.4526e-04, -1.1951e-03,  4.7280e-04,\n",
       "            -1.0727e-03, -5.2610e-04, -5.7019e-04,  2.0811e-03,  1.0047e-02,\n",
       "            -1.2903e-03, -1.6295e-04,  7.3316e-04, -6.6790e-04,  2.2433e-05,\n",
       "             9.4543e-04,  1.6266e-03, -1.3666e-03,  4.2085e-04,  3.2540e-04,\n",
       "             8.8530e-04,  1.9933e-02,  1.6715e-04,  4.7462e-03,  1.9403e-03,\n",
       "             6.5809e-04,  2.2566e-03, -1.2793e-03,  9.0160e-04,  2.7191e-04,\n",
       "             8.1252e-04, -1.5919e-03, -3.9201e-04, -8.3863e-04, -1.8355e-03,\n",
       "             1.8493e-02,  1.3501e-02, -1.1645e-03,  2.2635e-04,  4.3830e-05,\n",
       "             2.6717e-03, -9.6290e-04,  1.6987e-05, -4.3046e-04,  6.6088e-04,\n",
       "            -1.9627e-04, -4.0428e-03,  6.2997e-05,  9.0798e-05, -6.1300e-04,\n",
       "            -2.5417e-05, -5.4958e-04, -4.7922e-04, -1.0740e-04, -7.5399e-04,\n",
       "            -8.7030e-04,  1.7185e-03, -1.7608e-03, -6.4789e-04, -8.0362e-04,\n",
       "             2.5760e-04,  3.8175e-04,  1.6582e-03, -4.4747e-04, -2.8950e-04,\n",
       "             1.5717e-04,  5.5807e-04,  1.3325e-03,  3.7374e-04,  1.0441e-03,\n",
       "            -1.4468e-04, -1.4987e-03, -8.6184e-04,  7.7591e-04, -2.3636e-04,\n",
       "             1.5543e-03,  4.0086e-04, -7.7746e-04, -9.4514e-05, -6.2085e-04,\n",
       "            -4.3438e-04, -2.0852e-03, -1.4454e-03,  2.9953e-05,  2.1616e-04,\n",
       "            -1.2134e-03, -1.2638e-03,  1.2814e-03,  8.5177e-05, -6.6485e-04,\n",
       "            -1.3364e-03],\n",
       "           [-4.5417e-03, -1.6305e-02,  1.7559e-02,  6.1197e-03, -9.7200e-03,\n",
       "            -1.1423e-01, -8.0966e-05,  1.6517e-02, -3.4750e-03,  6.5308e-03,\n",
       "            -6.8150e-03,  1.8154e-02,  2.7830e-03,  1.5981e-02, -1.8114e-03,\n",
       "            -1.1891e-02, -2.8308e-03, -1.0802e-02,  3.1898e-02, -1.1716e-02,\n",
       "            -6.9221e-03,  2.0396e-03,  1.1179e-02, -5.6001e-03, -4.3835e-03,\n",
       "            -4.3868e-03, -2.1453e-02,  1.9008e-02,  1.1816e-03, -1.0722e-02,\n",
       "            -6.7933e-03, -1.1055e-01, -7.9961e-03,  3.5113e-03,  1.1242e-02,\n",
       "            -6.2271e-03,  1.7821e-02,  3.3317e-03,  1.5894e-02, -2.0334e-03,\n",
       "             2.3879e-03, -8.8171e-03, -1.2938e-02, -1.0931e-02, -8.1453e-03,\n",
       "             3.2680e-03,  1.0181e-02, -1.1571e-02,  1.4604e-02,  1.6351e-03,\n",
       "             1.6860e-02, -1.1307e-02,  1.5613e-02, -4.4896e-03, -3.9292e-03,\n",
       "             1.0495e-02,  2.4574e-04, -1.6371e-02, -1.6163e-02,  1.8925e-03,\n",
       "             2.0256e-02, -8.3920e-03, -1.8749e-04,  6.2682e-03,  1.2757e-02,\n",
       "            -5.8327e-03,  9.6373e-03,  1.5954e-03,  2.8289e-03, -2.1070e-03,\n",
       "             4.3727e-03,  3.2641e-03, -1.3517e-02,  2.1731e-02, -1.5190e-02,\n",
       "            -1.9771e-02, -2.2049e-02, -1.5002e-02,  1.3571e-02,  1.0200e-03,\n",
       "             6.8247e-06,  7.4823e-03, -1.5812e-03,  4.1953e-03,  1.6282e-02,\n",
       "            -1.5499e-02,  3.9703e-04,  1.0617e-04, -1.5867e-02, -1.1261e-02,\n",
       "            -7.3879e-03,  3.8178e-03, -3.8121e-03, -9.0557e-03, -6.8744e-03,\n",
       "            -8.9470e-03, -8.1445e-03,  1.8116e-02, -1.3703e-02,  6.1949e-03,\n",
       "             5.7862e-02,  1.7658e-02, -7.2761e-03,  8.6612e-03,  7.9039e-02,\n",
       "            -4.2320e-03, -1.0368e-02, -3.3249e-02,  1.1311e-02,  9.1381e-05,\n",
       "             1.1356e-02,  1.5406e-02, -2.9565e-03,  1.3453e-02, -1.0421e-02,\n",
       "             1.2812e-02,  5.2284e-04,  3.1174e-02,  3.4963e-03,  2.7693e-03,\n",
       "            -1.4085e-03,  2.2611e-02, -9.8856e-03,  4.6240e-02,  4.6872e-03,\n",
       "             5.5012e-03,  4.6342e-03, -3.0099e-03, -2.2208e-03, -7.0841e-03,\n",
       "            -1.1095e-03, -1.5335e-02, -1.8424e-04, -2.2207e-04,  3.3485e-03,\n",
       "            -1.6243e-03, -4.5986e-04,  7.5973e-04,  8.5311e-04,  6.8414e-04,\n",
       "            -2.1698e-02,  1.0347e-03,  1.1033e-03, -5.5845e-04,  9.9750e-04,\n",
       "             4.5325e-03,  8.8445e-04,  2.0924e-03,  1.5953e-03, -5.8482e-04,\n",
       "            -1.0646e-03,  1.9515e-04, -3.7536e-03, -1.3325e-03,  1.0511e-03,\n",
       "             4.3529e-05, -2.5905e-04, -1.2069e-05, -6.1997e-04, -7.6686e-05,\n",
       "             5.7147e-04,  3.5567e-05,  2.9071e-03, -5.6666e-04,  2.6254e-03,\n",
       "             1.9932e-04, -6.8233e-04,  9.7145e-04,  1.2479e-03, -4.3814e-04,\n",
       "             1.2738e-03,  8.8079e-04, -7.2797e-05, -2.1902e-03, -1.2191e-02,\n",
       "            -2.3653e-03,  2.9832e-03,  1.2358e-04,  8.8142e-04, -9.8268e-04,\n",
       "            -5.0349e-03, -1.0719e-03, -9.1437e-04,  4.1689e-03, -3.2225e-04,\n",
       "            -5.8268e-03, -2.3405e-02, -1.7100e-04, -4.3009e-03, -7.0976e-04,\n",
       "            -7.3852e-05, -3.2376e-03,  9.0153e-04, -3.8044e-04, -6.3701e-04,\n",
       "             9.2096e-04,  7.8998e-04,  2.9835e-03, -2.7501e-04,  1.1966e-03,\n",
       "            -2.1912e-02, -1.5201e-02, -6.7878e-04,  3.0748e-03, -3.3188e-04,\n",
       "            -7.8969e-03, -1.5146e-03, -6.6245e-04,  3.4103e-03, -2.0528e-04,\n",
       "             1.5791e-03,  7.3351e-03, -5.0131e-03,  5.7715e-03, -1.6651e-04,\n",
       "             1.8027e-03,  1.4123e-03,  1.8194e-04,  5.1645e-03,  9.5772e-04,\n",
       "            -3.7483e-03, -4.3655e-04,  1.6650e-03, -2.3603e-03, -4.9805e-04,\n",
       "             1.9749e-03, -2.8507e-04, -1.4012e-03, -2.3858e-03,  1.8591e-04,\n",
       "             2.3016e-04, -8.5874e-04, -9.4735e-04, -4.1436e-03,  6.7308e-04,\n",
       "            -1.2709e-03,  8.0214e-03,  7.5810e-04, -7.1315e-04,  3.9688e-03,\n",
       "             3.0420e-04, -5.5173e-03,  7.7487e-04, -8.1801e-04, -1.1221e-03,\n",
       "            -2.0773e-03,  1.9358e-03,  6.4481e-04,  7.4089e-04,  3.4356e-03,\n",
       "            -1.8662e-03,  1.1701e-03,  2.5573e-03,  1.5329e-03, -2.4308e-03,\n",
       "             1.1270e-03],\n",
       "           [ 3.6377e-02, -4.7825e-03,  1.9606e-01, -1.5933e-02, -1.1869e-02,\n",
       "            -2.1435e-01,  1.5014e-02,  4.6951e-02,  3.2152e-02, -3.9792e-02,\n",
       "             3.2445e-02, -4.6514e-02,  5.3694e-03, -4.1725e-02,  1.0544e-02,\n",
       "            -1.3096e-02, -2.2947e-03, -9.5511e-03, -6.8986e-02, -1.7799e-02,\n",
       "            -1.1812e-02, -1.1769e-03, -2.9902e-03, -3.1631e-03,  3.4995e-02,\n",
       "             1.0841e-02,  3.9555e-02, -1.2899e-02, -3.2535e-02,  2.6243e-02,\n",
       "            -2.1727e-02, -1.8761e-01,  2.3775e-02, -1.3457e-02,  1.1778e-02,\n",
       "             3.5057e-02, -2.8753e-02,  2.9476e-02, -3.2104e-02,  8.6471e-03,\n",
       "            -2.5302e-02,  4.3411e-02, -2.4696e-02, -1.4538e-02,  9.0895e-03,\n",
       "            -2.3864e-02,  3.6753e-03,  4.3450e-02,  1.0754e-02, -9.1329e-03,\n",
       "            -4.1746e-02,  1.0417e-02, -5.5143e-02,  2.4007e-02,  2.0673e-02,\n",
       "            -4.0229e-02, -4.5804e-03, -4.9107e-03,  8.7213e-03,  1.3023e-02,\n",
       "            -1.2357e-02,  3.6225e-02,  3.7481e-03, -1.7190e-02, -1.5307e-02,\n",
       "            -1.2067e-02,  8.6784e-03,  1.0498e-02,  2.2602e-02, -7.3491e-03,\n",
       "            -1.9464e-01, -1.2953e-02, -1.3525e-02,  1.0045e-01,  4.3001e-02,\n",
       "             2.0429e-02,  3.5070e-02,  3.4627e-02, -3.6002e-02, -1.2553e-02,\n",
       "             7.3547e-03,  2.9094e-02,  1.0531e-02, -2.4620e-03, -1.4942e-02,\n",
       "             1.5899e-02,  1.3455e-02,  4.1876e-03,  1.5343e-02,  1.1045e-02,\n",
       "             1.0896e-03,  8.2088e-03,  2.8483e-03, -3.0426e-02, -8.6795e-03,\n",
       "             5.3177e-03,  1.4027e-02,  2.0131e-02, -4.8482e-03,  7.0525e-03,\n",
       "             4.4681e-01, -1.5521e-02, -2.4915e-02,  9.8748e-03,  6.6001e-01,\n",
       "            -1.3043e-02,  3.1642e-03, -3.5202e-01, -3.1695e-02,  3.6062e-04,\n",
       "            -4.1213e-02, -2.3651e-02, -6.1040e-03,  4.8459e-03, -1.1946e-02,\n",
       "            -2.0100e-02,  7.7833e-03,  2.5407e-01,  2.4289e-02,  5.3355e-03,\n",
       "             3.0289e-02, -7.2383e-03,  3.5521e-03,  3.8680e-01,  2.3764e-02,\n",
       "            -1.6344e-02,  3.5355e-02,  5.7990e-04,  2.3163e-03,  5.5690e-03,\n",
       "             1.1666e-03,  3.4959e-03,  1.5072e-03,  5.0977e-05, -2.3904e-03,\n",
       "            -1.8195e-03, -9.3975e-04,  9.9918e-04, -2.3867e-03,  1.1574e-03,\n",
       "             3.9140e-03, -5.2810e-04, -1.1248e-03,  1.9760e-03,  4.1847e-04,\n",
       "            -4.4669e-03, -9.3620e-05, -1.8641e-03, -2.6531e-03,  2.8881e-04,\n",
       "            -8.8757e-05, -1.6576e-03,  3.2086e-03,  1.9166e-03, -6.1779e-05,\n",
       "             1.3178e-03, -3.1046e-04, -8.8683e-04,  7.8519e-04,  1.3523e-03,\n",
       "             1.9229e-04,  6.9103e-04, -2.7086e-03,  1.2885e-03, -1.7996e-03,\n",
       "            -6.1187e-04,  3.0590e-04, -2.6188e-05, -5.2883e-05, -3.4668e-05,\n",
       "            -2.0111e-04, -3.5470e-04,  6.4299e-04,  1.0914e-04,  2.1443e-03,\n",
       "             3.6556e-03, -2.8202e-03, -8.5674e-04, -2.1352e-04,  9.6025e-04,\n",
       "             4.0895e-03, -5.5469e-04,  2.2810e-03, -4.5897e-03, -3.1450e-06,\n",
       "             4.9415e-03,  3.4723e-03,  3.8423e-06, -4.4530e-04, -1.2306e-03,\n",
       "            -5.8424e-04,  9.8097e-04,  3.7775e-04, -5.2117e-04,  3.6510e-04,\n",
       "            -1.7335e-03,  8.0192e-04, -2.5915e-03,  1.1136e-03,  6.3884e-04,\n",
       "             3.4187e-03,  1.7002e-03,  1.8433e-03, -3.3011e-03,  2.8805e-04,\n",
       "             5.2252e-03,  2.4775e-03,  6.4546e-04, -2.9799e-03, -4.5560e-04,\n",
       "            -1.3828e-03, -3.2924e-03,  4.9501e-03, -5.8623e-03,  7.7952e-04,\n",
       "            -1.7773e-03, -8.6277e-04,  2.9728e-04, -5.0571e-03, -2.0373e-04,\n",
       "             4.6186e-03, -1.2820e-03,  9.5780e-05,  3.0082e-03,  1.3017e-03,\n",
       "            -2.2325e-03, -9.6678e-05, -2.5701e-04,  2.8333e-03,  1.0359e-04,\n",
       "            -3.8733e-04,  3.0067e-04, -3.8517e-04,  3.7699e-03, -1.7172e-03,\n",
       "             1.4155e-03, -6.5227e-03,  1.0374e-04, -6.2756e-05, -3.7324e-03,\n",
       "            -1.8584e-03,  5.1165e-03,  2.5875e-06,  9.1252e-04,  1.7430e-03,\n",
       "             2.5117e-03,  1.4944e-04,  8.0064e-04, -7.7084e-04, -3.6517e-03,\n",
       "             3.0796e-03,  9.3697e-05, -3.8388e-03, -1.6181e-03,  3.0957e-03,\n",
       "             2.0938e-04]], device='cuda:1'),\n",
       "   'exp_avg_sq': tensor([[3.0328e-03, 3.4126e-03, 7.3628e-02, 3.3800e-03, 3.5641e-03, 2.4664e-01,\n",
       "            4.4148e-03, 2.9979e-02, 3.7486e-03, 3.4559e-03, 4.5114e-03, 3.9186e-03,\n",
       "            3.5066e-03, 4.2713e-03, 4.3023e-03, 4.5733e-03, 3.6848e-03, 4.1634e-03,\n",
       "            1.0632e-01, 3.8736e-03, 5.5404e-03, 4.9537e-03, 4.5024e-03, 3.8791e-03,\n",
       "            3.8883e-03, 3.4699e-03, 4.9092e-03, 4.7383e-03, 4.3556e-03, 5.3331e-03,\n",
       "            4.2290e-03, 2.4347e-01, 3.6767e-03, 5.0821e-03, 5.2659e-03, 5.2305e-03,\n",
       "            5.6258e-03, 4.0920e-03, 4.0401e-03, 4.2285e-03, 5.6050e-03, 4.0106e-03,\n",
       "            4.8100e-03, 4.2854e-03, 5.0427e-03, 3.0660e-03, 4.9318e-03, 4.3597e-03,\n",
       "            3.2849e-03, 4.6040e-03, 3.7878e-03, 4.2865e-03, 4.2684e-03, 4.9282e-03,\n",
       "            3.4535e-03, 4.1669e-03, 5.4116e-03, 4.2325e-03, 5.1855e-03, 4.3259e-03,\n",
       "            5.0172e-03, 3.3069e-03, 3.1190e-03, 4.9004e-03, 4.8317e-03, 5.5706e-03,\n",
       "            3.3765e-03, 4.4305e-03, 4.1751e-03, 4.6855e-03, 9.5737e-02, 4.1812e-03,\n",
       "            4.5849e-03, 4.3476e-02, 6.1174e-03, 4.4330e-03, 5.9778e-03, 3.7699e-03,\n",
       "            2.9680e-03, 7.3924e-03, 3.9219e-03, 4.5985e-03, 3.0234e-03, 4.1312e-03,\n",
       "            4.1195e-03, 4.6438e-03, 9.9515e-03, 3.1411e-03, 3.5163e-03, 4.4192e-03,\n",
       "            4.8538e-03, 2.6668e-03, 4.9105e-03, 4.9617e-03, 5.2051e-03, 3.9117e-03,\n",
       "            4.4945e-03, 3.7945e-03, 3.5590e-03, 4.2658e-03, 1.8065e-01, 3.6817e-03,\n",
       "            3.3494e-03, 4.2206e-03, 3.3672e-01, 2.8330e-03, 5.3984e-03, 1.2553e-01,\n",
       "            4.7509e-03, 5.2456e-03, 3.6319e-03, 4.0379e-03, 4.9336e-03, 2.7483e-03,\n",
       "            1.0299e-02, 4.9057e-03, 2.9027e-03, 9.0401e-02, 5.2106e-03, 3.5737e-03,\n",
       "            5.0547e-03, 4.7763e-03, 4.8148e-03, 1.4022e-01, 5.1882e-03, 4.6710e-03,\n",
       "            4.9803e-03, 4.5315e-03, 1.5873e-04, 3.8432e-04, 5.1764e-05, 2.5829e-03,\n",
       "            7.4121e-05, 3.7095e-05, 5.0154e-04, 5.7907e-04, 4.3473e-05, 5.2714e-05,\n",
       "            1.3766e-04, 6.5896e-05, 6.2441e-03, 6.2552e-05, 5.7354e-05, 9.3907e-05,\n",
       "            6.9888e-05, 2.2869e-04, 1.7538e-05, 9.2612e-05, 1.2798e-04, 3.2673e-05,\n",
       "            2.6588e-05, 2.5908e-04, 2.0120e-04, 5.6258e-05, 4.3269e-05, 7.1302e-05,\n",
       "            2.7356e-05, 9.6241e-05, 9.3342e-05, 5.2843e-05, 2.0824e-05, 4.3575e-05,\n",
       "            1.4279e-04, 6.6950e-05, 3.1466e-04, 5.6044e-05, 7.8064e-05, 2.8822e-05,\n",
       "            4.0491e-05, 2.3705e-05, 6.4466e-05, 4.0349e-05, 8.6312e-05, 4.6677e-04,\n",
       "            2.5253e-03, 1.7050e-04, 1.6321e-04, 5.0493e-05, 3.6263e-05, 5.0920e-05,\n",
       "            4.0534e-04, 3.9999e-05, 1.4013e-04, 2.3185e-04, 2.5569e-05, 3.2990e-04,\n",
       "            6.1803e-03, 2.9114e-05, 8.0190e-04, 6.9434e-05, 4.4301e-05, 6.2866e-04,\n",
       "            5.9673e-05, 6.8759e-05, 3.4570e-05, 8.5883e-05, 6.4638e-05, 2.0611e-04,\n",
       "            8.4651e-05, 7.4139e-05, 6.1137e-03, 3.5048e-03, 1.3916e-04, 1.4541e-04,\n",
       "            2.5789e-05, 4.1345e-04, 1.9399e-04, 1.0009e-04, 1.5611e-04, 4.9653e-05,\n",
       "            2.8269e-04, 9.3072e-04, 2.1220e-04, 3.6256e-04, 1.0243e-04, 1.7867e-04,\n",
       "            5.7312e-05, 3.3104e-05, 2.2517e-04, 6.9040e-05, 2.1340e-04, 6.2271e-05,\n",
       "            3.8416e-05, 1.1168e-04, 8.3228e-05, 2.3359e-04, 3.5346e-05, 4.2265e-05,\n",
       "            1.4470e-04, 4.1480e-05, 3.2651e-05, 4.5282e-05, 4.8721e-05, 1.7848e-04,\n",
       "            8.8601e-05, 1.0888e-04, 3.7139e-04, 2.4023e-05, 2.3611e-05, 2.9720e-04,\n",
       "            6.8917e-05, 3.1853e-04, 2.8875e-05, 1.4109e-04, 9.1117e-05, 3.8089e-04,\n",
       "            2.1431e-05, 7.3378e-05, 4.5794e-05, 2.5986e-04, 1.4083e-04, 2.9745e-05,\n",
       "            1.5642e-04, 7.3053e-05, 1.4609e-04, 3.4394e-05],\n",
       "           [3.3258e-03, 3.7696e-03, 7.9990e-02, 3.1034e-03, 3.6093e-03, 2.6181e-01,\n",
       "            4.5931e-03, 3.2407e-02, 4.3534e-03, 3.5146e-03, 4.4063e-03, 4.0293e-03,\n",
       "            3.7615e-03, 4.4995e-03, 4.5194e-03, 4.7267e-03, 3.8167e-03, 4.2127e-03,\n",
       "            1.0616e-01, 3.3798e-03, 6.0850e-03, 5.0042e-03, 4.5522e-03, 3.9021e-03,\n",
       "            3.7842e-03, 3.5796e-03, 5.3539e-03, 4.6956e-03, 4.2835e-03, 4.8893e-03,\n",
       "            4.5993e-03, 2.5259e-01, 3.9497e-03, 5.3788e-03, 4.8620e-03, 4.6148e-03,\n",
       "            5.7144e-03, 3.8114e-03, 4.8786e-03, 4.8851e-03, 5.1251e-03, 4.1551e-03,\n",
       "            5.2265e-03, 4.2514e-03, 5.9411e-03, 3.1578e-03, 4.9659e-03, 3.8303e-03,\n",
       "            3.6272e-03, 4.9308e-03, 4.0536e-03, 4.9895e-03, 4.5245e-03, 5.4867e-03,\n",
       "            3.5963e-03, 4.6538e-03, 6.4787e-03, 4.4088e-03, 5.1944e-03, 4.4678e-03,\n",
       "            4.9501e-03, 3.5234e-03, 3.3250e-03, 5.2227e-03, 5.6448e-03, 5.6135e-03,\n",
       "            3.4209e-03, 4.5627e-03, 4.7678e-03, 5.0175e-03, 9.9483e-02, 4.9156e-03,\n",
       "            4.5320e-03, 4.8167e-02, 5.8225e-03, 4.5389e-03, 5.7267e-03, 4.0227e-03,\n",
       "            3.2407e-03, 8.6372e-03, 3.5867e-03, 4.9219e-03, 2.9963e-03, 4.7075e-03,\n",
       "            4.1385e-03, 4.9810e-03, 8.8542e-03, 3.3391e-03, 3.9151e-03, 4.5850e-03,\n",
       "            5.2114e-03, 2.7558e-03, 5.0694e-03, 4.2933e-03, 5.3467e-03, 4.1933e-03,\n",
       "            4.9109e-03, 3.8914e-03, 3.4232e-03, 4.2926e-03, 2.1848e-01, 3.7126e-03,\n",
       "            3.3186e-03, 4.5244e-03, 4.2638e-01, 3.1955e-03, 6.0110e-03, 1.3752e-01,\n",
       "            4.6917e-03, 5.2671e-03, 3.6641e-03, 4.1544e-03, 5.6014e-03, 3.0351e-03,\n",
       "            9.9695e-03, 4.8162e-03, 3.2168e-03, 1.0432e-01, 5.0268e-03, 4.0643e-03,\n",
       "            5.4365e-03, 4.9106e-03, 4.7788e-03, 1.6069e-01, 5.3852e-03, 5.2376e-03,\n",
       "            4.9438e-03, 4.7273e-03, 2.0725e-04, 6.0689e-04, 6.2294e-05, 3.7258e-03,\n",
       "            9.6600e-05, 4.7512e-05, 7.2081e-04, 6.9028e-04, 5.5879e-05, 6.4095e-05,\n",
       "            1.7602e-04, 7.6768e-05, 8.7684e-03, 1.0191e-04, 6.6332e-05, 1.1481e-04,\n",
       "            1.2633e-04, 2.8587e-04, 2.3844e-05, 1.4159e-04, 1.6772e-04, 6.8949e-05,\n",
       "            3.9176e-05, 3.7923e-04, 2.5641e-04, 6.9995e-05, 4.5431e-05, 1.1313e-04,\n",
       "            4.9896e-05, 1.1375e-04, 1.4854e-04, 7.4031e-05, 2.1845e-05, 5.7551e-05,\n",
       "            1.6085e-04, 1.0907e-04, 4.7838e-04, 7.3546e-05, 1.1971e-04, 3.4546e-05,\n",
       "            5.8795e-05, 3.2594e-05, 9.3403e-05, 8.7483e-05, 1.0911e-04, 6.6761e-04,\n",
       "            3.5835e-03, 2.1065e-04, 2.1529e-04, 6.8557e-05, 5.3782e-05, 6.7789e-05,\n",
       "            6.1342e-04, 4.5803e-05, 1.7389e-04, 2.9320e-04, 4.7027e-05, 3.6974e-04,\n",
       "            8.5658e-03, 4.3798e-05, 1.1196e-03, 7.3224e-05, 8.3320e-05, 9.1178e-04,\n",
       "            1.0011e-04, 9.3859e-05, 5.4736e-05, 1.0143e-04, 8.4063e-05, 2.3978e-04,\n",
       "            1.0255e-04, 1.1662e-04, 8.4557e-03, 4.6904e-03, 1.7227e-04, 2.2204e-04,\n",
       "            4.6126e-05, 6.7340e-04, 2.6551e-04, 1.2854e-04, 2.1391e-04, 5.8910e-05,\n",
       "            4.2134e-04, 1.3878e-03, 2.6834e-04, 4.4524e-04, 1.4403e-04, 2.2435e-04,\n",
       "            6.9875e-05, 5.6107e-05, 3.1032e-04, 9.8301e-05, 2.8685e-04, 8.8677e-05,\n",
       "            4.8775e-05, 1.3743e-04, 1.4284e-04, 3.5384e-04, 5.4307e-05, 6.6597e-05,\n",
       "            1.7394e-04, 7.1939e-05, 4.1334e-05, 7.0098e-05, 7.7168e-05, 2.0177e-04,\n",
       "            1.0631e-04, 1.4458e-04, 5.4609e-04, 4.9363e-05, 3.6979e-05, 3.2178e-04,\n",
       "            8.1510e-05, 5.0306e-04, 4.2402e-05, 2.2681e-04, 1.4020e-04, 5.7804e-04,\n",
       "            2.0496e-05, 9.0762e-05, 7.2355e-05, 3.8888e-04, 1.6022e-04, 4.3064e-05,\n",
       "            1.8364e-04, 9.7471e-05, 1.8667e-04, 4.8197e-05],\n",
       "           [4.0970e-03, 4.9557e-03, 1.0201e-01, 4.1159e-03, 4.3797e-03, 2.8962e-01,\n",
       "            5.5838e-03, 3.8320e-02, 5.5409e-03, 4.8152e-03, 4.9258e-03, 5.2437e-03,\n",
       "            4.7338e-03, 5.6874e-03, 5.8006e-03, 6.1129e-03, 4.8967e-03, 5.3147e-03,\n",
       "            1.1538e-01, 4.4482e-03, 6.9932e-03, 6.1492e-03, 5.7489e-03, 5.5844e-03,\n",
       "            5.0445e-03, 4.5238e-03, 6.2436e-03, 5.8993e-03, 5.5378e-03, 6.4011e-03,\n",
       "            5.9078e-03, 2.8175e-01, 4.5561e-03, 7.1709e-03, 6.9910e-03, 7.1380e-03,\n",
       "            6.5699e-03, 5.0996e-03, 6.1049e-03, 6.2140e-03, 7.4901e-03, 5.6163e-03,\n",
       "            6.3846e-03, 5.3842e-03, 7.3006e-03, 4.0784e-03, 6.9108e-03, 5.5475e-03,\n",
       "            4.5804e-03, 5.7379e-03, 4.9539e-03, 6.4106e-03, 5.7628e-03, 6.5360e-03,\n",
       "            5.0508e-03, 5.9717e-03, 7.7814e-03, 5.9037e-03, 6.2008e-03, 5.5866e-03,\n",
       "            6.4929e-03, 4.5886e-03, 4.2979e-03, 6.9062e-03, 6.5616e-03, 6.8191e-03,\n",
       "            4.6662e-03, 5.9282e-03, 5.6090e-03, 6.7661e-03, 1.1778e-01, 6.0542e-03,\n",
       "            6.1600e-03, 5.8412e-02, 7.8676e-03, 5.8827e-03, 7.3272e-03, 5.5735e-03,\n",
       "            4.2435e-03, 1.0283e-02, 5.0245e-03, 5.8017e-03, 3.7916e-03, 5.7803e-03,\n",
       "            5.5759e-03, 6.7144e-03, 1.0326e-02, 4.8643e-03, 4.7296e-03, 5.7335e-03,\n",
       "            5.7921e-03, 3.3266e-03, 6.8127e-03, 6.2282e-03, 6.3965e-03, 5.2178e-03,\n",
       "            6.4015e-03, 4.7717e-03, 4.9503e-03, 6.0050e-03, 2.7748e-01, 4.9020e-03,\n",
       "            4.2484e-03, 5.8908e-03, 5.3307e-01, 4.0195e-03, 7.5226e-03, 1.8050e-01,\n",
       "            5.1388e-03, 6.4907e-03, 4.5302e-03, 5.1611e-03, 7.1940e-03, 3.6729e-03,\n",
       "            1.2799e-02, 5.9402e-03, 4.3137e-03, 1.3262e-01, 6.5241e-03, 4.8068e-03,\n",
       "            6.7746e-03, 6.3120e-03, 6.5664e-03, 2.0779e-01, 7.0017e-03, 6.0041e-03,\n",
       "            6.0560e-03, 5.9171e-03, 2.6625e-04, 7.7583e-04, 8.8907e-05, 5.1083e-03,\n",
       "            1.3307e-04, 6.5053e-05, 1.0220e-03, 1.0389e-03, 7.2184e-05, 1.0203e-04,\n",
       "            2.3308e-04, 1.2853e-04, 1.1824e-02, 1.6082e-04, 8.7099e-05, 1.6639e-04,\n",
       "            1.6653e-04, 3.8598e-04, 3.3659e-05, 1.7815e-04, 2.2349e-04, 9.5958e-05,\n",
       "            5.1755e-05, 5.6281e-04, 3.3989e-04, 9.7294e-05, 6.7631e-05, 1.6485e-04,\n",
       "            9.7762e-05, 1.5648e-04, 1.9437e-04, 9.4015e-05, 3.5061e-05, 8.1444e-05,\n",
       "            2.1319e-04, 1.5127e-04, 6.7796e-04, 9.5490e-05, 1.4921e-04, 6.2152e-05,\n",
       "            9.1273e-05, 4.1534e-05, 1.4318e-04, 1.0430e-04, 1.5488e-04, 9.5072e-04,\n",
       "            4.9295e-03, 2.8232e-04, 2.8376e-04, 8.9781e-05, 7.9971e-05, 8.4297e-05,\n",
       "            7.7572e-04, 7.5575e-05, 2.4381e-04, 3.9765e-04, 5.9240e-05, 4.8596e-04,\n",
       "            1.1636e-02, 5.4430e-05, 1.6043e-03, 1.1014e-04, 1.3247e-04, 1.2621e-03,\n",
       "            1.2460e-04, 1.3372e-04, 7.7322e-05, 1.4255e-04, 1.1395e-04, 3.2096e-04,\n",
       "            1.4460e-04, 1.7690e-04, 1.1569e-02, 6.5680e-03, 2.3398e-04, 2.8763e-04,\n",
       "            6.8113e-05, 8.5693e-04, 3.8865e-04, 1.8339e-04, 2.9200e-04, 8.5487e-05,\n",
       "            5.5874e-04, 1.9017e-03, 3.3783e-04, 5.7936e-04, 2.1527e-04, 3.2300e-04,\n",
       "            1.0440e-04, 8.2269e-05, 4.1200e-04, 1.5439e-04, 3.9358e-04, 1.3809e-04,\n",
       "            6.7889e-05, 2.0918e-04, 2.0659e-04, 5.0011e-04, 8.0076e-05, 1.1105e-04,\n",
       "            2.2607e-04, 9.6709e-05, 5.5760e-05, 1.0405e-04, 1.1109e-04, 2.5738e-04,\n",
       "            1.4831e-04, 1.9331e-04, 6.5837e-04, 8.1993e-05, 5.1293e-05, 4.4032e-04,\n",
       "            1.0635e-04, 6.5526e-04, 5.9836e-05, 3.3167e-04, 2.0458e-04, 7.8831e-04,\n",
       "            3.1496e-05, 1.2438e-04, 8.8644e-05, 4.9908e-04, 2.1244e-04, 6.7224e-05,\n",
       "            2.4875e-04, 1.2103e-04, 2.3464e-04, 7.1905e-05]], device='cuda:1')},\n",
       "  7: {'step': 3545,\n",
       "   'exp_avg': tensor([ 0.0157, -0.0011, -0.0146], device='cuda:1'),\n",
       "   'exp_avg_sq': tensor([0.0104, 0.0108, 0.0137], device='cuda:1')},\n",
       "  8: {'step': 3545,\n",
       "   'exp_avg': tensor([[ 9.6884e-05, -6.3922e-05, -1.3613e-05,  ..., -9.9153e-06,\n",
       "            -1.0741e-05, -2.0973e-06],\n",
       "           [ 9.9922e-06, -4.2508e-05,  1.7788e-05,  ...,  4.5307e-05,\n",
       "            -2.7889e-05, -1.1883e-05],\n",
       "           [-1.4339e-05, -7.1051e-06,  6.4740e-06,  ...,  2.1358e-05,\n",
       "            -3.4603e-05, -2.9227e-05],\n",
       "           ...,\n",
       "           [-4.0733e-05, -1.4776e-05, -1.0186e-05,  ...,  4.8140e-05,\n",
       "            -4.2292e-05, -2.7654e-05],\n",
       "           [ 1.0035e-04, -8.5435e-05, -3.3275e-05,  ...,  5.6346e-05,\n",
       "            -4.3329e-05,  1.8110e-05],\n",
       "           [ 5.8407e-05, -3.0027e-05, -4.9228e-05,  ..., -3.2980e-05,\n",
       "             3.6291e-05,  3.6294e-05]], device='cuda:1'),\n",
       "   'exp_avg_sq': tensor([[9.8795e-09, 3.8423e-08, 8.5207e-09,  ..., 1.0552e-08, 8.7811e-09,\n",
       "            1.8193e-08],\n",
       "           [1.3890e-08, 4.9567e-08, 1.2190e-08,  ..., 1.4499e-08, 1.2283e-08,\n",
       "            2.6635e-08],\n",
       "           [1.8047e-08, 6.1248e-08, 1.5102e-08,  ..., 1.6526e-08, 1.6036e-08,\n",
       "            3.5970e-08],\n",
       "           ...,\n",
       "           [5.6713e-08, 1.7895e-07, 4.8821e-08,  ..., 5.5444e-08, 5.0440e-08,\n",
       "            1.1392e-07],\n",
       "           [2.1555e-08, 7.7910e-08, 1.7734e-08,  ..., 1.9307e-08, 1.8227e-08,\n",
       "            4.3629e-08],\n",
       "           [6.2657e-08, 1.9808e-07, 5.4874e-08,  ..., 6.2323e-08, 5.9382e-08,\n",
       "            1.1767e-07]], device='cuda:1')},\n",
       "  9: {'step': 3545,\n",
       "   'exp_avg': tensor([ 3.0142e-05, -4.4773e-05,  4.6972e-05,  1.8611e-05, -1.3856e-05,\n",
       "            1.2089e-06,  1.4339e-03, -3.5096e-04,  4.8839e-05, -6.0975e-06,\n",
       "            4.9541e-04,  3.1186e-05, -2.0933e-04, -4.0631e-05, -1.2151e-04,\n",
       "           -1.5220e-05,  8.8706e-05, -1.8499e-04, -9.1351e-04,  1.3263e-05,\n",
       "           -1.9047e-05, -1.5980e-06, -4.7016e-05, -6.5773e-06,  6.8643e-05,\n",
       "            7.3644e-04, -2.7837e-04, -7.1001e-05, -2.0488e-04,  5.4960e-05,\n",
       "           -6.9044e-06, -8.5202e-06,  5.7761e-05, -1.0006e-04,  2.3173e-05,\n",
       "            1.4183e-03, -1.5533e-05,  7.4342e-05,  4.5883e-05, -4.9347e-04,\n",
       "           -3.9343e-05,  2.9824e-05,  3.1171e-04,  6.3763e-06,  7.5873e-05,\n",
       "           -5.3739e-05,  1.8923e-04, -2.2220e-04,  2.0030e-05, -4.9225e-05,\n",
       "            3.5168e-06, -3.0694e-05,  5.4730e-05,  2.3949e-04,  5.8474e-05,\n",
       "           -1.4621e-06,  2.9711e-05, -2.4437e-05, -3.8282e-04, -9.1436e-05,\n",
       "           -1.0663e-05, -1.9206e-04,  5.0098e-05,  7.9552e-05, -6.6369e-05,\n",
       "            6.5779e-05,  3.8634e-05,  5.7602e-05,  6.5425e-05,  4.2504e-05,\n",
       "            1.4189e-03, -2.1745e-04, -7.9908e-05, -7.0327e-05, -7.2451e-05,\n",
       "           -2.0305e-05, -6.2273e-05,  1.3413e-04, -3.6454e-06,  3.4172e-06,\n",
       "           -1.2217e-06, -1.0261e-03, -3.0957e-05,  1.6734e-04, -3.1258e-04,\n",
       "            1.5740e-04,  6.8822e-05,  1.6704e-04, -5.1806e-05,  1.0843e-04,\n",
       "           -2.0017e-04,  3.3675e-05,  1.2095e-04, -1.0697e-06,  3.0233e-04,\n",
       "            1.5481e-04,  1.5968e-05,  3.6868e-05, -1.8532e-04, -4.2543e-05,\n",
       "            1.0851e-05,  1.0825e-04,  6.2431e-04,  2.1627e-05,  2.9526e-05,\n",
       "           -9.1393e-04, -1.3124e-04, -1.0174e-04, -5.7360e-05, -1.4958e-04,\n",
       "            2.2831e-05,  7.4480e-06,  2.8288e-05, -9.1843e-05,  4.3554e-05,\n",
       "            8.0525e-05, -2.9590e-05,  1.7784e-04, -1.7700e-04,  6.4965e-05,\n",
       "            3.0757e-05,  2.9335e-05,  5.5687e-05, -5.2549e-04, -5.4247e-07,\n",
       "           -2.9084e-05, -3.9172e-05, -3.5569e-04,  3.7408e-04,  4.4188e-06,\n",
       "            1.3437e-04,  1.0029e-04,  2.7831e-04, -2.2744e-05, -9.0786e-05,\n",
       "           -6.8043e-05,  5.0738e-05, -2.0988e-05, -2.8983e-05,  2.6583e-04,\n",
       "            1.2397e-04,  2.4222e-04, -2.5370e-05,  6.8000e-05, -6.0439e-04,\n",
       "            4.4635e-05, -4.9621e-05, -1.0383e-03, -2.5799e-05,  1.0831e-04,\n",
       "           -6.2061e-05,  2.9213e-04,  5.3374e-05, -3.9350e-05,  9.8212e-05,\n",
       "           -3.7373e-04, -6.3657e-05, -7.3558e-05, -1.3372e-04, -3.2503e-05,\n",
       "            6.7249e-05,  5.5247e-05, -1.1723e-04,  4.1782e-05,  3.1250e-05,\n",
       "           -6.5897e-05, -1.7563e-05,  9.1275e-05,  1.4531e-04,  9.3496e-05,\n",
       "            1.1167e-05, -1.0088e-05, -1.5683e-05,  2.5653e-05,  9.4033e-05,\n",
       "            1.2451e-05,  4.4751e-05, -1.5156e-04,  4.4840e-05,  6.5418e-05,\n",
       "           -4.8845e-05,  4.2904e-05, -2.8331e-04, -3.5974e-05,  2.1517e-05,\n",
       "           -6.1737e-04, -9.9714e-05, -1.1812e-05,  1.1941e-04,  4.0760e-04,\n",
       "           -3.6584e-07,  7.0870e-05,  3.7767e-06, -2.0764e-06, -2.6482e-05,\n",
       "            2.4039e-04,  1.6675e-04,  2.5719e-04, -1.5356e-05,  3.5743e-06,\n",
       "           -1.6401e-04, -2.0683e-04,  5.1834e-05, -1.9303e-05, -9.5001e-05,\n",
       "           -1.4696e-04,  1.4757e-04,  9.3914e-05, -2.0895e-05,  2.4023e-04,\n",
       "            1.2015e-05,  4.6316e-07, -2.8528e-04,  1.8801e-05, -2.6213e-04,\n",
       "           -2.3543e-05, -7.4561e-05, -8.0399e-05, -2.0990e-04, -1.3468e-04,\n",
       "           -1.2752e-04, -3.9143e-05,  7.5232e-06, -7.5143e-06,  2.3838e-05,\n",
       "            3.1645e-05,  9.6618e-06, -1.3388e-04,  1.9608e-04, -9.3916e-05,\n",
       "           -4.9608e-04,  3.3813e-05,  2.5701e-04, -9.7755e-06, -2.2952e-05,\n",
       "           -2.0183e-04, -4.6851e-05, -5.7986e-06,  8.1496e-06,  1.2370e-04,\n",
       "            7.0723e-05,  1.2243e-05,  4.3688e-05,  8.1897e-04,  2.8609e-06,\n",
       "           -7.9148e-04,  1.4206e-04, -5.9383e-05,  5.3195e-05, -3.9377e-05,\n",
       "           -4.2151e-07,  4.2056e-05, -2.3982e-04, -5.6055e-05, -4.1900e-05,\n",
       "           -4.9305e-04, -7.7343e-05,  1.3093e-04, -1.1849e-04,  3.5599e-05,\n",
       "            7.9806e-04,  2.1265e-05, -5.7257e-06,  1.4548e-04,  1.0150e-06,\n",
       "            9.6632e-05, -8.7153e-05,  4.2516e-06,  3.2358e-05, -7.9912e-05,\n",
       "            7.7347e-05,  1.9862e-05,  3.4886e-04,  3.6915e-05,  5.5271e-05,\n",
       "           -1.0292e-04, -3.6905e-05, -5.3068e-05,  4.8590e-05,  1.7169e-04,\n",
       "            3.3011e-04, -3.5905e-05,  1.4042e-06, -4.0866e-05,  9.1400e-05,\n",
       "            2.9969e-05, -1.2221e-04,  3.3204e-05,  6.2151e-04, -3.7936e-05,\n",
       "            5.0902e-05,  1.5877e-05, -2.8973e-04, -4.6298e-05, -2.1458e-05,\n",
       "           -6.3079e-05, -9.7039e-06,  1.0807e-04, -6.3608e-04,  7.8055e-06,\n",
       "            2.3578e-05, -2.4189e-06,  5.4005e-04,  1.2072e-03,  6.4740e-05,\n",
       "           -4.3283e-06,  8.7231e-05,  2.5991e-04, -1.5302e-05,  9.7945e-05,\n",
       "            5.1409e-05,  4.6497e-05, -7.7018e-05, -1.9396e-04,  3.4601e-05,\n",
       "           -1.0641e-05, -9.4862e-05,  1.0131e-05,  1.3721e-06,  2.4174e-05,\n",
       "            2.1150e-05, -2.3738e-05, -1.8931e-04,  1.0768e-04,  6.0245e-05,\n",
       "           -4.3133e-05,  8.5258e-05, -5.4771e-05,  2.1130e-04,  8.5641e-06,\n",
       "            8.6961e-06, -1.7999e-05,  1.0552e-04,  2.1339e-05,  9.0593e-07,\n",
       "           -1.7517e-05, -7.5765e-06, -1.1278e-04,  2.5783e-04, -1.1740e-06,\n",
       "           -7.8155e-05, -8.8727e-06, -8.4816e-05, -1.2229e-04, -9.7738e-04,\n",
       "            1.5488e-05, -4.2350e-04,  6.7550e-05,  1.1513e-04,  5.1851e-05,\n",
       "            3.9816e-06,  3.3164e-04,  2.0270e-05,  7.8567e-05, -1.0330e-05,\n",
       "           -4.4577e-05, -7.0443e-05,  5.4836e-05, -2.6850e-06,  5.0432e-05,\n",
       "            8.8664e-05, -1.6437e-05,  6.1443e-06, -7.4530e-05,  7.3796e-04,\n",
       "            2.3785e-04, -1.1298e-05, -2.6481e-05, -2.9503e-05,  1.1306e-04,\n",
       "           -3.0346e-04,  8.6663e-05, -3.2155e-05,  8.0625e-04,  7.4408e-05,\n",
       "            9.9181e-05, -3.2841e-05, -1.4533e-04,  1.3289e-04,  4.5785e-05,\n",
       "           -1.4018e-06, -5.5518e-06, -7.2616e-05,  7.0738e-06,  9.9173e-06,\n",
       "           -5.6722e-05, -3.6086e-06, -1.5275e-05,  5.2765e-05, -9.8688e-06,\n",
       "           -3.6062e-04,  4.2440e-05,  7.8212e-04,  9.9085e-05, -4.4378e-04,\n",
       "           -2.1469e-04,  7.1582e-05,  4.8057e-06,  5.5055e-07, -1.8228e-04,\n",
       "           -2.4318e-04, -1.5908e-05, -3.7767e-05, -7.5232e-05,  3.3413e-05,\n",
       "           -6.8198e-05,  8.5890e-04,  1.0404e-05,  1.3670e-04,  1.3661e-05,\n",
       "            1.1202e-04,  2.9735e-05, -1.0293e-04,  1.4914e-05, -4.2885e-05,\n",
       "            6.1127e-06,  2.0966e-04,  1.1387e-04,  2.6338e-04, -5.6367e-05,\n",
       "           -1.9721e-05, -1.9668e-04,  2.7513e-05,  1.4935e-04,  1.1005e-03,\n",
       "            6.0852e-05, -3.0616e-04, -1.6845e-05, -2.9986e-04, -3.0754e-04,\n",
       "            2.9494e-05,  1.1702e-04,  1.4812e-05,  1.6429e-06,  5.8307e-04,\n",
       "            1.0725e-05, -3.1900e-06,  1.9052e-05,  1.4839e-06,  2.1140e-06,\n",
       "            2.2921e-05,  1.8666e-04, -1.1986e-04, -2.2709e-04, -2.1962e-05,\n",
       "           -9.2346e-05, -1.5291e-05,  3.0441e-05,  3.1362e-05,  4.2618e-05,\n",
       "           -5.4641e-05, -4.4371e-05,  6.3453e-05, -4.9756e-05,  3.2601e-05,\n",
       "           -6.0835e-05,  1.2662e-04,  1.9870e-05,  7.1019e-05,  5.2620e-05,\n",
       "            2.4754e-04,  2.9528e-05, -2.4375e-06,  3.3013e-04,  2.4133e-04,\n",
       "            1.5153e-05,  9.5584e-05,  2.1614e-05,  4.6559e-05, -1.1622e-04,\n",
       "            1.1309e-05,  6.6256e-05, -4.7350e-05, -1.5827e-04, -5.1339e-05,\n",
       "            3.3817e-04, -2.1399e-05, -9.0332e-05, -1.9589e-05,  7.2117e-05,\n",
       "           -8.2332e-05,  7.2615e-05, -2.5495e-05, -4.6852e-05,  1.0368e-04,\n",
       "           -1.0843e-05,  3.3083e-05, -1.1286e-05,  3.1788e-04, -2.4398e-05,\n",
       "           -1.1386e-05,  5.0077e-05, -7.5566e-05, -7.3291e-05,  1.2020e-05,\n",
       "           -6.7577e-04,  3.8144e-05,  2.2511e-05,  2.2668e-05,  4.4730e-06,\n",
       "           -1.8988e-04, -1.6073e-04,  4.3929e-05,  1.7314e-03, -8.4178e-05,\n",
       "            4.9287e-06,  1.5811e-05,  5.9251e-04, -2.2833e-06,  6.5536e-05,\n",
       "           -3.3660e-05,  1.1184e-04,  5.6146e-05, -1.2184e-04, -3.4231e-04,\n",
       "           -3.9743e-05, -4.5254e-05, -3.8623e-05, -8.2674e-05,  1.6049e-05,\n",
       "            1.6886e-04, -2.2021e-05, -1.0188e-04,  4.5435e-04,  6.2072e-06,\n",
       "            7.9535e-05,  9.6929e-05,  3.5011e-04, -1.1387e-04, -3.0185e-04,\n",
       "           -1.6006e-04, -9.2843e-05, -4.0777e-06, -3.4855e-04, -5.3786e-05,\n",
       "            4.0616e-05,  9.5808e-05, -1.0644e-04,  1.4317e-05, -9.3017e-05,\n",
       "           -1.3922e-05,  8.9511e-05,  6.0515e-05,  1.6400e-05, -1.9878e-05,\n",
       "           -9.2661e-06,  4.3559e-05, -6.3073e-05,  1.1356e-05,  5.4203e-04,\n",
       "            2.5071e-05,  5.4294e-05, -1.1377e-05, -1.4791e-03, -5.0854e-05,\n",
       "           -1.3302e-05,  1.8608e-05, -3.5242e-06, -1.0423e-04, -3.5642e-05,\n",
       "           -3.2563e-05,  3.1474e-04,  1.5035e-05, -2.1512e-05, -7.6807e-05,\n",
       "            1.2582e-05,  1.0400e-05,  5.8373e-05,  6.2780e-05, -1.3074e-04,\n",
       "            1.6373e-04,  2.7112e-04,  3.0609e-04, -2.0764e-04,  5.2355e-05,\n",
       "            2.4031e-05, -1.7554e-04, -1.9532e-06, -7.6408e-05, -7.6219e-05,\n",
       "            5.2859e-04, -1.7322e-05,  3.4148e-04,  1.0398e-04, -2.5915e-04,\n",
       "            6.5751e-05, -2.0292e-04, -9.6816e-06, -7.2789e-07, -2.5185e-05,\n",
       "            5.4954e-05, -4.3573e-05, -5.3205e-05, -4.5745e-05, -4.4412e-05,\n",
       "            2.3969e-05, -7.6086e-05,  6.7658e-05, -2.0788e-04,  4.5703e-05,\n",
       "           -7.5962e-05,  1.6673e-05, -1.2702e-04, -7.5185e-05, -4.8304e-05,\n",
       "           -2.5288e-05, -1.4320e-05,  5.3653e-05, -5.8343e-05, -6.3477e-04,\n",
       "           -7.8136e-05, -1.1004e-06, -2.8374e-05,  1.0346e-05, -5.8219e-06,\n",
       "            1.9998e-05,  3.4105e-05,  1.1817e-04, -1.3012e-04, -1.0069e-05,\n",
       "            2.3111e-04, -5.0824e-04, -1.5217e-04, -4.5660e-05,  1.0846e-04,\n",
       "            1.5063e-04,  1.0817e-04,  4.7801e-05,  9.1976e-05, -7.8476e-05,\n",
       "           -3.3819e-05, -1.3101e-04, -1.2009e-04, -1.1787e-04, -1.6922e-04,\n",
       "            2.8367e-07, -5.0310e-06, -7.0995e-05, -1.8786e-04,  3.2369e-05,\n",
       "           -1.9151e-05,  1.7646e-05,  3.9155e-05,  3.8140e-05,  1.2025e-04,\n",
       "            1.2940e-04, -2.7967e-05, -3.5499e-04,  9.0720e-06,  7.5114e-06,\n",
       "            3.8341e-05, -1.5012e-05,  2.2993e-05, -5.5986e-04,  3.6148e-05,\n",
       "           -4.4949e-05, -3.9711e-05,  3.5299e-05,  1.8034e-05,  8.8970e-05,\n",
       "           -1.3253e-05,  6.4320e-05,  1.0549e-04,  4.7967e-05,  1.8023e-05,\n",
       "            1.9477e-05, -9.5982e-05,  4.3793e-05, -9.1863e-06, -2.1362e-06,\n",
       "           -4.1715e-05, -6.1952e-05,  9.8756e-05, -2.9399e-04, -2.7283e-05,\n",
       "           -3.3233e-05, -6.9330e-05, -7.7001e-06,  4.7402e-05,  4.2793e-05,\n",
       "           -3.6896e-05, -3.0536e-04, -9.1867e-05, -2.2101e-05,  3.8098e-05,\n",
       "           -5.2848e-05, -3.7161e-05, -4.3622e-05,  3.4573e-04, -3.1454e-05,\n",
       "           -5.4758e-05, -7.8265e-05,  2.9481e-04, -4.6508e-05, -7.3895e-05,\n",
       "            2.4631e-05,  2.0113e-05,  1.4916e-06,  7.6772e-05, -2.4323e-04,\n",
       "            7.1147e-04, -6.2835e-05,  1.0581e-04, -1.6242e-05,  2.1406e-04,\n",
       "            1.7306e-04, -5.0911e-05, -5.6750e-05, -6.3475e-05,  1.3932e-03,\n",
       "            3.3057e-05, -3.0002e-05,  4.1262e-04,  1.6901e-04, -1.0609e-04,\n",
       "            9.5649e-06, -2.0100e-04, -5.6331e-05,  1.1786e-04, -8.2273e-05,\n",
       "            1.6171e-04,  6.6962e-05,  3.2335e-05,  3.4305e-05, -1.3075e-05,\n",
       "            3.4930e-05,  1.0227e-04,  3.4517e-04, -2.1795e-04, -2.3704e-05,\n",
       "            1.5615e-04,  3.1552e-05,  8.8270e-05,  9.3629e-05,  4.0316e-05,\n",
       "            7.5222e-06,  7.4944e-05, -1.8241e-05,  6.9409e-05,  8.4053e-05,\n",
       "           -2.4499e-04,  3.5418e-04,  1.0005e-04, -1.2741e-04, -2.5247e-05,\n",
       "           -5.5744e-05,  3.1075e-04,  2.1348e-05, -6.3781e-05, -5.3042e-05,\n",
       "           -3.7599e-05,  1.1571e-05, -1.6518e-06, -6.9185e-05, -4.0013e-04,\n",
       "            2.1723e-05,  7.3676e-05,  1.0381e-03,  2.6029e-05,  9.1183e-05,\n",
       "            2.0432e-04,  9.6454e-05, -2.8465e-05,  4.0356e-05, -7.4533e-05,\n",
       "           -2.2482e-05,  1.1329e-04, -2.2848e-05], device='cuda:1'),\n",
       "   'exp_avg_sq': tensor([1.4728e-07, 2.1873e-07, 2.9039e-07, 1.7719e-07, 3.2689e-07, 1.2070e-06,\n",
       "           6.1585e-06, 1.9367e-06, 2.9132e-07, 4.2049e-07, 2.0485e-06, 8.7574e-08,\n",
       "           1.5600e-06, 2.0961e-07, 4.0611e-07, 4.7223e-07, 2.7423e-07, 2.9318e-06,\n",
       "           5.3832e-06, 4.9595e-07, 2.3649e-07, 2.5609e-07, 2.5315e-07, 5.1073e-07,\n",
       "           1.4357e-06, 6.1877e-06, 1.8540e-06, 1.2177e-07, 1.5204e-06, 5.3446e-07,\n",
       "           9.9245e-07, 2.9750e-07, 2.2077e-07, 1.3290e-06, 5.1785e-07, 8.5160e-06,\n",
       "           2.4106e-07, 2.6677e-06, 5.3601e-07, 2.1459e-06, 3.9890e-06, 2.5023e-07,\n",
       "           2.7239e-06, 2.6121e-07, 2.8259e-07, 2.2425e-07, 1.7345e-06, 1.6373e-07,\n",
       "           3.0649e-07, 4.0135e-07, 2.0555e-07, 6.6091e-07, 2.0770e-07, 1.0006e-06,\n",
       "           5.9346e-07, 2.6036e-07, 1.5425e-07, 4.2810e-07, 1.3744e-06, 7.4915e-06,\n",
       "           6.5236e-06, 9.9459e-07, 2.2615e-07, 1.7553e-06, 1.4748e-06, 2.2018e-07,\n",
       "           2.5515e-07, 1.9716e-07, 1.6213e-07, 7.8763e-06, 6.2738e-06, 2.8017e-07,\n",
       "           1.3931e-06, 1.5929e-07, 2.0250e-07, 8.3988e-07, 1.8507e-07, 5.1350e-07,\n",
       "           1.7600e-07, 1.6689e-07, 4.8677e-07, 8.2769e-06, 2.1085e-07, 1.8616e-07,\n",
       "           2.7062e-06, 1.6955e-07, 1.1133e-06, 1.8621e-06, 1.4651e-07, 2.3040e-06,\n",
       "           2.8991e-07, 3.5064e-07, 2.2055e-07, 4.0156e-07, 2.0510e-06, 1.6283e-06,\n",
       "           8.0939e-07, 5.5351e-06, 1.0646e-06, 1.1062e-06, 2.3904e-07, 1.7713e-07,\n",
       "           7.0671e-06, 5.6750e-07, 2.2095e-07, 2.2899e-06, 7.4641e-07, 1.9923e-07,\n",
       "           1.2188e-07, 8.6139e-06, 1.0875e-07, 2.6038e-06, 3.2206e-07, 1.8203e-07,\n",
       "           4.0635e-06, 2.1126e-07, 1.1237e-06, 1.8518e-07, 8.1212e-07, 3.8317e-07,\n",
       "           2.1469e-07, 2.5046e-07, 6.0978e-07, 5.5926e-06, 5.7276e-07, 4.9090e-07,\n",
       "           6.4761e-07, 1.6785e-07, 1.0469e-06, 1.1313e-07, 5.2926e-07, 3.1299e-06,\n",
       "           2.5745e-06, 1.9877e-07, 1.4620e-06, 6.0294e-07, 8.0303e-08, 1.6788e-07,\n",
       "           1.6759e-07, 2.2373e-06, 1.2366e-06, 2.2594e-06, 2.0923e-07, 1.6879e-07,\n",
       "           2.6794e-06, 2.3922e-07, 4.2917e-07, 5.4368e-06, 2.4740e-07, 3.7535e-07,\n",
       "           1.6266e-07, 2.5997e-06, 1.7284e-06, 4.2405e-07, 2.8281e-06, 9.3356e-06,\n",
       "           6.2873e-07, 2.5184e-06, 4.9871e-07, 2.7595e-07, 7.5139e-07, 2.9090e-07,\n",
       "           1.9608e-06, 2.5703e-06, 2.6594e-07, 1.5510e-07, 1.6338e-07, 2.3042e-07,\n",
       "           1.0510e-06, 1.9593e-07, 1.8532e-07, 2.5862e-07, 3.1619e-07, 1.6653e-06,\n",
       "           1.2705e-06, 2.4588e-07, 2.0604e-07, 3.5933e-06, 2.0939e-07, 4.0713e-07,\n",
       "           3.6096e-07, 3.8060e-07, 3.4635e-07, 6.1023e-07, 3.7235e-07, 3.1675e-06,\n",
       "           1.8002e-06, 1.9594e-07, 1.2051e-06, 4.1486e-06, 2.3524e-07, 2.2954e-07,\n",
       "           1.9383e-07, 1.5640e-07, 2.2336e-07, 3.3115e-06, 9.3581e-08, 1.1052e-06,\n",
       "           1.7968e-07, 3.5868e-07, 1.2058e-06, 5.3629e-07, 8.7897e-07, 4.9307e-07,\n",
       "           9.8697e-07, 8.2025e-07, 2.0135e-07, 7.9049e-07, 1.1491e-06, 1.4749e-05,\n",
       "           3.2301e-07, 9.7231e-07, 2.1969e-06, 2.0581e-07, 2.0640e-07, 1.7473e-07,\n",
       "           1.7555e-07, 1.6334e-06, 1.5265e-06, 1.6842e-06, 1.0081e-06, 6.0295e-07,\n",
       "           2.2399e-06, 9.7390e-07, 2.3121e-07, 4.6884e-08, 4.0429e-07, 2.7701e-06,\n",
       "           2.8033e-06, 6.8074e-07, 3.4823e-06, 1.2467e-06, 3.7309e-06, 1.1565e-06,\n",
       "           6.4297e-07, 3.6519e-07, 2.8060e-07, 1.8673e-07, 3.3260e-06, 2.0829e-07,\n",
       "           3.0562e-07, 3.4976e-07, 1.1813e-06, 3.5971e-06, 2.0341e-07, 4.7014e-06,\n",
       "           1.6816e-07, 1.9903e-07, 7.9190e-07, 2.8837e-07, 2.6754e-07, 1.7032e-07,\n",
       "           5.1471e-06, 3.1934e-07, 6.1591e-07, 3.7188e-06, 1.3459e-07, 1.6939e-07,\n",
       "           3.1975e-07, 5.1896e-07, 4.4670e-06, 1.7270e-07, 3.0227e-07, 8.6946e-07,\n",
       "           1.0194e-06, 2.4638e-07, 2.3018e-06, 2.5663e-07, 2.7170e-07, 9.4681e-07,\n",
       "           5.4633e-07, 4.1113e-07, 6.0138e-07, 2.6136e-07, 2.6135e-07, 4.7728e-07,\n",
       "           6.5182e-08, 1.2131e-06, 1.5169e-07, 5.3160e-07, 2.1012e-06, 5.4464e-07,\n",
       "           1.4690e-07, 5.4491e-07, 2.6815e-07, 1.7925e-06, 4.6833e-07, 5.1686e-07,\n",
       "           2.3450e-06, 4.9287e-07, 1.6104e-07, 2.2372e-07, 5.7688e-07, 1.6007e-07,\n",
       "           3.7672e-07, 3.2260e-06, 2.0401e-07, 1.2857e-06, 2.6679e-06, 3.0684e-07,\n",
       "           4.0353e-07, 1.5876e-07, 6.1529e-06, 4.1352e-06, 4.4804e-07, 2.8655e-07,\n",
       "           1.5302e-07, 5.5034e-06, 2.4601e-07, 1.3344e-07, 1.3676e-06, 2.1283e-07,\n",
       "           1.0859e-06, 1.6362e-06, 2.3029e-07, 2.2180e-07, 2.0111e-07, 3.3017e-07,\n",
       "           3.1980e-07, 3.0350e-07, 9.7841e-07, 7.9614e-07, 2.3846e-07, 2.0330e-06,\n",
       "           1.0110e-06, 3.4978e-07, 2.1006e-07, 5.8919e-07, 6.1993e-08, 3.2034e-07,\n",
       "           2.0500e-07, 2.9808e-07, 8.3228e-07, 2.5515e-07, 4.4499e-07, 3.4008e-07,\n",
       "           1.8986e-07, 1.5692e-06, 2.0742e-07, 4.5540e-07, 7.9321e-06, 2.1682e-07,\n",
       "           1.2012e-06, 1.3902e-06, 7.7478e-06, 5.8756e-07, 6.8885e-06, 2.4638e-06,\n",
       "           1.5022e-07, 1.5740e-07, 3.4647e-07, 2.0832e-06, 2.7010e-07, 1.3988e-06,\n",
       "           2.3504e-07, 2.7848e-07, 2.2869e-06, 1.7262e-07, 3.4340e-07, 1.7229e-07,\n",
       "           1.3140e-07, 2.0678e-07, 5.1149e-07, 2.8600e-07, 3.6805e-06, 1.9244e-06,\n",
       "           2.3647e-06, 1.9872e-07, 5.3705e-07, 1.0261e-06, 7.5795e-06, 2.4462e-07,\n",
       "           7.1730e-07, 6.2503e-06, 3.2852e-06, 6.1366e-07, 8.2345e-07, 1.5838e-06,\n",
       "           3.8316e-07, 2.5768e-07, 2.3657e-07, 2.1451e-07, 3.7079e-07, 3.0943e-07,\n",
       "           3.7259e-07, 1.7347e-07, 6.4417e-07, 5.5325e-07, 5.4380e-07, 1.9032e-07,\n",
       "           1.9590e-06, 6.5541e-07, 3.4894e-06, 1.6330e-07, 2.4435e-06, 1.3702e-06,\n",
       "           2.6843e-07, 1.5714e-07, 1.6143e-07, 1.1673e-06, 2.7945e-06, 1.9348e-07,\n",
       "           2.0240e-07, 1.2998e-07, 4.4743e-07, 2.7846e-07, 5.2221e-06, 2.2829e-07,\n",
       "           1.9998e-07, 1.3449e-07, 1.2080e-06, 3.5132e-07, 1.6687e-06, 1.7719e-07,\n",
       "           3.2955e-07, 2.0133e-07, 2.1364e-06, 4.7899e-07, 3.2340e-06, 1.3750e-07,\n",
       "           3.4449e-07, 4.0827e-06, 1.7911e-07, 1.9399e-07, 8.3282e-06, 2.4925e-07,\n",
       "           1.5008e-06, 8.7310e-07, 2.3271e-06, 1.1700e-06, 1.4376e-07, 2.2755e-06,\n",
       "           4.0843e-07, 1.8017e-07, 6.7122e-06, 1.8321e-07, 2.2116e-07, 5.7559e-07,\n",
       "           2.3524e-07, 2.0200e-07, 4.2499e-07, 1.1999e-06, 2.8011e-07, 9.0438e-07,\n",
       "           2.9192e-07, 9.8065e-07, 3.6361e-07, 5.8419e-07, 3.7924e-06, 2.0478e-06,\n",
       "           2.2043e-07, 2.0145e-06, 1.7657e-07, 1.1692e-07, 3.5817e-07, 1.2471e-06,\n",
       "           1.8156e-07, 3.4585e-07, 3.5161e-07, 3.5000e-07, 1.1803e-06, 2.6039e-07,\n",
       "           1.4499e-07, 2.5482e-07, 1.1064e-06, 1.5701e-07, 3.5611e-07, 2.1356e-07,\n",
       "           6.4916e-07, 3.4442e-06, 2.5840e-07, 5.6847e-07, 1.0671e-06, 2.2845e-06,\n",
       "           5.2739e-07, 2.9854e-06, 7.7062e-07, 2.0204e-07, 1.2330e-07, 4.3663e-07,\n",
       "           5.6630e-07, 3.2985e-06, 2.8347e-07, 1.3418e-06, 1.4152e-06, 2.4943e-06,\n",
       "           1.9761e-07, 4.3664e-07, 3.0276e-07, 1.4287e-07, 2.3149e-07, 3.7055e-07,\n",
       "           4.1794e-07, 4.3151e-07, 1.8628e-07, 3.9408e-06, 3.5594e-07, 2.6276e-07,\n",
       "           1.9834e-07, 2.0157e-07, 1.8776e-07, 1.1962e-06, 5.1748e-07, 9.8092e-06,\n",
       "           4.2326e-07, 1.8676e-07, 3.7006e-07, 2.3719e-06, 2.7083e-07, 3.3603e-07,\n",
       "           1.4016e-06, 2.6381e-07, 3.0186e-07, 6.1826e-07, 4.7397e-06, 1.8971e-07,\n",
       "           1.6107e-07, 1.2362e-06, 1.3591e-06, 2.2989e-07, 3.3860e-06, 9.0245e-07,\n",
       "           7.8133e-07, 1.6186e-06, 2.1097e-07, 6.8047e-07, 7.4822e-06, 1.7098e-06,\n",
       "           1.9726e-07, 2.5923e-06, 3.0304e-07, 2.3806e-07, 1.5918e-07, 1.7350e-06,\n",
       "           2.3459e-07, 8.1850e-07, 1.8534e-07, 7.3453e-07, 2.1706e-07, 2.2234e-07,\n",
       "           2.1425e-07, 2.4240e-07, 2.1713e-07, 1.4740e-07, 5.8211e-07, 5.5674e-07,\n",
       "           2.1210e-07, 4.8489e-07, 6.5920e-07, 2.5160e-06, 1.4183e-07, 2.6572e-07,\n",
       "           3.8790e-07, 1.0179e-05, 6.9540e-07, 1.7051e-07, 2.3223e-06, 1.0412e-07,\n",
       "           2.9535e-07, 4.5227e-07, 2.6721e-07, 5.3544e-07, 7.4914e-08, 2.0985e-07,\n",
       "           1.5529e-07, 1.7134e-07, 2.1090e-07, 3.6328e-07, 1.7007e-07, 3.9564e-07,\n",
       "           8.3035e-08, 1.1128e-06, 3.9492e-06, 1.9198e-06, 4.7639e-07, 1.4887e-07,\n",
       "           1.9479e-07, 3.2094e-07, 3.8372e-07, 2.8314e-07, 2.0563e-06, 5.9746e-07,\n",
       "           4.8100e-06, 1.9517e-06, 3.9672e-07, 1.6165e-07, 1.9530e-07, 4.2579e-07,\n",
       "           2.8279e-07, 1.8196e-06, 1.9976e-06, 2.2665e-06, 1.9033e-07, 3.5771e-07,\n",
       "           1.4268e-07, 1.0200e-07, 3.3466e-07, 1.4782e-07, 1.2298e-06, 2.3857e-06,\n",
       "           2.6836e-07, 1.8788e-06, 3.5634e-07, 3.7889e-07, 1.8369e-07, 3.1018e-07,\n",
       "           1.0771e-06, 4.6420e-07, 1.6042e-07, 6.9056e-06, 2.3460e-07, 7.4490e-07,\n",
       "           1.6150e-06, 6.2442e-07, 1.7274e-06, 2.7459e-07, 1.6672e-07, 3.3796e-07,\n",
       "           5.7662e-07, 2.3316e-07, 5.2194e-07, 2.0858e-06, 1.8059e-07, 7.8119e-07,\n",
       "           2.4846e-07, 2.3364e-07, 1.6959e-06, 2.2841e-07, 3.3281e-07, 9.0276e-07,\n",
       "           4.7702e-07, 1.4621e-07, 3.8504e-06, 1.9892e-07, 6.1059e-07, 2.2303e-07,\n",
       "           2.0865e-07, 8.3080e-07, 3.2840e-06, 3.0315e-07, 1.4572e-07, 1.5475e-07,\n",
       "           6.5996e-07, 2.9399e-07, 1.5695e-07, 7.4922e-07, 3.8500e-07, 2.0177e-06,\n",
       "           4.6188e-07, 1.9711e-07, 1.1045e-06, 1.8650e-07, 1.3180e-06, 2.7073e-06,\n",
       "           4.3240e-06, 3.6251e-07, 1.2847e-07, 3.1966e-07, 1.5617e-06, 2.9074e-07,\n",
       "           9.5532e-07, 1.9075e-07, 2.5924e-06, 2.3407e-07, 8.1646e-07, 7.0358e-07,\n",
       "           2.2782e-07, 8.7064e-07, 3.2675e-07, 3.4459e-07, 3.8845e-07, 2.2888e-07,\n",
       "           3.2296e-07, 1.9930e-06, 1.9558e-07, 2.5823e-07, 3.4556e-07, 1.1744e-07,\n",
       "           4.0551e-07, 1.6872e-07, 1.7537e-07, 1.9217e-07, 8.9210e-07, 2.1565e-07,\n",
       "           1.8600e-07, 2.8330e-07, 1.8981e-07, 7.4373e-07, 2.7448e-06, 6.7830e-07,\n",
       "           5.3819e-07, 2.8918e-07, 3.3951e-06, 3.4147e-07, 8.4182e-07, 5.5055e-07,\n",
       "           1.8529e-07, 3.8517e-07, 6.3819e-07, 1.3947e-06, 5.2335e-06, 3.3678e-07,\n",
       "           6.5849e-07, 5.7382e-07, 1.4113e-06, 2.0633e-07, 1.5676e-07, 2.6428e-07,\n",
       "           1.4113e-07, 5.6671e-06, 1.8374e-07, 1.1859e-06, 1.1677e-05, 1.7017e-06,\n",
       "           5.0468e-07, 4.2362e-07, 3.4405e-07, 2.5551e-07, 1.6341e-07, 1.5826e-07,\n",
       "           3.5737e-06, 6.0813e-07, 1.8061e-07, 6.7344e-07, 1.5302e-07, 2.3778e-07,\n",
       "           1.8699e-07, 3.1305e-06, 3.8962e-06, 1.8052e-07, 1.2183e-06, 1.4373e-07,\n",
       "           4.1102e-07, 5.7231e-07, 1.5073e-07, 1.6364e-06, 6.4806e-07, 2.5535e-07,\n",
       "           6.5976e-07, 1.1316e-07, 2.0831e-06, 1.5256e-06, 1.4445e-07, 1.1311e-06,\n",
       "           1.9844e-06, 3.0142e-07, 2.3997e-07, 3.8556e-07, 6.5856e-07, 2.6677e-07,\n",
       "           9.2349e-07, 1.9077e-07, 2.7487e-07, 6.2093e-07, 1.3689e-06, 2.9042e-07,\n",
       "           1.6153e-07, 5.7113e-06, 3.3932e-07, 9.3533e-07, 2.2915e-06, 7.2365e-07,\n",
       "           2.9805e-07, 1.2277e-07, 5.2379e-07, 8.4496e-07, 3.7040e-07, 9.1607e-07],\n",
       "          device='cuda:1')},\n",
       "  10: {'step': 3545,\n",
       "   'exp_avg': tensor([[ 3.3037e-04,  1.7508e-04,  7.6859e-05,  ...,  5.1041e-04,\n",
       "             1.3951e-04, -6.0869e-04],\n",
       "           [ 1.6711e-05,  5.2006e-05,  2.2013e-05,  ...,  7.1150e-05,\n",
       "            -1.8316e-05, -9.2089e-05],\n",
       "           [-6.3032e-04, -3.4637e-04, -2.2852e-04,  ..., -1.0918e-03,\n",
       "            -1.3274e-04,  1.1216e-03],\n",
       "           ...,\n",
       "           [ 3.2120e-04,  2.0023e-04,  9.6340e-05,  ...,  5.1274e-04,\n",
       "             1.7329e-04, -6.3870e-04],\n",
       "           [ 3.6263e-04,  1.9052e-04,  9.6060e-05,  ...,  5.4383e-04,\n",
       "             1.8347e-04, -6.6795e-04],\n",
       "           [ 9.0746e-05,  2.2059e-05,  3.5170e-05,  ...,  1.3526e-04,\n",
       "             2.4093e-05, -1.0637e-04]], device='cuda:1'),\n",
       "   'exp_avg_sq': tensor([[1.2095e-07, 1.1727e-07, 1.4432e-07,  ..., 1.4011e-07, 1.1176e-07,\n",
       "            1.8133e-07],\n",
       "           [1.3857e-07, 1.4212e-07, 1.4891e-07,  ..., 1.4290e-07, 1.1853e-07,\n",
       "            1.8217e-07],\n",
       "           [2.4901e-06, 2.4907e-06, 1.8752e-06,  ..., 2.7799e-06, 1.4982e-06,\n",
       "            2.9406e-06],\n",
       "           ...,\n",
       "           [1.5533e-07, 1.3299e-07, 1.1010e-07,  ..., 1.6359e-07, 9.0023e-08,\n",
       "            2.3000e-07],\n",
       "           [1.2157e-07, 1.2693e-07, 8.2797e-08,  ..., 1.3837e-07, 6.4773e-08,\n",
       "            1.8555e-07],\n",
       "           [1.1463e-07, 1.3235e-07, 9.0920e-08,  ..., 1.1733e-07, 6.9521e-08,\n",
       "            1.5180e-07]], device='cuda:1')},\n",
       "  11: {'step': 3545,\n",
       "   'exp_avg': tensor([ 2.5481e-04,  2.7446e-05, -3.4017e-04,  3.9337e-05,  2.9323e-05,\n",
       "           -1.4186e-04, -1.5146e-04, -1.7875e-05, -1.0676e-04, -2.9581e-04,\n",
       "           -1.5207e-04, -1.5003e-04,  1.1631e-04, -1.9361e-05, -2.8097e-06,\n",
       "           -8.8186e-06, -9.5543e-05, -9.5674e-06,  3.6395e-04, -2.3573e-04,\n",
       "           -2.5689e-04, -2.3514e-04,  1.2318e-04, -7.7053e-05,  5.0986e-05,\n",
       "           -1.4215e-04, -7.8494e-05,  1.5868e-04, -6.5807e-05,  3.8950e-05,\n",
       "           -1.3944e-04, -2.3258e-04,  6.5344e-05,  3.9465e-05,  7.1230e-05,\n",
       "            5.7111e-05,  1.1720e-04,  5.9527e-05,  9.2012e-06,  8.1510e-05,\n",
       "            1.5467e-05,  2.6459e-04, -2.3121e-04, -1.0699e-05,  2.5093e-05,\n",
       "           -3.9740e-05,  2.0818e-04,  1.8823e-04,  1.4263e-04,  2.2420e-04,\n",
       "            5.7474e-05, -1.4724e-04, -2.9706e-05,  8.8681e-05, -2.5212e-05,\n",
       "            1.1289e-05,  9.8399e-05,  2.3682e-05,  1.3819e-04, -6.6207e-05,\n",
       "           -3.4606e-05, -1.1082e-04, -6.0236e-05,  4.5941e-05,  1.8057e-04,\n",
       "           -2.6976e-04,  1.0868e-05, -2.0506e-04,  5.4486e-05,  1.4367e-05,\n",
       "            4.7459e-04, -8.8449e-05, -2.1692e-04, -8.4603e-05,  2.3366e-04,\n",
       "           -2.8427e-05, -1.1814e-04,  3.8352e-05, -4.4618e-05, -2.4523e-05,\n",
       "            2.5963e-04, -1.2421e-04, -7.7211e-05,  2.5511e-05,  7.1600e-05,\n",
       "            1.4540e-04, -1.1979e-04,  9.2699e-05,  8.3763e-05,  1.1374e-04,\n",
       "           -1.1653e-04,  9.6588e-05,  6.7396e-06, -1.1287e-04, -2.3590e-04,\n",
       "           -3.2120e-05,  2.5988e-04,  3.1936e-04, -4.6655e-05,  1.9383e-04,\n",
       "           -7.1732e-04, -2.1483e-05,  1.3170e-04, -1.3358e-04, -1.2921e-03,\n",
       "            4.2068e-06, -3.2797e-05,  5.4240e-04, -2.0207e-04,  1.9215e-05,\n",
       "           -1.1993e-04,  1.8712e-04,  1.4957e-05, -4.6074e-05,  1.6363e-05,\n",
       "            1.4822e-04, -4.7053e-05, -4.1898e-04,  2.4102e-04, -6.4790e-05,\n",
       "            7.6830e-06, -2.0703e-04, -8.2901e-05, -5.4805e-04,  1.1888e-04,\n",
       "            2.9444e-04,  2.8695e-04,  6.0409e-06], device='cuda:1'),\n",
       "   'exp_avg_sq': tensor([1.1024e-06, 1.1641e-06, 1.3732e-05, 9.9495e-07, 1.5362e-06, 5.6487e-05,\n",
       "           9.8638e-07, 6.5467e-06, 1.2073e-06, 8.9757e-07, 9.1341e-07, 1.0077e-06,\n",
       "           1.1450e-06, 7.0862e-07, 6.5966e-07, 6.1523e-07, 9.2551e-07, 9.8079e-07,\n",
       "           2.1588e-05, 1.3199e-06, 9.4110e-07, 8.9635e-07, 6.2590e-07, 8.6482e-07,\n",
       "           9.3408e-07, 9.7584e-07, 8.4895e-07, 1.0883e-06, 7.5289e-07, 8.6513e-07,\n",
       "           6.3593e-07, 5.8645e-05, 6.9961e-07, 6.4833e-07, 5.7644e-07, 9.9272e-07,\n",
       "           7.3028e-07, 1.9749e-06, 8.1670e-07, 8.9849e-07, 5.5629e-07, 1.0327e-06,\n",
       "           6.8234e-07, 8.1647e-07, 1.9943e-06, 1.3472e-06, 6.1664e-07, 8.0781e-07,\n",
       "           8.6386e-07, 6.3751e-07, 9.6479e-07, 6.3634e-07, 1.0566e-06, 1.4288e-06,\n",
       "           7.9179e-07, 6.0750e-07, 6.4120e-07, 5.3578e-07, 9.5942e-07, 8.3645e-07,\n",
       "           1.1601e-06, 9.5560e-07, 1.1496e-06, 7.7540e-07, 8.1042e-07, 7.2482e-07,\n",
       "           9.0081e-07, 1.0829e-06, 6.2391e-07, 7.1939e-07, 1.8968e-05, 9.1640e-07,\n",
       "           8.5569e-07, 8.8378e-06, 7.0569e-07, 5.9951e-07, 6.9071e-07, 1.2481e-06,\n",
       "           1.1880e-06, 2.1831e-06, 7.5174e-07, 7.2261e-07, 1.1564e-06, 6.9729e-07,\n",
       "           8.7391e-07, 1.1159e-06, 4.0912e-06, 1.1106e-06, 7.2448e-07, 6.0308e-07,\n",
       "           5.5887e-07, 1.7217e-06, 5.6549e-07, 6.8757e-07, 7.3584e-07, 8.0244e-07,\n",
       "           9.0115e-07, 1.0799e-06, 9.9379e-07, 6.9757e-07, 3.4971e-05, 9.3842e-07,\n",
       "           1.0644e-06, 7.6949e-07, 7.7792e-05, 1.2576e-06, 6.3961e-07, 2.4451e-05,\n",
       "           1.8467e-06, 2.2682e-06, 1.0950e-06, 8.9016e-07, 5.8705e-07, 1.0576e-06,\n",
       "           3.8464e-06, 6.7423e-07, 1.1900e-06, 1.7390e-05, 6.7031e-07, 1.0594e-06,\n",
       "           9.5160e-07, 9.3912e-07, 6.0964e-07, 2.7068e-05, 6.2344e-07, 8.5713e-07,\n",
       "           6.2354e-07, 6.5387e-07], device='cuda:1')}},\n",
       " 'param_groups': [{'lr': 0.001,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'maximize': False,\n",
       "   'params': [0, 1, 2, 3]},\n",
       "  {'lr': 0.001,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'maximize': False,\n",
       "   'params': [4, 5]},\n",
       "  {'lr': 0.001,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'maximize': False,\n",
       "   'params': [6, 7]},\n",
       "  {'lr': 0.001,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'maximize': False,\n",
       "   'params': [8, 9]},\n",
       "  {'lr': 0.001,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'maximize': False,\n",
       "   'params': [10, 11]},\n",
       "  {'lr': 2e-05,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'maximize': False,\n",
       "   'params': [12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158,\n",
       "    159,\n",
       "    160,\n",
       "    161,\n",
       "    162,\n",
       "    163,\n",
       "    164,\n",
       "    165,\n",
       "    166,\n",
       "    167,\n",
       "    168,\n",
       "    169,\n",
       "    170,\n",
       "    171,\n",
       "    172,\n",
       "    173,\n",
       "    174,\n",
       "    175,\n",
       "    176,\n",
       "    177,\n",
       "    178,\n",
       "    179,\n",
       "    180,\n",
       "    181,\n",
       "    182,\n",
       "    183,\n",
       "    184,\n",
       "    185,\n",
       "    186,\n",
       "    187,\n",
       "    188,\n",
       "    189,\n",
       "    190,\n",
       "    191,\n",
       "    192,\n",
       "    193,\n",
       "    194,\n",
       "    195,\n",
       "    196,\n",
       "    197,\n",
       "    198,\n",
       "    199,\n",
       "    200,\n",
       "    201,\n",
       "    202,\n",
       "    203,\n",
       "    204,\n",
       "    205,\n",
       "    206,\n",
       "    207,\n",
       "    208,\n",
       "    209,\n",
       "    210]},\n",
       "  {'lr': 0.0001,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'maximize': False,\n",
       "   'params': [211,\n",
       "    212,\n",
       "    213,\n",
       "    214,\n",
       "    215,\n",
       "    216,\n",
       "    217,\n",
       "    218,\n",
       "    219,\n",
       "    220,\n",
       "    221,\n",
       "    222,\n",
       "    223,\n",
       "    224,\n",
       "    225,\n",
       "    226,\n",
       "    227,\n",
       "    228,\n",
       "    229,\n",
       "    230,\n",
       "    231,\n",
       "    232,\n",
       "    233,\n",
       "    234,\n",
       "    235,\n",
       "    236,\n",
       "    237,\n",
       "    238,\n",
       "    239,\n",
       "    240,\n",
       "    241,\n",
       "    242,\n",
       "    243,\n",
       "    244,\n",
       "    245,\n",
       "    246,\n",
       "    247,\n",
       "    248,\n",
       "    249,\n",
       "    250,\n",
       "    251,\n",
       "    252,\n",
       "    253,\n",
       "    254,\n",
       "    255,\n",
       "    256,\n",
       "    257,\n",
       "    258,\n",
       "    259,\n",
       "    260,\n",
       "    261,\n",
       "    262,\n",
       "    263,\n",
       "    264,\n",
       "    265,\n",
       "    266,\n",
       "    267,\n",
       "    268,\n",
       "    269,\n",
       "    270,\n",
       "    271,\n",
       "    272,\n",
       "    273,\n",
       "    274,\n",
       "    275,\n",
       "    276,\n",
       "    277,\n",
       "    278,\n",
       "    279,\n",
       "    280,\n",
       "    281,\n",
       "    282,\n",
       "    283,\n",
       "    284,\n",
       "    285,\n",
       "    286,\n",
       "    287,\n",
       "    288,\n",
       "    289,\n",
       "    290,\n",
       "    291,\n",
       "    292,\n",
       "    293,\n",
       "    294,\n",
       "    295,\n",
       "    296,\n",
       "    297,\n",
       "    298,\n",
       "    299,\n",
       "    300,\n",
       "    301,\n",
       "    302,\n",
       "    303,\n",
       "    304,\n",
       "    305,\n",
       "    306,\n",
       "    307,\n",
       "    308,\n",
       "    309,\n",
       "    310,\n",
       "    311,\n",
       "    312,\n",
       "    313,\n",
       "    314,\n",
       "    315,\n",
       "    316,\n",
       "    317,\n",
       "    318,\n",
       "    319,\n",
       "    320,\n",
       "    321,\n",
       "    322,\n",
       "    323,\n",
       "    324,\n",
       "    325,\n",
       "    326,\n",
       "    327,\n",
       "    328,\n",
       "    329,\n",
       "    330,\n",
       "    331,\n",
       "    332,\n",
       "    333,\n",
       "    334,\n",
       "    335,\n",
       "    336,\n",
       "    337,\n",
       "    338,\n",
       "    339,\n",
       "    340,\n",
       "    341,\n",
       "    342,\n",
       "    343,\n",
       "    344,\n",
       "    345,\n",
       "    346,\n",
       "    347,\n",
       "    348,\n",
       "    349,\n",
       "    350,\n",
       "    351,\n",
       "    352,\n",
       "    353,\n",
       "    354,\n",
       "    355,\n",
       "    356,\n",
       "    357,\n",
       "    358,\n",
       "    359,\n",
       "    360,\n",
       "    361,\n",
       "    362,\n",
       "    363,\n",
       "    364,\n",
       "    365,\n",
       "    366,\n",
       "    367,\n",
       "    368,\n",
       "    369,\n",
       "    370,\n",
       "    371,\n",
       "    372,\n",
       "    373,\n",
       "    374,\n",
       "    375,\n",
       "    376,\n",
       "    377,\n",
       "    378,\n",
       "    379,\n",
       "    380,\n",
       "    381,\n",
       "    382,\n",
       "    383,\n",
       "    384,\n",
       "    385,\n",
       "    386,\n",
       "    387,\n",
       "    388,\n",
       "    389,\n",
       "    390,\n",
       "    391,\n",
       "    392,\n",
       "    393,\n",
       "    394,\n",
       "    395,\n",
       "    396,\n",
       "    397,\n",
       "    398,\n",
       "    399,\n",
       "    400,\n",
       "    401,\n",
       "    402,\n",
       "    403,\n",
       "    404,\n",
       "    405,\n",
       "    406,\n",
       "    407,\n",
       "    408,\n",
       "    409,\n",
       "    410,\n",
       "    411,\n",
       "    412,\n",
       "    413,\n",
       "    414,\n",
       "    415,\n",
       "    416,\n",
       "    417,\n",
       "    418,\n",
       "    419,\n",
       "    420,\n",
       "    421,\n",
       "    422,\n",
       "    423,\n",
       "    424,\n",
       "    425,\n",
       "    426,\n",
       "    427,\n",
       "    428,\n",
       "    429,\n",
       "    430,\n",
       "    431,\n",
       "    432,\n",
       "    433,\n",
       "    434,\n",
       "    435,\n",
       "    436,\n",
       "    437,\n",
       "    438,\n",
       "    439,\n",
       "    440,\n",
       "    441,\n",
       "    442,\n",
       "    443,\n",
       "    444,\n",
       "    445,\n",
       "    446,\n",
       "    447,\n",
       "    448,\n",
       "    449,\n",
       "    450,\n",
       "    451,\n",
       "    452,\n",
       "    453,\n",
       "    454,\n",
       "    455,\n",
       "    456,\n",
       "    457,\n",
       "    458,\n",
       "    459,\n",
       "    460,\n",
       "    461,\n",
       "    462,\n",
       "    463,\n",
       "    464,\n",
       "    465,\n",
       "    466,\n",
       "    467,\n",
       "    468,\n",
       "    469,\n",
       "    470,\n",
       "    471,\n",
       "    472,\n",
       "    473,\n",
       "    474,\n",
       "    475,\n",
       "    476,\n",
       "    477,\n",
       "    478,\n",
       "    479,\n",
       "    480,\n",
       "    481,\n",
       "    482,\n",
       "    483,\n",
       "    484,\n",
       "    485,\n",
       "    486,\n",
       "    487,\n",
       "    488,\n",
       "    489,\n",
       "    490,\n",
       "    491,\n",
       "    492,\n",
       "    493,\n",
       "    494]}]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1VyLADEpnFs"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def plot(model):\n",
    "  model.eval()\n",
    "  test_preds = torch.tensor([], device=device)\n",
    "  test_labels = torch.tensor([], device = device)\n",
    "  test_text = []\n",
    "  test_img = []\n",
    "\n",
    "  soft_m = nn.Softmax(dim=-1)\n",
    "  with torch.no_grad():\n",
    "    for i, (texts, images, labels) in enumerate(dm.test_dataloader()):\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images, texts)\n",
    "\n",
    "        output_scores = soft_m(outputs)\n",
    "        predictions = torch.argmax(output_scores, dim=-1)\n",
    "\n",
    "        test_preds = torch.cat((test_preds, predictions), dim=0)\n",
    "        test_labels = torch.cat((test_labels, labels), dim=0)\n",
    "        for t in texts:\n",
    "          test_text.append(t) \n",
    "        for i in images:\n",
    "          test_img.append(i) \n",
    "\n",
    "    \n",
    "    test_preds = test_preds.cpu().numpy()\n",
    "    test_labels = test_labels.cpu().numpy()\n",
    "  i = 1\n",
    "  plt.figure(figsize=(40,40))\n",
    "  print(len(test_labels))\n",
    "  for image, actual_label, label, text in zip(test_img, test_labels, test_preds, test_text):\n",
    "\n",
    "      if (actual_label == label):\n",
    "\n",
    "        plt.subplot(4,4,i)\n",
    "        i+=1\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = T.ToPILImage()(image).convert(\"RGB\")\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Text: {}...\\n Actual: {}\\n Predicted: {}\".format(text[:30], actual_label, label))\n",
    "        # plt.xlabel(text)\n",
    "      else:\n",
    "        pass\n",
    "      if (i==17):\n",
    "        break;\n",
    "  plt.savefig('res_freeze_af20epoch.png', bbox_inches='tight')\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "plot(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  6 21:41:53 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "|  0%   41C    P8     1W / 250W |   2368MiB / 11019MiB |     13%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:86:00.0 Off |                  N/A |\n",
      "|  0%   24C    P8     2W / 250W |   3496MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    214205      C   ...da3/envs/AI_DA/bin/python     2365MiB |\n",
      "|    1   N/A  N/A    429695      C   python                           3493MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBUVnSf-_ht0"
   },
   "source": [
    "# Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dlaSCOAxb0i"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n",
    "\n",
    "class Multimodal(pl.LightningModule):\n",
    "  def __init__(self, lr_multi, lr_classifier):\n",
    "    super(Multimodal,self).__init__()\n",
    "    self.loss_module = nn.CrossEntropyLoss()\n",
    "    self.BERT = Bert_Lstm()\n",
    "    self.incept = Inception()\n",
    "    self.dense = nn.Linear(256,256)\n",
    "    self.cl = nn.Linear(256,3)\n",
    "    self.bpe_path = \"/content/drive/MyDrive/NLP/PhoBERT_base_transformers/bpe.codes\"\n",
    "    self.vocab_path = \"/content/drive/MyDrive/NLP/PhoBERT_base_transformers/dict.txt\"\n",
    "    self.lr_multi = lr_multi\n",
    "    self.lr_classifier = lr_classifier\n",
    "\n",
    "    # self.model = self._build_model()\n",
    "    # self.trainer_params = self._get_trainer_params()\n",
    "\n",
    "  def forward(self, image, texts, labels=None):\n",
    "    inputs = tokenize_data(texts, self.vocab_path, self.bpe_path)\n",
    "    # b_labels = None\n",
    "    # b_labels = labels.to(self.device)\n",
    "\n",
    "    for key in inputs:\n",
    "        inputs[key] = inputs[key].to(self.device)\n",
    "    image = image.to(self.device)\n",
    "\n",
    "    fea1 = self.BERT(inputs)\n",
    "    fea2 = self.incept(image)\n",
    "    cat = torch.cat((fea1, fea2), 1)\n",
    "    out = self.cl(cat)\n",
    "\n",
    "    return out\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    roberta_params = self.BERT.parameters()\n",
    "    inception_params = self.incept.parameters()\n",
    "    dense_params = self.dense.parameters()\n",
    "    classifier_params = self.cl.parameters()\n",
    "\n",
    "    # for n,p in classifier_params:\n",
    "    #   print(n,p)\n",
    "\n",
    "    # grouped_params = [\n",
    "    #     {\"params\": roberta_params, \"lr\": self.lr_multi},\n",
    "    #     {\"params\": inception_params, \"lr\": self.lr_multi},\n",
    "    #     {\"params\": dense_params, \"lr\": self.lr_multi},\n",
    "    #     {\"params\": classifier_params, \"lr\": self.lr_classifier}\n",
    "    # ]\n",
    "    # optimizer = torch.optim.AdamW(\n",
    "    #     grouped_params\n",
    "    # )\n",
    "    optimizer = torch.optim.AdamW(\n",
    "              self.parameters(), \n",
    "              lr = 0.001\n",
    "          )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.98)\n",
    "  \n",
    "\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    texts, images, labels = batch\n",
    "    preds = self(images, texts, labels)\n",
    "    labels = labels.to(self.device)\n",
    "\n",
    "    loss = self.loss_module(preds, labels)\n",
    "\n",
    "    return loss\n",
    "  \n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    texts, images, labels = batch\n",
    "    logits = self(images, texts, labels)\n",
    "\n",
    "    loss = self.loss_module(logits, labels)\n",
    "    output_scores = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    return loss, output_scores, labels\n",
    "\n",
    "  def validation_epoch_end(self, validation_step_outputs):\n",
    "    val_preds = torch.tensor([], device=self.device)\n",
    "    val_scores = torch.tensor([], device=self.device)\n",
    "    val_labels = torch.tensor([], device=self.device)\n",
    "    val_loss = 0\n",
    "    total_item = 0\n",
    "\n",
    "    for idx, item in enumerate(validation_step_outputs):\n",
    "        loss, output_scores, labels = item\n",
    "\n",
    "        predictions = torch.argmax(output_scores, dim=-1)\n",
    "        val_preds = torch.cat((val_preds, predictions), dim=0)\n",
    "        val_scores = torch.cat((val_scores, output_scores[:, 1]), dim=0)\n",
    "        val_labels = torch.cat((val_labels, labels), dim=0)\n",
    "\n",
    "        val_loss += loss\n",
    "        total_item += 1\n",
    "\n",
    "    # print(\"VAL PREDS\", val_preds.shape)\n",
    "    # print(\"VAL SCORES\", val_scores.shape)\n",
    "    # print(\"VAL LABELS\", val_labels.shape)\n",
    "    val_preds = val_preds.cpu().numpy()\n",
    "    val_scores = val_scores.cpu().numpy()\n",
    "    val_labels = val_labels.cpu().numpy()\n",
    "\n",
    "    # reports = classification_report(val_labels, val_preds, output_dict=True)\n",
    "    print(\"VAL PREDS\", val_preds)\n",
    "    print(\"VAL LABELS\", val_labels)\n",
    "    print(\"VAL SCORES\", val_scores)\n",
    "    # try:\n",
    "    #     auc = roc_auc_score(val_labels, val_scores)\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     print(\"Cannot calculate AUC. Default to 0\")\n",
    "    #     auc = 0\n",
    "    accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(classification_report(val_labels, val_preds))\n",
    "\n",
    "    self.log(\"loss/val\", val_loss)\n",
    "    # self.log(\"auc/val\", auc)\n",
    "    self.log(\"accuracy/val\", accuracy)\n",
    "    # self.log(\"precision/val\", reports[\"weighted avg\"][\"precision\"])\n",
    "    # self.log(\"recall/val\", reports[\"weighted avg\"][\"recall\"])\n",
    "    # self.log(\"f1/val\", reports[\"weighted avg\"][\"f1-score\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1RPu7-B7wWu"
   },
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(\n",
    "#     fast_dev_run=True,\n",
    "# )\n",
    "# multi = Multimodal(lr_multi=1e-5, lr_classifier=3e-3)\n",
    "# dm = SentimentDataModule(data_df)\n",
    "# trainer.fit(multi, dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a93f05a257d5421eb2c72efcdac8fcd3",
      "16559060dd074447bf5e27134b4870ae",
      "8d8bf547e78f461da79bb4e3e8449335",
      "2d90f769f9a748899fd536bc215e0902",
      "83e93a1ba3f24f96ac5ea9107e160a9e",
      "664ccebe5b894806a2c84d633e107f38",
      "81d26020a9784869b593de58ca922404",
      "2132d76e642e4cbaaabf71e032d0fb8b",
      "1f0e5ebe496b45ec97082f2bb666a82e",
      "02eca356512546b1954a563bc988d6b5",
      "7939b8ff88a940028fb77f2bd715db87",
      "9aad7677f25b4c85abc0e6edb7b9212d",
      "fff7e36afcae4a3a81e5b40705c21519",
      "e47ffdaa9228458182c11c9ba945e33d",
      "c4c4bae04bad46dea96a97dc5a7d8d0d",
      "460e2a8033f04d4fbd9109254d2dfb73",
      "f7947613432143f98f2f714598d25dfd",
      "bb16f7ad93f34d12babc320869e1413b",
      "ba20e1bc66e94c829e2a46dd5d6a3483",
      "31d14a5ec28640d8acf64959fb4a5aa8",
      "b860941628094b5c8720672f5ebb3f3d",
      "93b193607ebd4e758cfc04a19b9dd2d6"
     ]
    },
    "id": "f9_mXDl3znZO",
    "outputId": "0605ceaf-c20f-4bfd-e5cc-d55755bf15e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:470: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/optimizers.py:39: UserWarning: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "  UserWarning,\n",
      "Missing logger folder: /content/drive/MyDrive/Colab Notebooks/Multimodal/tb_logs/default\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | loss_module | CrossEntropyLoss | 0     \n",
      "1 | BERT        | Bert_Lstm        | 135 M \n",
      "2 | incept      | Inception        | 24.1 M\n",
      "3 | dense       | Linear           | 65.8 K\n",
      "4 | cl          | Linear           | 771   \n",
      "-------------------------------------------------\n",
      "159 M     Trainable params\n",
      "0         Non-trainable params\n",
      "159 M     Total params\n",
      "319.243   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93f05a257d5421eb2c72efcdac8fcd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL PREDS [2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 2. 2. 2. 2.]\n",
      "VAL LABELS [1. 2. 0. 0. 2. 2. 2. 2. 0. 2. 1. 0. 1. 1. 1. 1. 0. 2. 2. 1. 2. 1. 1. 2.\n",
      " 1. 2. 2. 2. 1. 2. 0. 1.]\n",
      "VAL SCORES [0.2503872  0.25511816 0.33502465 0.233994   0.2737939  0.30235466\n",
      " 0.30597535 0.28478307 0.34449401 0.28433585 0.3386114  0.24622746\n",
      " 0.2953767  0.28849763 0.32898384 0.27177638 0.2833459  0.30263612\n",
      " 0.31047884 0.24584286 0.32877764 0.25412712 0.20685947 0.29209316\n",
      " 0.30371505 0.292875   0.31025544 0.36505568 0.30896547 0.29549003\n",
      " 0.30231565 0.30986333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      0.08      0.14        12\n",
      "         2.0       0.41      0.86      0.56        14\n",
      "\n",
      "    accuracy                           0.41        32\n",
      "   macro avg       0.30      0.31      0.23        32\n",
      "weighted avg       0.37      0.41      0.30        32\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aad7677f25b4c85abc0e6edb7b9212d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a151cafc1a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mtrain_dataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         self._call_and_handle_interrupt(\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m         )\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \"\"\"\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;31m# TODO: ckpt_path only in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_EVALUATE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# the global step is manually decreased here due to backwards compatibility with existing loggers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_active_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_frequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         )\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_run_optimization\u001b[0;34m(self, split_batch, batch_idx, optimizer, opt_idx)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# gradient update with accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDeviceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_TPU_AVAILABLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_backend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_backend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mAMPType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNATIVE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0musing_lbfgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         )\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \"\"\"\n\u001b[0;32m-> 1652\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \"\"\"\n\u001b[1;32m    335\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/precision/native_amp.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, model, optimizer, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskipped_backward\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# note: the scaler will skip the `optimizer.step` if nonfinite gradients are found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: No inf checks were recorded for this optimizer."
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger('/content/drive/MyDrive/Colab Notebooks/Multimodal/tb_logs/')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    min_epochs=1,\n",
    "    max_epochs=5,\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    val_check_interval=0.5,\n",
    "    # check_val_every_n_epoch=1,\n",
    "    callbacks=[\n",
    "      ModelCheckpoint(\n",
    "          dirpath='/content/drive/MyDrive/Colab Notebooks/Multimodal/ckpt',\n",
    "          save_top_k=3,\n",
    "          monitor='f1/val',\n",
    "      ), \n",
    "      EarlyStopping('f1/val', patience=5)\n",
    "    ],\n",
    "    fast_dev_run=False,\n",
    "    logger=tb_logger\n",
    ")\n",
    "\n",
    "dm.setup(stage=\"fit\")\n",
    "trainer.fit(multi, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8YFA9dl3Lkw2"
   },
   "outputs": [],
   "source": [
    "# multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWmHn9ggNLfQ"
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# class Concatmodal(nn.Module):\n",
    "#   def __init__(self, lr_multi, lr_classifier):\n",
    "#     super(Concatmodal,self).__init__()\n",
    "#     self.loss_module = nn.CrossEntropyLoss()\n",
    "#     self.BERT = Bert_Lstm()\n",
    "#     self.incept = Inception()\n",
    "#     self.dense = nn.Linear(256,256)\n",
    "#     self.cl = nn.Linear(256,3)\n",
    "#     self.bpe_path = \"/content/drive/MyDrive/NLP/PhoBERT_base_transformers/bpe.codes\"\n",
    "#     self.vocab_path = \"/content/drive/MyDrive/NLP/PhoBERT_base_transformers/dict.txt\"\n",
    "#     self.lr_multi = lr_multi\n",
    "#     self.lr_classifier = lr_classifier\n",
    "  \n",
    "#   def forward(self, image, texts, labels=None):\n",
    "#     inputs = tokenize_data(texts, self.vocab_path, self.bpe_path)\n",
    "#     # b_labels = None\n",
    "#     # b_labels = labels.to(self.device)\n",
    "\n",
    "#     for key in inputs:\n",
    "#         inputs[key] = inputs[key].to(self.device)\n",
    "#     image = image.to(self.device)\n",
    "\n",
    "#     fea1 = self.BERT(inputs)\n",
    "#     fea2 = self.incept(image)\n",
    "#     cat = torch.cat((fea1, fea2), 1)\n",
    "#     out = self.cl(cat)\n",
    "\n",
    "#     return out\n",
    "  \n",
    "\n",
    "# class Multimodal(pl.LightningModule):\n",
    "#   def __init__(self, lr_multi, lr_classifier):\n",
    "#     super(Multimodal,self).__init__()\n",
    "#     # self.loss_module = nn.CrossEntropyLoss()\n",
    "#     # self.BERT = Bert_Lstm()\n",
    "#     # self.incept = Inception()\n",
    "#     # self.dense = nn.Linear(256,256)\n",
    "#     # self.cl = nn.Linear(256,3)\n",
    "#     # self.bpe_path = \"/content/drive/MyDrive/NLP/PhoBERT_base_transformers/bpe.codes\"\n",
    "#     # self.vocab_path = \"/content/drive/MyDrive/NLP/PhoBERT_base_transformers/dict.txt\"\n",
    "#     self.lr_multi = lr_multi\n",
    "#     self.lr_classifier = lr_classifier\n",
    "\n",
    "#     self.model = self._build_model()\n",
    "#     # self.trainer_params = self._get_trainer_params()\n",
    "\n",
    "#   def forward(self, image, texts, labels=None):\n",
    "#     # inputs = tokenize_data(texts, self.vocab_path, self.bpe_path)\n",
    "#     # # b_labels = None\n",
    "#     # # b_labels = labels.to(self.device)\n",
    "\n",
    "#     # for key in inputs:\n",
    "#     #     inputs[key] = inputs[key].to(self.device)\n",
    "#     # image = image.to(self.device)\n",
    "\n",
    "#     # fea1 = self.BERT(inputs)\n",
    "#     # fea2 = self.incept(image)\n",
    "#     # cat = torch.cat((fea1, fea2), 1)\n",
    "#     # out = self.model(cat)\n",
    "\n",
    "#     return self.model(image, texts)\n",
    "  \n",
    "#   def _build_model(self):\n",
    "#     return Concatmodal(self.lr_multi, self.lr_classifier)\n",
    "  \n",
    "#   def configure_optimizers(self):\n",
    "#     # roberta_params = self.BERT.parameters()\n",
    "#     # inception_params = self.incept.parameters()\n",
    "#     # dense_params = self.dense.parameters()\n",
    "#     # classifier_params = self.cl.parameters()\n",
    "\n",
    "#     # for n,p in classifier_params:\n",
    "#     #   print(n,p)\n",
    "\n",
    "#     # grouped_params = [\n",
    "#     #     {\"params\": roberta_params, \"lr\": self.lr_multi},\n",
    "#     #     {\"params\": inception_params, \"lr\": self.lr_multi},\n",
    "#     #     {\"params\": dense_params, \"lr\": self.lr_multi},\n",
    "#     #     {\"params\": classifier_params, \"lr\": self.lr_classifier}\n",
    "#     # ]\n",
    "#     # optimizer = torch.optim.AdamW(\n",
    "#     #     grouped_params\n",
    "#     # )\n",
    "#     optimizer = torch.optim.AdamW(\n",
    "#               self.model.parameters(), \n",
    "#               lr = 0.001\n",
    "#           )\n",
    "\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.98)\n",
    "  \n",
    "\n",
    "\n",
    "#   def training_step(self, batch, batch_idx):\n",
    "#     texts, images, labels = batch\n",
    "#     preds = self(images, texts, labels)\n",
    "\n",
    "#     loss = self.loss_module(preds, labels)\n",
    "\n",
    "#     print(\"train_loss\", loss)\n",
    "#     return loss\n",
    "  \n",
    "#   def validation_step(self, batch, batch_idx):\n",
    "#     texts, images, labels = batch\n",
    "#     logits = self(images, texts, labels)\n",
    "\n",
    "#     loss = self.loss_module(logits, labels)\n",
    "#     output_scores = torch.softmax(logits, dim=-1)\n",
    "\n",
    "#     return loss, output_scores, labels\n",
    "\n",
    "#   def validation_epoch_end(self, validation_step_outputs):\n",
    "#     val_preds = torch.tensor([], device=self.device)\n",
    "#     val_scores = torch.tensor([], device=self.device)\n",
    "#     val_labels = torch.tensor([], device=self.device)\n",
    "#     val_loss = 0\n",
    "#     total_item = 0\n",
    "\n",
    "#     for idx, item in enumerate(validation_step_outputs):\n",
    "#         loss, output_scores, labels = item\n",
    "\n",
    "#         predictions = torch.argmax(output_scores, dim=-1)\n",
    "#         val_preds = torch.cat((val_preds, predictions), dim=0)\n",
    "#         val_scores = torch.cat((val_scores, output_scores[:, 1]), dim=0)\n",
    "#         val_labels = torch.cat((val_labels, labels), dim=0)\n",
    "\n",
    "#         val_loss += loss\n",
    "#         total_item += 1\n",
    "\n",
    "#     # print(\"VAL PREDS\", val_preds.shape)\n",
    "#     # print(\"VAL SCORES\", val_scores.shape)\n",
    "#     # print(\"VAL LABELS\", val_labels.shape)\n",
    "#     val_preds = val_preds.cpu().numpy()\n",
    "#     val_scores = val_scores.cpu().numpy()\n",
    "#     val_labels = val_labels.cpu().numpy()\n",
    "\n",
    "#     # reports = classification_report(val_labels, val_preds, output_dict=True)\n",
    "#     print(\"VAL PREDS\", val_preds)\n",
    "#     print(\"VAL LABELS\", val_labels)\n",
    "#     print(\"VAL SCORES\", val_scores)\n",
    "#     # try:\n",
    "#     #     auc = roc_auc_score(val_labels, val_scores)\n",
    "#     # except Exception as e:\n",
    "#     #     print(e)\n",
    "#     #     print(\"Cannot calculate AUC. Default to 0\")\n",
    "#     #     auc = 0\n",
    "#     accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "#     print(classification_report(val_labels, val_preds))\n",
    "\n",
    "#     self.log(\"loss/val\", val_loss)\n",
    "#     # self.log(\"auc/val\", auc)\n",
    "#     self.log(\"accuracy/val\", accuracy)\n",
    "#     # self.log(\"precision/val\", reports[\"weighted avg\"][\"precision\"])\n",
    "#     # self.log(\"recall/val\", reports[\"weighted avg\"][\"recall\"])\n",
    "#     # self.log(\"f1/val\", reports[\"weighted avg\"][\"f1-score\"])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hBUVnSf-_ht0"
   ],
   "name": "Multimodal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02eca356512546b1954a563bc988d6b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "046f564c5ccc4b9f9c866a6a57b900bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08e56fb9c8c74262aa75994d2766136d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cfbf06467a04d4e9f97d8fbbb9328b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_345e16e44bad4ccf83b61099383e8b71",
      "placeholder": "​",
      "style": "IPY_MODEL_69e00ff1b849487f9e10000b486a766c",
      "value": "Downloading: 100%"
     }
    },
    "1250687b6c4e48e0a4b79de74f294235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0cfbf06467a04d4e9f97d8fbbb9328b7",
       "IPY_MODEL_16736771e702494cb52be951b3df47bc",
       "IPY_MODEL_df155493042740d9b96ee0343b9f03d4"
      ],
      "layout": "IPY_MODEL_70da72f327b64a8a8d2574848ddaa5c0"
     }
    },
    "16559060dd074447bf5e27134b4870ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "16736771e702494cb52be951b3df47bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98128e9bcb0b4cf4a949d51f299b3bde",
      "max": 895321,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_302b8bb010ec40908960c26742dd4df3",
      "value": 895321
     }
    },
    "1bb3780855494b029edc7dc564fcc51e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e21006c0b9740ecb6f427f6a49bf409": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f0e5ebe496b45ec97082f2bb666a82e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2132d76e642e4cbaaabf71e032d0fb8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2889253c1e7d4df1b02db1773a304e26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_876c019d15f04031af2f5735ed37a038",
       "IPY_MODEL_800ec21aa4674fce95f33685c2033b11",
       "IPY_MODEL_6b4ab9aa406a4071b5e888b0cd25335c"
      ],
      "layout": "IPY_MODEL_82995c53c15f4166a2641b2560faa49d"
     }
    },
    "2d90f769f9a748899fd536bc215e0902": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f0e5ebe496b45ec97082f2bb666a82e",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2132d76e642e4cbaaabf71e032d0fb8b",
      "value": 2
     }
    },
    "2f8400d957d4428b86f73a07c12a69ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b375fdd33a8f4fad9f7dcc33f24f3f7b",
       "IPY_MODEL_562df45b9b7e42799e8323f7db1eaf18",
       "IPY_MODEL_624a86d43249405388f1286063cebae4"
      ],
      "layout": "IPY_MODEL_c9918922671546a88e3b2ee509394df3"
     }
    },
    "302b8bb010ec40908960c26742dd4df3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "31d14a5ec28640d8acf64959fb4a5aa8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "345e16e44bad4ccf83b61099383e8b71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d8af058291c4c7393bb04f2f1ec2622": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f3889c16b134b408de36adb46505c40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "460e2a8033f04d4fbd9109254d2dfb73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93b193607ebd4e758cfc04a19b9dd2d6",
      "placeholder": "​",
      "style": "IPY_MODEL_b860941628094b5c8720672f5ebb3f3d",
      "value": " 0/540 [00:00&lt;?, ?it/s]"
     }
    },
    "49da75829cbd4350a64bfcdc04576ac1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bea41d4adb249d5afc2cbd40dc3210d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "562df45b9b7e42799e8323f7db1eaf18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49da75829cbd4350a64bfcdc04576ac1",
      "max": 557,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bea41d4adb249d5afc2cbd40dc3210d",
      "value": 557
     }
    },
    "624a86d43249405388f1286063cebae4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08e56fb9c8c74262aa75994d2766136d",
      "placeholder": "​",
      "style": "IPY_MODEL_ca0da54234e9446db60b5331fa076d81",
      "value": " 557/557 [00:00&lt;00:00, 5.30kB/s]"
     }
    },
    "664ccebe5b894806a2c84d633e107f38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69e00ff1b849487f9e10000b486a766c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b4ab9aa406a4071b5e888b0cd25335c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad4a2e90f75d49f289b127d43acca1df",
      "placeholder": "​",
      "style": "IPY_MODEL_d63ef1d399ab42698b667b2938d7e398",
      "value": " 1.08M/1.08M [00:00&lt;00:00, 3.02MB/s]"
     }
    },
    "70da72f327b64a8a8d2574848ddaa5c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "733c53bc95c0490982e6473ad1d55418": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7939b8ff88a940028fb77f2bd715db87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "800ec21aa4674fce95f33685c2033b11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d8af058291c4c7393bb04f2f1ec2622",
      "max": 1135173,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e4cb55de261c4416b945fdb72232c12d",
      "value": 1135173
     }
    },
    "81d26020a9784869b593de58ca922404": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82995c53c15f4166a2641b2560faa49d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83e93a1ba3f24f96ac5ea9107e160a9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7939b8ff88a940028fb77f2bd715db87",
      "placeholder": "​",
      "style": "IPY_MODEL_02eca356512546b1954a563bc988d6b5",
      "value": " 2/2 [00:03&lt;00:00,  1.54s/it]"
     }
    },
    "876c019d15f04031af2f5735ed37a038": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e21006c0b9740ecb6f427f6a49bf409",
      "placeholder": "​",
      "style": "IPY_MODEL_733c53bc95c0490982e6473ad1d55418",
      "value": "Downloading: 100%"
     }
    },
    "8d8bf547e78f461da79bb4e3e8449335": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81d26020a9784869b593de58ca922404",
      "placeholder": "​",
      "style": "IPY_MODEL_664ccebe5b894806a2c84d633e107f38",
      "value": "Validation sanity check: 100%"
     }
    },
    "93b193607ebd4e758cfc04a19b9dd2d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98128e9bcb0b4cf4a949d51f299b3bde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9aad7677f25b4c85abc0e6edb7b9212d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e47ffdaa9228458182c11c9ba945e33d",
       "IPY_MODEL_c4c4bae04bad46dea96a97dc5a7d8d0d",
       "IPY_MODEL_460e2a8033f04d4fbd9109254d2dfb73"
      ],
      "layout": "IPY_MODEL_fff7e36afcae4a3a81e5b40705c21519"
     }
    },
    "a93f05a257d5421eb2c72efcdac8fcd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d8bf547e78f461da79bb4e3e8449335",
       "IPY_MODEL_2d90f769f9a748899fd536bc215e0902",
       "IPY_MODEL_83e93a1ba3f24f96ac5ea9107e160a9e"
      ],
      "layout": "IPY_MODEL_16559060dd074447bf5e27134b4870ae"
     }
    },
    "ad4a2e90f75d49f289b127d43acca1df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b375fdd33a8f4fad9f7dcc33f24f3f7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bb3780855494b029edc7dc564fcc51e",
      "placeholder": "​",
      "style": "IPY_MODEL_046f564c5ccc4b9f9c866a6a57b900bf",
      "value": "Downloading: 100%"
     }
    },
    "b860941628094b5c8720672f5ebb3f3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba20e1bc66e94c829e2a46dd5d6a3483": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bb16f7ad93f34d12babc320869e1413b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4c4bae04bad46dea96a97dc5a7d8d0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31d14a5ec28640d8acf64959fb4a5aa8",
      "max": 540,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ba20e1bc66e94c829e2a46dd5d6a3483",
      "value": 0
     }
    },
    "c9918922671546a88e3b2ee509394df3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca0da54234e9446db60b5331fa076d81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d63ef1d399ab42698b667b2938d7e398": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db463b1c3ae44d6980bec291e144523c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df155493042740d9b96ee0343b9f03d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f3889c16b134b408de36adb46505c40",
      "placeholder": "​",
      "style": "IPY_MODEL_db463b1c3ae44d6980bec291e144523c",
      "value": " 874k/874k [00:00&lt;00:00, 1.31MB/s]"
     }
    },
    "e47ffdaa9228458182c11c9ba945e33d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb16f7ad93f34d12babc320869e1413b",
      "placeholder": "​",
      "style": "IPY_MODEL_f7947613432143f98f2f714598d25dfd",
      "value": "Epoch 0:   0%"
     }
    },
    "e4cb55de261c4416b945fdb72232c12d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f7947613432143f98f2f714598d25dfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fff7e36afcae4a3a81e5b40705c21519": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
